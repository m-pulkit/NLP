{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Naive Machine Translation and LSH\n",
    "\n",
    "You will now implement your first machine translation system and then you\n",
    "will see how locality sensitive hashing works. Let's get started by importing\n",
    "the required functions!\n",
    "\n",
    "If you are running this notebook in your local computer, don't forget to\n",
    "download the twitter samples and stopwords from nltk.\n",
    "\n",
    "```\n",
    "nltk.download('stopwords')\n",
    "nltk.download('twitter_samples')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb\n",
    "import pickle\n",
    "import string\n",
    "import re\n",
    "\n",
    "# import time\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add directory of pre-downloaded corpora files to nltk's data path\n",
    "nltk.data.path.append(\"D:/Pulkit/2017 Class-XII/Jupyter/NLP - Deeplearning.ai/nltk_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0\n",
      "  0  599M    0 53524    0     0   9820      0 17:47:06  0:00:05 17:47:01 11047\n",
      "  0  599M    0  307k    0     0  48979      0  3:33:56  0:00:06  3:33:50 63628\n",
      "  0  599M    0  486k    0     0  67057      0  2:36:16  0:00:07  2:36:09  101k\n",
      "  0  599M    0  723k    0     0  88016      0  1:59:03  0:00:08  1:58:55  147k\n",
      "  0  599M    0  885k    0     0  96233      0  1:48:53  0:00:09  1:48:44  193k\n",
      "  0  599M    0 1064k    0     0   102k      0  1:40:14  0:00:10  1:40:04  203k\n",
      "  0  599M    0 1259k    0     0   109k      0  1:33:13  0:00:11  1:33:02  188k\n",
      "  0  599M    0 1659k    0     0   133k      0  1:16:36  0:00:12  1:16:24  234k\n",
      "  0  599M    0 1835k    0     0   136k      0  1:14:56  0:00:13  1:14:43  221k\n",
      "  0  599M    0 2123k    0     0   147k      0  1:09:29  0:00:14  1:09:15  247k\n",
      "  0  599M    0 2459k    0     0   159k      0  1:04:07  0:00:15  1:03:52  279k\n",
      "  0  599M    0 2747k    0     0   167k      0  1:01:09  0:00:16  1:00:53  300k\n",
      "  0  599M    0 3003k    0     0   172k      0  0:59:23  0:00:17  0:59:06  268k\n",
      "  0  599M    0 3275k    0     0   177k      0  0:57:31  0:00:18  0:57:13  289k\n",
      "  0  599M    0 3483k    0     0   179k      0  0:57:03  0:00:19  0:56:44  271k\n",
      "  0  599M    0 3771k    0     0   183k      0  0:55:52  0:00:20  0:55:32  253k\n",
      "  0  599M    0 3931k    0     0   183k      0  0:55:44  0:00:21  0:55:23  236k\n",
      "  0  599M    0 4155k    0     0   184k      0  0:55:19  0:00:22  0:54:57  229k\n",
      "  0  599M    0 4299k    0     0   183k      0  0:55:47  0:00:23  0:55:24  203k\n",
      "  0  599M    0 4331k    0     0   176k      0  0:57:56  0:00:24  0:57:32  166k\n",
      "  0  599M    0 4427k    0     0   174k      0  0:58:44  0:00:25  0:58:19  136k\n",
      "  0  599M    0 4651k    0     0   176k      0  0:58:07  0:00:26  0:57:41  143k\n",
      "  0  599M    0 4955k    0     0   180k      0  0:56:38  0:00:27  0:56:11  160k\n",
      "  0  599M    0 5259k    0     0   184k      0  0:55:19  0:00:28  0:54:51  192k\n",
      "  0  599M    0 5547k    0     0   188k      0  0:54:15  0:00:29  0:53:46  248k\n",
      "  0  599M    0 5867k    0     0   192k      0  0:53:06  0:00:30  0:52:36  285k\n",
      "  0  599M    0 6075k    0     0   193k      0  0:52:54  0:00:31  0:52:23  284k\n",
      "  1  599M    1 6331k    0     0   195k      0  0:52:23  0:00:32  0:51:51  276k\n",
      "  1  599M    1 6539k    0     0   195k      0  0:52:25  0:00:33  0:51:52  252k\n",
      "  1  599M    1 6795k    0     0   197k      0  0:51:51  0:00:34  0:51:17  248k\n",
      "  1  599M    1 7019k    0     0   198k      0  0:51:39  0:00:35  0:51:04  231k\n",
      "  1  599M    1 7163k    0     0   196k      0  0:52:01  0:00:36  0:51:25  217k\n",
      "  1  599M    1 7355k    0     0   196k      0  0:52:05  0:00:37  0:51:28  203k\n",
      "  1  599M    1 7563k    0     0   196k      0  0:51:59  0:00:38  0:51:21  208k\n",
      "  1  599M    1 7803k    0     0   197k      0  0:51:41  0:00:39  0:51:02  202k\n",
      "  1  599M    1 8059k    0     0   199k      0  0:51:18  0:00:40  0:50:38  208k\n",
      "  1  599M    1 8203k    0     0   197k      0  0:51:41  0:00:41  0:51:00  207k\n",
      "  1  599M    1 8331k    0     0   196k      0  0:52:07  0:00:42  0:51:25  195k\n",
      "  1  599M    1 8411k    0     0   193k      0  0:52:50  0:00:43  0:52:07  169k\n",
      "  1  599M    1 8523k    0     0   191k      0  0:53:20  0:00:44  0:52:36  143k\n",
      "  1  599M    1 8667k    0     0   190k      0  0:53:46  0:00:45  0:53:01  118k\n",
      "  1  599M    1 8827k    0     0   190k      0  0:53:48  0:00:46  0:53:02  125k\n",
      "  1  599M    1 8923k    0     0   188k      0  0:54:24  0:00:47  0:53:37  118k\n",
      "  1  599M    1 9147k    0     0   188k      0  0:54:09  0:00:48  0:53:21  147k\n",
      "  1  599M    1 9403k    0     0   190k      0  0:53:47  0:00:49  0:52:58  176k\n",
      "  1  599M    1 9659k    0     0   191k      0  0:53:24  0:00:50  0:52:34  203k\n",
      "  1  599M    1 9947k    0     0   193k      0  0:52:53  0:00:51  0:52:02  223k\n",
      "  1  599M    1  9.9M    0     0   194k      0  0:52:34  0:00:52  0:51:42  257k\n",
      "  1  599M    1 10.2M    0     0   196k      0  0:51:57  0:00:53  0:51:04  274k\n",
      "  1  599M    1 10.5M    0     0   199k      0  0:51:21  0:00:54  0:50:27  288k\n",
      "  1  599M    1 10.9M    0     0   202k      0  0:50:30  0:00:55  0:49:35  313k\n",
      "  1  599M    1 11.2M    0     0   204k      0  0:49:59  0:00:56  0:49:03  320k\n",
      "  1  599M    1 11.6M    0     0   206k      0  0:49:27  0:00:57  0:48:30  335k\n",
      "  1  599M    1 11.8M    0     0   207k      0  0:49:20  0:00:58  0:48:22  317k\n",
      "  2  599M    2 12.2M    0     0   211k      0  0:48:25  0:00:59  0:47:26  342k\n",
      "  2  599M    2 12.6M    0     0   214k      0  0:47:36  0:01:00  0:46:36  351k\n",
      "  2  599M    2 12.9M    0     0   215k      0  0:47:24  0:01:01  0:46:23  342k\n",
      "  2  599M    2 13.1M    0     0   215k      0  0:47:30  0:01:02  0:46:28  311k\n",
      "  2  599M    2 13.3M    0     0   215k      0  0:47:28  0:01:03  0:46:25  312k\n",
      "  2  599M    2 13.6M    0     0   216k      0  0:47:18  0:01:04  0:46:14  275k\n",
      "  2  599M    2 13.8M    0     0   217k      0  0:47:04  0:01:05  0:45:59  246k\n",
      "  2  599M    2 14.1M    0     0   217k      0  0:46:57  0:01:06  0:45:51  243k\n",
      "  2  599M    2 14.4M    0     0   218k      0  0:46:46  0:01:07  0:45:39  261k\n",
      "  2  599M    2 14.6M    0     0   219k      0  0:46:34  0:01:08  0:45:26  272k\n",
      "  2  599M    2 14.9M    0     0   220k      0  0:46:18  0:01:09  0:45:09  281k\n",
      "  2  599M    2 15.2M    0     0   221k      0  0:46:09  0:01:10  0:44:59  278k\n",
      "  2  599M    2 15.4M    0     0   221k      0  0:46:10  0:01:11  0:44:59  270k\n",
      "  2  599M    2 15.6M    0     0   221k      0  0:46:08  0:01:12  0:44:56  262k\n",
      "  2  599M    2 15.9M    0     0   222k      0  0:46:00  0:01:13  0:44:47  259k\n",
      "  2  599M    2 16.1M    0     0   222k      0  0:46:05  0:01:14  0:44:51  236k\n",
      "  2  599M    2 16.4M    0     0   223k      0  0:45:46  0:01:15  0:44:31  249k\n",
      "  2  599M    2 16.8M    0     0   226k      0  0:45:13  0:01:16  0:43:57  293k\n",
      "  2  599M    2 17.2M    0     0   228k      0  0:44:50  0:01:17  0:43:33  320k\n",
      "  2  599M    2 17.5M    0     0   229k      0  0:44:38  0:01:18  0:43:20  328k\n",
      "  2  599M    2 17.7M    0     0   229k      0  0:44:39  0:01:19  0:43:20  334k\n",
      "  3  599M    3 18.0M    0     0   229k      0  0:44:37  0:01:20  0:43:17  316k\n",
      "  3  599M    3 18.2M    0     0   229k      0  0:44:33  0:01:21  0:43:12  281k\n",
      "  3  599M    3 18.4M    0     0   229k      0  0:44:38  0:01:22  0:43:16  245k\n",
      "  3  599M    3 18.6M    0     0   229k      0  0:44:39  0:01:23  0:43:16  227k\n",
      "  3  599M    3 18.8M    0     0   228k      0  0:44:43  0:01:24  0:43:19  224k\n",
      "  3  599M    3 19.1M    0     0   229k      0  0:44:40  0:01:25  0:43:15  224k\n",
      "  3  599M    3 19.3M    0     0   229k      0  0:44:39  0:01:26  0:43:13  220k\n",
      "  3  599M    3 19.5M    0     0   228k      0  0:44:42  0:01:27  0:43:15  223k\n",
      "  3  599M    3 19.7M    0     0   228k      0  0:44:47  0:01:28  0:43:19  217k\n",
      "  3  599M    3 19.8M    0     0   227k      0  0:44:56  0:01:29  0:43:27  208k\n",
      "  3  599M    3 20.0M    0     0   226k      0  0:45:11  0:01:30  0:43:41  183k\n",
      "  3  599M    3 20.1M    0     0   226k      0  0:45:14  0:01:31  0:43:43  175k\n",
      "  3  599M    3 20.4M    0     0   226k      0  0:45:12  0:01:32  0:43:40  181k\n",
      "  3  599M    3 20.5M    0     0   225k      0  0:45:26  0:01:33  0:43:53  167k\n",
      "  3  599M    3 20.7M    0     0   225k      0  0:45:25  0:01:34  0:43:51  182k\n",
      "  3  599M    3 20.9M    0     0   224k      0  0:45:29  0:01:35  0:43:54  197k\n",
      "  3  599M    3 21.1M    0     0   224k      0  0:45:29  0:01:36  0:43:53  202k\n",
      "  3  599M    3 21.3M    0     0   224k      0  0:45:35  0:01:37  0:43:58  189k\n",
      "  3  599M    3 21.5M    0     0   223k      0  0:45:42  0:01:38  0:44:04  199k\n",
      "  3  599M    3 21.6M    0     0   223k      0  0:45:49  0:01:39  0:44:10  185k\n",
      "  3  599M    3 21.8M    0     0   222k      0  0:45:54  0:01:40  0:44:14  182k\n",
      "  3  599M    3 22.0M    0     0   222k      0  0:45:54  0:01:41  0:44:13  182k\n",
      "  3  599M    3 22.2M    0     0   222k      0  0:45:54  0:01:42  0:44:12  192k\n",
      "  3  599M    3 22.4M    0     0   222k      0  0:46:04  0:01:43  0:44:21  186k\n",
      "  3  599M    3 22.6M    0     0   222k      0  0:46:04  0:01:44  0:44:20  197k\n",
      "  3  599M    3 22.8M    0     0   222k      0  0:46:05  0:01:45  0:44:20  204k\n",
      "  3  599M    3 23.0M    0     0   221k      0  0:46:07  0:01:46  0:44:21  201k\n",
      "  3  599M    3 23.2M    0     0   222k      0  0:46:05  0:01:47  0:44:18  204k\n",
      "  3  599M    3 23.4M    0     0   221k      0  0:46:10  0:01:48  0:44:22  211k\n",
      "  3  599M    3 23.7M    0     0   221k      0  0:46:06  0:01:49  0:44:17  218k\n",
      "  3  599M    3 23.8M    0     0   221k      0  0:46:13  0:01:50  0:44:23  208k\n",
      "  4  599M    4 24.3M    0     0   223k      0  0:45:46  0:01:51  0:43:55  259k\n",
      "  4  599M    4 24.5M    0     0   223k      0  0:45:41  0:01:52  0:43:49  266k\n",
      "  4  599M    4 24.7M    0     0   223k      0  0:45:45  0:01:53  0:43:52  268k\n",
      "  4  599M    4 24.9M    0     0   222k      0  0:45:55  0:01:54  0:44:01  243k\n",
      "  4  599M    4 25.1M    0     0   223k      0  0:45:53  0:01:55  0:43:58  258k\n",
      "  4  599M    4 25.3M    0     0   222k      0  0:45:58  0:01:56  0:44:02  200k\n",
      "  4  599M    4 25.4M    0     0   222k      0  0:46:01  0:01:57  0:44:04  184k\n",
      "  4  599M    4 25.6M    0     0   221k      0  0:46:11  0:01:58  0:44:13  172k\n",
      "  4  599M    4 25.7M    0     0   220k      0  0:46:21  0:01:59  0:44:22  172k\n",
      "  4  599M    4 25.8M    0     0   219k      0  0:46:30  0:02:00  0:44:30  150k\n",
      "  4  599M    4 25.9M    0     0   218k      0  0:46:44  0:02:01  0:44:43  134k\n",
      "  4  599M    4 26.0M    0     0   217k      0  0:47:00  0:02:02  0:44:58  108k\n",
      "  4  599M    4 26.1M    0     0   217k      0  0:47:06  0:02:03  0:45:03  115k\n",
      "  4  599M    4 26.3M    0     0   216k      0  0:47:10  0:02:04  0:45:06  124k\n",
      "  4  599M    4 26.4M    0     0   215k      0  0:47:23  0:02:05  0:45:18  118k\n",
      "  4  599M    4 26.5M    0     0   215k      0  0:47:31  0:02:06  0:45:25  127k\n",
      "  4  599M    4 26.7M    0     0   214k      0  0:47:36  0:02:07  0:45:29  147k\n",
      "  4  599M    4 26.9M    0     0   214k      0  0:47:35  0:02:08  0:45:27  159k\n",
      "  4  599M    4 27.1M    0     0   214k      0  0:47:38  0:02:09  0:45:29  162k\n",
      "  4  599M    4 27.3M    0     0   215k      0  0:47:35  0:02:10  0:45:25  191k\n",
      "  4  599M    4 27.6M    0     0   215k      0  0:47:32  0:02:11  0:45:21  212k\n",
      "  4  599M    4 27.8M    0     0   215k      0  0:47:35  0:02:12  0:45:23  216k\n",
      "  4  599M    4 27.8M    0     0   213k      0  0:47:52  0:02:13  0:45:39  182k\n",
      "  4  599M    4 27.9M    0     0   212k      0  0:48:04  0:02:14  0:45:50  163k\n",
      "  4  599M    4 28.0M    0     0   211k      0  0:48:19  0:02:15  0:46:04  129k\n",
      "  4  599M    4 28.1M    0     0   211k      0  0:48:23  0:02:16  0:46:07  111k\n",
      "  4  599M    4 28.2M    0     0   210k      0  0:48:36  0:02:17  0:46:19 95027\n",
      "  4  599M    4 28.3M    0     0   209k      0  0:48:46  0:02:18  0:46:28  104k\n",
      "  4  599M    4 28.5M    0     0   209k      0  0:48:48  0:02:19  0:46:29  121k\n",
      "  4  599M    4 28.7M    0     0   209k      0  0:48:48  0:02:20  0:46:28  149k\n",
      "  4  599M    4 28.9M    0     0   209k      0  0:48:48  0:02:21  0:46:27  162k\n",
      "  4  599M    4 29.1M    0     0   209k      0  0:48:48  0:02:22  0:46:26  185k\n",
      "  4  599M    4 29.3M    0     0   209k      0  0:48:51  0:02:23  0:46:28  200k\n",
      "  4  599M    4 29.5M    0     0   209k      0  0:48:49  0:02:24  0:46:25  208k\n",
      "  4  599M    4 29.7M    0     0   209k      0  0:48:50  0:02:25  0:46:25  207k\n",
      "  5  599M    5 29.9M    0     0   209k      0  0:48:47  0:02:26  0:46:21  212k\n",
      "  5  599M    5 30.2M    0     0   209k      0  0:48:45  0:02:27  0:46:18  215k\n",
      "  5  599M    5 30.4M    0     0   210k      0  0:48:40  0:02:28  0:46:12  233k\n",
      "  5  599M    5 30.6M    0     0   210k      0  0:48:42  0:02:29  0:46:13  223k\n",
      "  5  599M    5 30.8M    0     0   210k      0  0:48:43  0:02:30  0:46:13  224k\n",
      "  5  599M    5 31.0M    0     0   210k      0  0:48:42  0:02:31  0:46:11  220k\n",
      "  5  599M    5 31.2M    0     0   209k      0  0:48:48  0:02:32  0:46:16  204k\n",
      "  5  599M    5 31.3M    0     0   208k      0  0:48:58  0:02:33  0:46:25  170k\n",
      "  5  599M    5 31.4M    0     0   208k      0  0:49:04  0:02:34  0:46:30  163k\n",
      "  5  599M    5 31.6M    0     0   208k      0  0:49:07  0:02:35  0:46:32  156k\n",
      "  5  599M    5 31.7M    0     0   208k      0  0:49:10  0:02:36  0:46:34  147k\n",
      "  5  599M    5 31.9M    0     0   207k      0  0:49:14  0:02:37  0:46:37  150k\n",
      "  5  599M    5 32.1M    0     0   207k      0  0:49:14  0:02:38  0:46:36  173k\n",
      "  5  599M    5 32.3M    0     0   208k      0  0:49:11  0:02:39  0:46:32  192k\n",
      "  5  599M    5 32.6M    0     0   208k      0  0:49:10  0:02:40  0:46:30  201k\n",
      "  5  599M    5 32.8M    0     0   208k      0  0:49:05  0:02:41  0:46:24  217k\n",
      "  5  599M    5 33.1M    0     0   208k      0  0:49:02  0:02:42  0:46:20  235k\n",
      "  5  599M    5 33.3M    0     0   209k      0  0:48:56  0:02:43  0:46:13  249k\n",
      "  5  599M    5 33.6M    0     0   209k      0  0:48:46  0:02:44  0:46:02  265k\n",
      "  5  599M    5 34.0M    0     0   210k      0  0:48:36  0:02:45  0:45:51  288k\n",
      "  5  599M    5 34.3M    0     0   211k      0  0:48:22  0:02:46  0:45:36  310k\n",
      "  5  599M    5 34.7M    0     0   212k      0  0:48:05  0:02:47  0:45:18  348k\n",
      "  5  599M    5 35.3M    0     0   214k      0  0:47:40  0:02:48  0:44:52  396k\n",
      "  5  599M    5 35.7M    0     0   216k      0  0:47:21  0:02:49  0:44:32  422k\n",
      "  6  599M    6 35.9M    0     0   216k      0  0:47:19  0:02:50  0:44:29  403k\n",
      "  6  599M    6 36.3M    0     0   217k      0  0:47:08  0:02:51  0:44:17  403k\n",
      "  6  599M    6 36.5M    0     0   217k      0  0:47:06  0:02:52  0:44:14  364k\n",
      "  6  599M    6 36.8M    0     0   217k      0  0:47:03  0:02:53  0:44:10  309k\n",
      "  6  599M    6 37.0M    0     0   217k      0  0:47:02  0:02:54  0:44:08  268k\n",
      "  6  599M    6 37.3M    0     0   217k      0  0:46:58  0:02:55  0:44:03  275k\n",
      "  6  599M    6 37.4M    0     0   217k      0  0:47:05  0:02:56  0:44:09  225k\n",
      "  6  599M    6 37.8M    0     0   218k      0  0:46:53  0:02:57  0:43:56  252k\n",
      "  6  599M    6 38.2M    0     0   219k      0  0:46:39  0:02:58  0:43:41  285k\n",
      "  6  599M    6 38.6M    0     0   220k      0  0:46:23  0:02:59  0:43:24  324k\n",
      "  6  599M    6 39.1M    0     0   221k      0  0:46:06  0:03:00  0:43:06  363k\n",
      "  6  599M    6 39.5M    0     0   223k      0  0:45:52  0:03:01  0:42:51  435k\n",
      "  6  599M    6 39.9M    0     0   224k      0  0:45:39  0:03:02  0:42:37  435k\n",
      "  6  599M    6 40.3M    0     0   225k      0  0:45:28  0:03:03  0:42:25  429k\n",
      "  6  599M    6 40.8M    0     0   226k      0  0:45:05  0:03:04  0:42:01  456k\n",
      "  6  599M    6 41.2M    0     0   227k      0  0:44:53  0:03:05  0:41:48  444k\n",
      "  6  599M    6 41.6M    0     0   228k      0  0:44:41  0:03:06  0:41:35  443k\n",
      "  7  599M    7 42.1M    0     0   230k      0  0:44:23  0:03:07  0:41:16  464k\n",
      "  7  599M    7 42.7M    0     0   232k      0  0:44:04  0:03:08  0:40:56  489k\n",
      "  7  599M    7 43.3M    0     0   234k      0  0:43:41  0:03:09  0:40:32  501k\n",
      "  7  599M    7 43.7M    0     0   234k      0  0:43:33  0:03:10  0:40:23  485k\n",
      "  7  599M    7 44.1M    0     0   236k      0  0:43:19  0:03:11  0:40:08  505k\n",
      "  7  599M    7 44.5M    0     0   237k      0  0:43:07  0:03:12  0:39:55  487k\n",
      "  7  599M    7 45.0M    0     0   238k      0  0:42:54  0:03:13  0:39:41  479k\n",
      "  7  599M    7 45.4M    0     0   239k      0  0:42:45  0:03:14  0:39:31  433k\n",
      "  7  599M    7 45.7M    0     0   239k      0  0:42:41  0:03:15  0:39:26  428k\n",
      "  7  599M    7 46.2M    0     0   240k      0  0:42:27  0:03:16  0:39:11  424k\n",
      "  7  599M    7 46.5M    0     0   241k      0  0:42:23  0:03:17  0:39:06  400k\n",
      "  7  599M    7 46.8M    0     0   241k      0  0:42:19  0:03:18  0:39:01  371k\n",
      "  7  599M    7 47.2M    0     0   242k      0  0:42:09  0:03:19  0:38:50  376k\n",
      "  7  599M    7 47.6M    0     0   243k      0  0:42:04  0:03:20  0:38:44  380k\n",
      "  7  599M    7 47.8M    0     0   243k      0  0:42:04  0:03:21  0:38:43  331k\n",
      "  8  599M    8 48.1M    0     0   243k      0  0:42:01  0:03:22  0:38:39  326k\n",
      "  8  599M    8 48.3M    0     0   243k      0  0:42:01  0:03:23  0:38:38  310k\n",
      "  8  599M    8 48.6M    0     0   243k      0  0:42:01  0:03:24  0:38:37  272k\n",
      "  8  599M    8 49.3M    0     0   246k      0  0:41:35  0:03:25  0:38:10  359k\n",
      "  8  599M    8 50.1M    0     0   248k      0  0:41:09  0:03:26  0:37:43  464k\n",
      "  8  599M    8 50.8M    0     0   251k      0  0:40:45  0:03:27  0:37:18  560k\n",
      "  8  599M    8 51.4M    0     0   253k      0  0:40:26  0:03:28  0:36:58  639k\n",
      "  8  599M    8 52.0M    0     0   254k      0  0:40:14  0:03:29  0:36:45  696k\n",
      "  8  599M    8 52.4M    0     0   255k      0  0:40:04  0:03:30  0:36:34  639k\n",
      "  8  599M    8 52.9M    0     0   256k      0  0:39:52  0:03:31  0:36:21  591k\n",
      "  8  599M    8 53.6M    0     0   258k      0  0:39:31  0:03:32  0:35:59  582k\n",
      "  9  599M    9 54.3M    0     0   260k      0  0:39:16  0:03:33  0:35:43  575k\n",
      "  9  599M    9 54.9M    0     0   262k      0  0:38:59  0:03:34  0:35:25  601k\n",
      "  9  599M    9 55.5M    0     0   263k      0  0:38:46  0:03:35  0:35:11  621k\n",
      "  9  599M    9 55.9M    0     0   264k      0  0:38:40  0:03:36  0:35:04  598k\n",
      "  9  599M    9 56.2M    0     0   264k      0  0:38:37  0:03:37  0:35:00  521k\n",
      "  9  599M    9 56.5M    0     0   265k      0  0:38:34  0:03:38  0:34:56  464k\n",
      "  9  599M    9 56.9M    0     0   265k      0  0:38:31  0:03:39  0:34:52  405k\n",
      "  9  599M    9 57.2M    0     0   265k      0  0:38:29  0:03:40  0:34:49  349k\n",
      "  9  599M    9 57.4M    0     0   265k      0  0:38:29  0:03:41  0:34:48  320k\n",
      "  9  599M    9 57.7M    0     0   265k      0  0:38:29  0:03:42  0:34:47  305k\n",
      "  9  599M    9 58.0M    0     0   265k      0  0:38:29  0:03:43  0:34:46  295k\n",
      "  9  599M    9 58.2M    0     0   265k      0  0:38:28  0:03:44  0:34:44  278k\n",
      "  9  599M    9 58.5M    0     0   265k      0  0:38:30  0:03:45  0:34:45  262k\n",
      "  9  599M    9 58.7M    0     0   265k      0  0:38:29  0:03:46  0:34:43  265k\n",
      "  9  599M    9 58.9M    0     0   265k      0  0:38:32  0:03:47  0:34:45  252k\n",
      "  9  599M    9 59.3M    0     0   265k      0  0:38:28  0:03:48  0:34:40  266k\n",
      "  9  599M    9 59.6M    0     0   266k      0  0:38:25  0:03:49  0:34:36  282k\n",
      "  9  599M    9 59.9M    0     0   266k      0  0:38:25  0:03:50  0:34:35  291k\n",
      " 10  599M   10 60.1M    0     0   266k      0  0:38:26  0:03:51  0:34:35  284k\n",
      " 10  599M   10 60.4M    0     0   266k      0  0:38:27  0:03:52  0:34:35  292k\n",
      " 10  599M   10 60.6M    0     0   265k      0  0:38:29  0:03:53  0:34:36  261k\n",
      " 10  599M   10 60.8M    0     0   265k      0  0:38:28  0:03:54  0:34:34  250k\n",
      " 10  599M   10 61.2M    0     0   266k      0  0:38:25  0:03:55  0:34:30  262k\n",
      " 10  599M   10 61.5M    0     0   266k      0  0:38:22  0:03:56  0:34:26  288k\n",
      " 10  599M   10 61.8M    0     0   266k      0  0:38:22  0:03:57  0:34:25  296k\n",
      " 10  599M   10 62.0M    0     0   266k      0  0:38:22  0:03:58  0:34:24  306k\n",
      " 10  599M   10 62.2M    0     0   266k      0  0:38:25  0:03:59  0:34:26  284k\n",
      " 10  599M   10 62.5M    0     0   266k      0  0:38:25  0:04:00  0:34:25  266k\n",
      " 10  599M   10 62.7M    0     0   266k      0  0:38:27  0:04:01  0:34:26  237k\n",
      " 10  599M   10 63.0M    0     0   266k      0  0:38:26  0:04:02  0:34:24  243k\n",
      " 10  599M   10 63.3M    0     0   266k      0  0:38:24  0:04:03  0:34:21  255k\n",
      " 10  599M   10 63.5M    0     0   266k      0  0:38:25  0:04:04  0:34:21  263k\n",
      " 10  599M   10 63.8M    0     0   266k      0  0:38:25  0:04:05  0:34:20  267k\n",
      " 10  599M   10 64.0M    0     0   265k      0  0:38:28  0:04:06  0:34:22  261k\n",
      " 10  599M   10 64.2M    0     0   265k      0  0:38:29  0:04:07  0:34:22  246k\n",
      " 10  599M   10 64.4M    0     0   265k      0  0:38:30  0:04:08  0:34:22  233k\n",
      " 10  599M   10 64.7M    0     0   265k      0  0:38:30  0:04:09  0:34:21  239k\n",
      " 10  599M   10 65.0M    0     0   265k      0  0:38:29  0:04:10  0:34:19  246k\n",
      " 10  599M   10 65.2M    0     0   265k      0  0:38:31  0:04:11  0:34:20  246k\n",
      " 10  599M   10 65.3M    0     0   265k      0  0:38:34  0:04:12  0:34:22  236k\n",
      " 10  599M   10 65.6M    0     0   265k      0  0:38:33  0:04:13  0:34:20  246k\n",
      " 11  599M   11 65.9M    0     0   265k      0  0:38:33  0:04:14  0:34:19  248k\n",
      " 11  599M   11 66.4M    0     0   266k      0  0:38:26  0:04:15  0:34:11  283k\n",
      " 11  599M   11 66.8M    0     0   266k      0  0:38:21  0:04:16  0:34:05  327k\n",
      " 11  599M   11 67.1M    0     0   266k      0  0:38:20  0:04:17  0:34:03  349k\n",
      " 11  599M   11 67.4M    0     0   267k      0  0:38:17  0:04:18  0:33:59  357k\n",
      " 11  599M   11 67.6M    0     0   267k      0  0:38:18  0:04:19  0:33:59  360k\n",
      " 11  599M   11 68.0M    0     0   267k      0  0:38:14  0:04:20  0:33:54  335k\n",
      " 11  599M   11 68.3M    0     0   267k      0  0:38:12  0:04:21  0:33:51  319k\n",
      " 11  599M   11 68.5M    0     0   267k      0  0:38:17  0:04:22  0:33:55  283k\n",
      " 11  599M   11 68.6M    0     0   266k      0  0:38:21  0:04:23  0:33:58  244k\n",
      " 11  599M   11 68.7M    0     0   266k      0  0:38:26  0:04:24  0:34:02  214k\n",
      " 11  599M   11 68.9M    0     0   265k      0  0:38:29  0:04:25  0:34:04  176k\n",
      " 11  599M   11 69.0M    0     0   265k      0  0:38:32  0:04:26  0:34:06  147k\n",
      " 11  599M   11 69.2M    0     0   265k      0  0:38:36  0:04:27  0:34:09  145k\n",
      " 11  599M   11 69.3M    0     0   264k      0  0:38:41  0:04:28  0:34:13  141k\n",
      " 11  599M   11 69.4M    0     0   263k      0  0:38:47  0:04:29  0:34:18  139k\n",
      " 11  599M   11 69.5M    0     0   263k      0  0:38:51  0:04:30  0:34:21  127k\n",
      " 11  599M   11 69.7M    0     0   263k      0  0:38:54  0:04:31  0:34:23  127k\n",
      " 11  599M   11 69.8M    0     0   262k      0  0:38:57  0:04:32  0:34:25  134k\n",
      " 11  599M   11 70.0M    0     0   262k      0  0:39:00  0:04:33  0:34:27  147k\n",
      " 11  599M   11 70.2M    0     0   262k      0  0:39:03  0:04:34  0:34:29  165k\n",
      " 11  599M   11 70.4M    0     0   261k      0  0:39:04  0:04:35  0:34:29  185k\n",
      " 11  599M   11 70.7M    0     0   261k      0  0:39:03  0:04:36  0:34:27  205k\n",
      " 11  599M   11 70.9M    0     0   261k      0  0:39:04  0:04:37  0:34:27  220k\n",
      " 11  599M   11 71.1M    0     0   261k      0  0:39:06  0:04:38  0:34:28  225k\n",
      " 11  599M   11 71.4M    0     0   261k      0  0:39:05  0:04:39  0:34:26  244k\n",
      " 11  599M   11 71.7M    0     0   261k      0  0:39:04  0:04:40  0:34:24  262k\n",
      " 12  599M   12 72.0M    0     0   262k      0  0:39:02  0:04:41  0:34:21  268k\n",
      " 12  599M   12 72.2M    0     0   262k      0  0:39:02  0:04:42  0:34:20  275k\n",
      " 12  599M   12 72.5M    0     0   262k      0  0:39:01  0:04:43  0:34:18  292k\n",
      " 12  599M   12 72.8M    0     0   262k      0  0:39:02  0:04:44  0:34:18  282k\n",
      " 12  599M   12 73.1M    0     0   262k      0  0:39:00  0:04:45  0:34:15  282k\n",
      " 12  599M   12 73.2M    0     0   261k      0  0:39:05  0:04:46  0:34:19  242k\n",
      " 12  599M   12 73.3M    0     0   261k      0  0:39:10  0:04:47  0:34:23  207k\n",
      " 12  599M   12 73.3M    0     0   260k      0  0:39:18  0:04:48  0:34:30  158k\n",
      " 12  599M   12 73.4M    0     0   259k      0  0:39:22  0:04:49  0:34:33  132k\n",
      " 12  599M   12 73.5M    0     0   259k      0  0:39:28  0:04:50  0:34:38 87580\n",
      " 12  599M   12 73.7M    0     0   259k      0  0:39:30  0:04:51  0:34:39 94989\n",
      " 12  599M   12 73.8M    0     0   258k      0  0:39:33  0:04:52  0:34:41  117k\n",
      " 12  599M   12 74.0M    0     0   258k      0  0:39:34  0:04:53  0:34:41  152k\n",
      " 12  599M   12 74.3M    0     0   258k      0  0:39:34  0:04:54  0:34:40  184k\n",
      " 12  599M   12 74.6M    0     0   258k      0  0:39:34  0:04:55  0:34:39  223k\n",
      " 12  599M   12 74.9M    0     0   258k      0  0:39:32  0:04:56  0:34:36  242k\n",
      " 12  599M   12 75.1M    0     0   258k      0  0:39:32  0:04:57  0:34:35  261k\n",
      " 12  599M   12 75.4M    0     0   258k      0  0:39:32  0:04:58  0:34:34  275k\n",
      " 12  599M   12 75.6M    0     0   258k      0  0:39:31  0:04:59  0:34:32  278k\n",
      " 12  599M   12 76.0M    0     0   259k      0  0:39:29  0:05:00  0:34:29  287k\n",
      " 12  599M   12 76.2M    0     0   258k      0  0:39:30  0:05:01  0:34:29  272k\n",
      " 12  599M   12 76.5M    0     0   259k      0  0:39:30  0:05:02  0:34:28  278k\n",
      " 12  599M   12 76.9M    0     0   259k      0  0:39:25  0:05:03  0:34:22  300k\n",
      " 12  599M   12 77.2M    0     0   259k      0  0:39:23  0:05:04  0:34:19  310k\n",
      " 12  599M   12 77.4M    0     0   259k      0  0:39:24  0:05:05  0:34:19  298k\n",
      " 12  599M   12 77.6M    0     0   259k      0  0:39:24  0:05:06  0:34:18  300k\n",
      " 12  599M   12 77.9M    0     0   259k      0  0:39:25  0:05:07  0:34:18  288k\n",
      " 13  599M   13 78.2M    0     0   259k      0  0:39:22  0:05:08  0:34:14  284k\n",
      " 13  599M   13 78.5M    0     0   259k      0  0:39:22  0:05:09  0:34:13  268k\n",
      " 13  599M   13 78.8M    0     0   259k      0  0:39:21  0:05:10  0:34:11  275k\n",
      " 13  599M   13 79.0M    0     0   260k      0  0:39:20  0:05:11  0:34:09  285k\n",
      " 13  599M   13 79.3M    0     0   260k      0  0:39:20  0:05:12  0:34:08  294k\n",
      " 13  599M   13 79.6M    0     0   260k      0  0:39:19  0:05:13  0:34:06  278k\n",
      " 13  599M   13 79.9M    0     0   260k      0  0:39:16  0:05:14  0:34:02  300k\n",
      " 13  599M   13 80.3M    0     0   260k      0  0:39:14  0:05:15  0:33:59  307k\n",
      " 13  599M   13 80.6M    0     0   260k      0  0:39:12  0:05:16  0:33:56  316k\n",
      " 13  599M   13 80.8M    0     0   260k      0  0:39:13  0:05:17  0:33:56  310k\n",
      " 13  599M   13 81.0M    0     0   260k      0  0:39:14  0:05:18  0:33:56  294k\n",
      " 13  599M   13 81.4M    0     0   261k      0  0:39:10  0:05:19  0:33:51  301k\n",
      " 13  599M   13 81.7M    0     0   261k      0  0:39:09  0:05:20  0:33:49  300k\n",
      " 13  599M   13 82.0M    0     0   261k      0  0:39:09  0:05:21  0:33:48  285k\n",
      " 13  599M   13 82.2M    0     0   261k      0  0:39:11  0:05:22  0:33:49  274k\n",
      " 13  599M   13 82.3M    0     0   260k      0  0:39:14  0:05:23  0:33:51  259k\n",
      " 13  599M   13 82.6M    0     0   260k      0  0:39:13  0:05:24  0:33:49  244k\n",
      " 13  599M   13 82.9M    0     0   261k      0  0:39:12  0:05:25  0:33:47  240k\n",
      " 13  599M   13 83.1M    0     0   260k      0  0:39:13  0:05:26  0:33:47  233k\n",
      " 13  599M   13 83.4M    0     0   260k      0  0:39:14  0:05:27  0:33:47  240k\n",
      " 13  599M   13 83.6M    0     0   260k      0  0:39:13  0:05:28  0:33:45  271k\n",
      " 13  599M   13 83.9M    0     0   260k      0  0:39:13  0:05:29  0:33:44  259k\n",
      " 14  599M   14 84.3M    0     0   261k      0  0:39:09  0:05:30  0:33:39  284k\n",
      " 14  599M   14 84.6M    0     0   261k      0  0:39:07  0:05:31  0:33:36  307k\n",
      " 14  599M   14 84.8M    0     0   261k      0  0:39:09  0:05:32  0:33:37  299k\n",
      " 14  599M   14 85.1M    0     0   261k      0  0:39:09  0:05:33  0:33:36  290k\n",
      " 14  599M   14 85.3M    0     0   261k      0  0:39:09  0:05:34  0:33:35  292k\n",
      " 14  599M   14 85.6M    0     0   261k      0  0:39:09  0:05:35  0:33:34  258k\n",
      " 14  599M   14 85.6M    0     0   260k      0  0:39:13  0:05:36  0:33:37  211k\n",
      " 14  599M   14 85.8M    0     0   260k      0  0:39:17  0:05:37  0:33:40  203k\n",
      " 14  599M   14 85.9M    0     0   259k      0  0:39:21  0:05:38  0:33:43  166k\n",
      " 14  599M   14 86.0M    0     0   259k      0  0:39:25  0:05:39  0:33:46  135k\n",
      " 14  599M   14 86.1M    0     0   259k      0  0:39:30  0:05:40  0:33:50  105k\n",
      " 14  599M   14 86.1M    0     0   258k      0  0:39:35  0:05:41  0:33:54   99k\n",
      " 14  599M   14 86.2M    0     0   257k      0  0:39:40  0:05:42  0:33:58 83235\n",
      " 14  599M   14 86.3M    0     0   257k      0  0:39:44  0:05:43  0:34:01 88420\n",
      " 14  599M   14 86.4M    0     0   256k      0  0:39:49  0:05:44  0:34:05 85077\n",
      " 14  599M   14 86.5M    0     0   256k      0  0:39:54  0:05:45  0:34:09 82530\n",
      " 14  599M   14 86.6M    0     0   256k      0  0:39:58  0:05:46  0:34:12 91677\n",
      " 14  599M   14 86.7M    0     0   255k      0  0:40:00  0:05:47  0:34:13  109k\n",
      " 14  599M   14 86.9M    0     0   255k      0  0:40:02  0:05:48  0:34:14  124k\n",
      " 14  599M   14 87.1M    0     0   255k      0  0:40:05  0:05:49  0:34:16  137k\n",
      " 14  599M   14 87.2M    0     0   254k      0  0:40:09  0:05:50  0:34:19  143k\n",
      " 14  599M   14 87.3M    0     0   254k      0  0:40:11  0:05:51  0:34:20  156k\n",
      " 14  599M   14 87.5M    0     0   254k      0  0:40:12  0:05:52  0:34:20  167k\n",
      " 14  599M   14 87.7M    0     0   254k      0  0:40:13  0:05:53  0:34:20  172k\n",
      " 14  599M   14 87.9M    0     0   254k      0  0:40:15  0:05:54  0:34:21  179k\n",
      " 14  599M   14 88.1M    0     0   253k      0  0:40:19  0:05:55  0:34:24  182k\n",
      " 14  599M   14 88.2M    0     0   253k      0  0:40:21  0:05:56  0:34:25  176k\n",
      " 14  599M   14 88.5M    0     0   253k      0  0:40:21  0:05:57  0:34:24  188k\n",
      " 14  599M   14 88.8M    0     0   253k      0  0:40:19  0:05:58  0:34:21  208k\n",
      " 14  599M   14 89.1M    0     0   253k      0  0:40:18  0:05:59  0:34:19  230k\n",
      " 14  599M   14 89.3M    0     0   253k      0  0:40:17  0:06:00  0:34:17  264k\n",
      " 14  599M   14 89.6M    0     0   253k      0  0:40:17  0:06:01  0:34:16  284k\n",
      " 14  599M   14 89.9M    0     0   254k      0  0:40:16  0:06:02  0:34:14  287k\n",
      " 15  599M   15 90.1M    0     0   253k      0  0:40:17  0:06:03  0:34:14  272k\n",
      " 15  599M   15 90.3M    0     0   253k      0  0:40:19  0:06:04  0:34:15  246k\n",
      " 15  599M   15 90.5M    0     0   253k      0  0:40:18  0:06:05  0:34:13  246k\n",
      " 15  599M   15 90.8M    0     0   253k      0  0:40:17  0:06:06  0:34:11  255k\n",
      " 15  599M   15 91.1M    0     0   254k      0  0:40:16  0:06:07  0:34:09  255k\n",
      " 15  599M   15 91.6M    0     0   254k      0  0:40:10  0:06:08  0:34:02  307k\n",
      " 15  599M   15 91.9M    0     0   254k      0  0:40:08  0:06:09  0:33:59  342k\n",
      " 15  599M   15 92.3M    0     0   255k      0  0:40:06  0:06:10  0:33:56  350k\n",
      " 15  599M   15 92.5M    0     0   255k      0  0:40:05  0:06:11  0:33:54  345k\n",
      " 15  599M   15 92.8M    0     0   255k      0  0:40:05  0:06:12  0:33:53  340k\n",
      " 15  599M   15 93.0M    0     0   255k      0  0:40:06  0:06:13  0:33:53  291k\n",
      " 15  599M   15 93.3M    0     0   255k      0  0:40:04  0:06:14  0:33:50  284k\n",
      " 15  599M   15 93.6M    0     0   255k      0  0:40:04  0:06:15  0:33:49  272k\n",
      " 15  599M   15 93.9M    0     0   255k      0  0:40:03  0:06:16  0:33:47  271k\n",
      " 15  599M   15 94.1M    0     0   255k      0  0:40:02  0:06:17  0:33:45  281k\n",
      " 15  599M   15 94.4M    0     0   255k      0  0:40:02  0:06:18  0:33:44  280k\n",
      " 15  599M   15 94.8M    0     0   255k      0  0:39:59  0:06:19  0:33:40  294k\n",
      " 15  599M   15 95.1M    0     0   256k      0  0:39:58  0:06:20  0:33:38  304k\n",
      " 15  599M   15 95.3M    0     0   255k      0  0:39:59  0:06:21  0:33:38  291k\n",
      " 15  599M   15 95.6M    0     0   256k      0  0:39:56  0:06:22  0:33:34  301k\n",
      " 16  599M   16 95.9M    0     0   256k      0  0:39:56  0:06:23  0:33:33  311k\n",
      " 16  599M   16 96.4M    0     0   256k      0  0:39:50  0:06:24  0:33:26  333k\n",
      " 16  599M   16 96.9M    0     0   257k      0  0:39:43  0:06:25  0:33:18  377k\n",
      " 16  599M   16 97.3M    0     0   257k      0  0:39:40  0:06:26  0:33:14  414k\n",
      " 16  599M   16 97.7M    0     0   258k      0  0:39:36  0:06:27  0:33:09  429k\n",
      " 16  599M   16 98.0M    0     0   258k      0  0:39:34  0:06:28  0:33:06  434k\n",
      " 16  599M   16 98.4M    0     0   258k      0  0:39:32  0:06:29  0:33:03  408k\n",
      " 16  599M   16 98.8M    0     0   259k      0  0:39:27  0:06:30  0:32:57  393k\n",
      " 16  599M   16 99.2M    0     0   259k      0  0:39:24  0:06:31  0:32:53  396k\n",
      " 16  599M   16 99.6M    0     0   259k      0  0:39:21  0:06:32  0:32:49  383k\n",
      " 16  599M   16 99.9M    0     0   260k      0  0:39:21  0:06:33  0:32:48  373k\n",
      " 16  599M   16  100M    0     0   259k      0  0:39:24  0:06:34  0:32:50  326k\n",
      " 16  599M   16  100M    0     0   259k      0  0:39:22  0:06:35  0:32:47  300k\n",
      " 16  599M   16  100M    0     0   259k      0  0:39:23  0:06:36  0:32:47  262k\n",
      " 16  599M   16  100M    0     0   259k      0  0:39:25  0:06:37  0:32:48  228k\n",
      " 16  599M   16  100M    0     0   259k      0  0:39:25  0:06:38  0:32:47  221k\n",
      " 16  599M   16  101M    0     0   259k      0  0:39:24  0:06:39  0:32:45  256k\n",
      " 16  599M   16  101M    0     0   259k      0  0:39:25  0:06:40  0:32:45  235k\n",
      " 16  599M   16  101M    0     0   259k      0  0:39:23  0:06:41  0:32:42  258k\n",
      " 17  599M   17  102M    0     0   259k      0  0:39:24  0:06:42  0:32:42  267k\n",
      " 17  599M   17  102M    0     0   259k      0  0:39:26  0:06:43  0:32:43  256k\n",
      " 17  599M   17  102M    0     0   259k      0  0:39:25  0:06:44  0:32:41  255k\n",
      " 17  599M   17  102M    0     0   259k      0  0:39:24  0:06:45  0:32:39  262k\n",
      " 17  599M   17  102M    0     0   259k      0  0:39:27  0:06:46  0:32:41  225k\n",
      " 17  599M   17  103M    0     0   258k      0  0:39:31  0:06:47  0:32:44  192k\n",
      " 17  599M   17  103M    0     0   258k      0  0:39:35  0:06:48  0:32:47  173k\n",
      " 17  599M   17  103M    0     0   258k      0  0:39:39  0:06:49  0:32:50  131k\n",
      " 17  599M   17  103M    0     0   257k      0  0:39:40  0:06:50  0:32:50  121k\n",
      " 17  599M   17  103M    0     0   257k      0  0:39:42  0:06:51  0:32:51  125k\n",
      " 17  599M   17  103M    0     0   257k      0  0:39:46  0:06:52  0:32:54  127k\n",
      " 17  599M   17  103M    0     0   257k      0  0:39:48  0:06:53  0:32:55  145k\n",
      " 17  599M   17  103M    0     0   256k      0  0:39:50  0:06:54  0:32:56  157k\n",
      " 17  599M   17  104M    0     0   256k      0  0:39:54  0:06:55  0:32:59  134k\n",
      " 17  599M   17  104M    0     0   256k      0  0:39:56  0:06:56  0:33:00  131k\n",
      " 17  599M   17  104M    0     0   255k      0  0:39:59  0:06:57  0:33:02  148k\n",
      " 17  599M   17  104M    0     0   255k      0  0:40:00  0:06:58  0:33:02  149k\n",
      " 17  599M   17  104M    0     0   255k      0  0:40:02  0:06:59  0:33:03  155k\n",
      " 17  599M   17  104M    0     0   255k      0  0:40:05  0:07:00  0:33:05  156k\n",
      " 17  599M   17  104M    0     0   255k      0  0:40:07  0:07:01  0:33:06  160k\n",
      " 17  599M   17  105M    0     0   254k      0  0:40:08  0:07:02  0:33:06  167k\n",
      " 17  599M   17  105M    0     0   254k      0  0:40:08  0:07:03  0:33:05  180k\n",
      " 17  599M   17  105M    0     0   254k      0  0:40:09  0:07:04  0:33:05  190k\n",
      " 17  599M   17  105M    0     0   254k      0  0:40:09  0:07:05  0:33:04  216k\n",
      " 17  599M   17  106M    0     0   254k      0  0:40:11  0:07:06  0:33:05  216k\n",
      " 17  599M   17  106M    0     0   254k      0  0:40:14  0:07:07  0:33:07  201k\n",
      " 17  599M   17  106M    0     0   253k      0  0:40:19  0:07:08  0:33:11  161k\n",
      " 17  599M   17  106M    0     0   253k      0  0:40:19  0:07:09  0:33:10  163k\n",
      " 17  599M   17  106M    0     0   253k      0  0:40:21  0:07:10  0:33:11  144k\n",
      " 17  599M   17  106M    0     0   253k      0  0:40:24  0:07:11  0:33:13  135k\n",
      " 17  599M   17  106M    0     0   252k      0  0:40:27  0:07:12  0:33:15  132k\n",
      " 17  599M   17  106M    0     0   252k      0  0:40:32  0:07:13  0:33:19  135k\n",
      " 17  599M   17  106M    0     0   252k      0  0:40:34  0:07:14  0:33:20  118k\n",
      " 17  599M   17  107M    0     0   251k      0  0:40:38  0:07:15  0:33:23  102k\n",
      " 17  599M   17  107M    0     0   251k      0  0:40:42  0:07:16  0:33:26 94913\n",
      " 17  599M   17  107M    0     0   250k      0  0:40:46  0:07:17  0:33:29 88455\n",
      " 17  599M   17  107M    0     0   250k      0  0:40:50  0:07:18  0:33:32 88121\n",
      " 17  599M   17  107M    0     0   249k      0  0:40:56  0:07:19  0:33:37 67829\n",
      " 17  599M   17  107M    0     0   249k      0  0:41:01  0:07:20  0:33:41 55113\n",
      " 17  599M   17  107M    0     0   249k      0  0:41:04  0:07:21  0:33:43 59006\n",
      " 17  599M   17  107M    0     0   248k      0  0:41:07  0:07:22  0:33:45 65496\n",
      " 17  599M   17  107M    0     0   248k      0  0:41:10  0:07:23  0:33:47 75578\n",
      " 17  599M   17  107M    0     0   248k      0  0:41:14  0:07:24  0:33:50 80778\n",
      " 17  599M   17  107M    0     0   247k      0  0:41:18  0:07:25  0:33:53 89813\n",
      " 17  599M   17  107M    0     0   247k      0  0:41:22  0:07:26  0:33:56 91058\n",
      " 17  599M   17  107M    0     0   246k      0  0:41:25  0:07:27  0:33:58 81903\n",
      " 18  599M   18  108M    0     0   246k      0  0:41:29  0:07:28  0:34:01 77603\n",
      " 18  599M   18  108M    0     0   246k      0  0:41:32  0:07:29  0:34:03 85060\n",
      " 18  599M   18  108M    0     0   246k      0  0:41:35  0:07:30  0:34:05 97025\n",
      " 18  599M   18  108M    0     0   245k      0  0:41:39  0:07:31  0:34:08 92546\n",
      " 18  599M   18  108M    0     0   245k      0  0:41:43  0:07:32  0:34:11 95084\n",
      " 18  599M   18  108M    0     0   244k      0  0:41:48  0:07:33  0:34:15 89902\n",
      " 18  599M   18  108M    0     0   244k      0  0:41:50  0:07:34  0:34:16 88473\n",
      " 18  599M   18  108M    0     0   244k      0  0:41:53  0:07:35  0:34:18 91695\n",
      " 18  599M   18  108M    0     0   243k      0  0:41:57  0:07:36  0:34:21 88402\n",
      " 18  599M   18  108M    0     0   243k      0  0:42:01  0:07:37  0:34:24 88579\n",
      " 18  599M   18  108M    0     0   243k      0  0:42:04  0:07:38  0:34:26 98444\n",
      " 18  599M   18  108M    0     0   242k      0  0:42:08  0:07:39  0:34:29 91384\n",
      " 18  599M   18  109M    0     0   242k      0  0:42:12  0:07:40  0:34:32 75140\n",
      " 18  599M   18  109M    0     0   242k      0  0:42:16  0:07:41  0:34:35 75291\n",
      " 18  599M   18  109M    0     0   241k      0  0:42:20  0:07:42  0:34:38 71831\n",
      " 18  599M   18  109M    0     0   241k      0  0:42:25  0:07:43  0:34:42 59112\n",
      " 18  599M   18  109M    0     0   240k      0  0:42:29  0:07:44  0:34:45 59458\n",
      " 18  599M   18  109M    0     0   240k      0  0:42:33  0:07:45  0:34:48 59017\n",
      " 18  599M   18  109M    0     0   240k      0  0:42:38  0:07:46  0:34:52 52324\n",
      " 18  599M   18  109M    0     0   239k      0  0:42:43  0:07:47  0:34:56 45847\n",
      " 18  599M   18  109M    0     0   239k      0  0:42:48  0:07:48  0:35:00 39203\n",
      " 18  599M   18  109M    0     0   238k      0  0:42:52  0:07:49  0:35:03 35929\n",
      " 18  599M   18  109M    0     0   237k      0  0:43:00  0:07:51  0:35:09 32315\n",
      " 18  599M   18  109M    0     0   237k      0  0:43:02  0:07:51  0:35:11 32462\n",
      " 18  599M   18  109M    0     0   237k      0  0:43:06  0:07:52  0:35:14 32800\n",
      " 18  599M   18  109M    0     0   236k      0  0:43:11  0:07:53  0:35:18 35772\n",
      " 18  599M   18  109M    0     0   236k      0  0:43:16  0:07:54  0:35:22 32833\n",
      " 18  599M   18  109M    0     0   236k      0  0:43:20  0:07:55  0:35:25 37160\n",
      " 18  599M   18  109M    0     0   235k      0  0:43:24  0:07:56  0:35:28 39590\n",
      " 18  599M   18  109M    0     0   235k      0  0:43:28  0:07:57  0:35:31 45930\n",
      " 18  599M   18  109M    0     0   234k      0  0:43:32  0:07:58  0:35:34 52872\n",
      " 18  599M   18  109M    0     0   234k      0  0:43:36  0:07:59  0:35:37 65300\n",
      " 18  599M   18  109M    0     0   234k      0  0:43:39  0:08:00  0:35:39 72075\n",
      " 18  599M   18  110M    0     0   234k      0  0:43:42  0:08:01  0:35:41 82166\n",
      " 18  599M   18  110M    0     0   233k      0  0:43:46  0:08:02  0:35:44 81854\n",
      " 18  599M   18  110M    0     0   233k      0  0:43:49  0:08:03  0:35:46 88775\n",
      " 18  599M   18  110M    0     0   233k      0  0:43:53  0:08:04  0:35:49 85026\n",
      " 18  599M   18  110M    0     0   232k      0  0:43:57  0:08:05  0:35:52 81936\n",
      " 18  599M   18  110M    0     0   232k      0  0:44:01  0:08:06  0:35:55 78003\n",
      " 18  599M   18  110M    0     0   232k      0  0:44:05  0:08:07  0:35:58 78706\n",
      " 18  599M   18  110M    0     0   231k      0  0:44:10  0:08:08  0:36:02 64905\n",
      " 18  599M   18  110M    0     0   231k      0  0:44:12  0:08:09  0:36:03 69158\n",
      " 18  599M   18  110M    0     0   231k      0  0:44:16  0:08:10  0:36:06 72017\n",
      " 18  599M   18  110M    0     0   230k      0  0:44:20  0:08:11  0:36:09 72466\n",
      " 18  599M   18  110M    0     0   230k      0  0:44:23  0:08:12  0:36:11 75366\n",
      " 18  599M   18  110M    0     0   230k      0  0:44:27  0:08:13  0:36:14 86816\n",
      " 18  599M   18  111M    0     0   229k      0  0:44:30  0:08:14  0:36:16 81805\n",
      " 18  599M   18  111M    0     0   229k      0  0:44:33  0:08:15  0:36:18 88491\n",
      " 18  599M   18  111M    0     0   229k      0  0:44:36  0:08:16  0:36:20 88722\n",
      " 18  599M   18  111M    0     0   229k      0  0:44:40  0:08:17  0:36:23 91585\n",
      " 18  599M   18  111M    0     0   228k      0  0:44:43  0:08:18  0:36:25 95217\n",
      " 18  599M   18  111M    0     0   228k      0  0:44:47  0:08:19  0:36:28 87166\n",
      " 18  599M   18  111M    0     0   228k      0  0:44:50  0:08:20  0:36:30 81772\n",
      " 18  599M   18  111M    0     0   227k      0  0:44:53  0:08:21  0:36:32 88668\n",
      " 18  599M   18  111M    0     0   227k      0  0:44:56  0:08:22  0:36:34 91952\n",
      " 18  599M   18  111M    0     0   227k      0  0:44:57  0:08:23  0:36:34  102k\n",
      " 18  599M   18  112M    0     0   227k      0  0:44:59  0:08:24  0:36:35  130k\n",
      " 18  599M   18  112M    0     0   227k      0  0:45:01  0:08:25  0:36:36  141k\n",
      " 18  599M   18  112M    0     0   227k      0  0:45:02  0:08:26  0:36:36  155k\n",
      " 18  599M   18  112M    0     0   227k      0  0:45:02  0:08:27  0:36:35  172k\n",
      " 18  599M   18  112M    0     0   227k      0  0:45:02  0:08:28  0:36:34  185k\n",
      " 18  599M   18  113M    0     0   227k      0  0:45:02  0:08:29  0:36:33  201k\n",
      " 18  599M   18  113M    0     0   227k      0  0:45:03  0:08:30  0:36:33  207k\n",
      " 18  599M   18  113M    0     0   227k      0  0:45:04  0:08:31  0:36:33  205k\n",
      " 18  599M   18  113M    0     0   226k      0  0:45:06  0:08:32  0:36:34  198k\n",
      " 18  599M   18  113M    0     0   226k      0  0:45:07  0:08:33  0:36:34  187k\n",
      " 19  599M   19  113M    0     0   226k      0  0:45:07  0:08:34  0:36:33  182k\n",
      " 19  599M   19  114M    0     0   226k      0  0:45:08  0:08:35  0:36:33  178k\n",
      " 19  599M   19  114M    0     0   226k      0  0:45:11  0:08:36  0:36:35  169k\n",
      " 19  599M   19  114M    0     0   226k      0  0:45:14  0:08:37  0:36:37  156k\n",
      " 19  599M   19  114M    0     0   225k      0  0:45:18  0:08:38  0:36:40  130k\n",
      " 19  599M   19  114M    0     0   225k      0  0:45:21  0:08:39  0:36:42  101k\n",
      " 19  599M   19  114M    0     0   225k      0  0:45:24  0:08:40  0:36:44 98520\n",
      " 19  599M   19  114M    0     0   225k      0  0:45:26  0:08:41  0:36:45 98837\n",
      " 19  599M   19  114M    0     0   224k      0  0:45:29  0:08:42  0:36:47 97640\n",
      " 19  599M   19  114M    0     0   224k      0  0:45:30  0:08:43  0:36:47  119k\n",
      " 19  599M   19  115M    0     0   224k      0  0:45:32  0:08:44  0:36:48  132k\n",
      " 19  599M   19  115M    0     0   224k      0  0:45:33  0:08:45  0:36:48  144k\n",
      " 19  599M   19  115M    0     0   224k      0  0:45:36  0:08:46  0:36:50  140k\n",
      " 19  599M   19  115M    0     0   223k      0  0:45:41  0:08:47  0:36:54  123k\n",
      " 19  599M   19  115M    0     0   223k      0  0:45:41  0:08:48  0:36:53  127k\n",
      " 19  599M   19  115M    0     0   223k      0  0:45:44  0:08:49  0:36:55  117k\n",
      " 19  599M   19  115M    0     0   223k      0  0:45:48  0:08:50  0:36:58   99k\n",
      " 19  599M   19  115M    0     0   223k      0  0:45:51  0:08:51  0:37:00 91815\n",
      " 19  599M   19  115M    0     0   222k      0  0:45:53  0:08:52  0:37:01  116k\n",
      " 19  599M   19  116M    0     0   222k      0  0:45:56  0:08:53  0:37:03   99k\n",
      " 19  599M   19  116M    0     0   222k      0  0:46:03  0:08:55  0:37:08 79163\n",
      " 19  599M   19  116M    0     0   221k      0  0:46:08  0:08:56  0:37:12 59992\n",
      " 19  599M   19  116M    0     0   221k      0  0:46:10  0:08:56  0:37:14 55783\n",
      " 19  599M   19  116M    0     0   221k      0  0:46:14  0:08:57  0:37:17 42428\n",
      " 19  599M   19  116M    0     0   221k      0  0:46:16  0:08:58  0:37:18 45911\n",
      " 19  599M   19  116M    0     0   220k      0  0:46:19  0:08:59  0:37:20 74659\n",
      " 19  599M   19  116M    0     0   220k      0  0:46:21  0:09:00  0:37:21   98k\n",
      " 19  599M   19  116M    0     0   220k      0  0:46:24  0:09:01  0:37:23  106k\n",
      " 19  599M   19  116M    0     0   220k      0  0:46:27  0:09:02  0:37:25  109k\n",
      " 19  599M   19  116M    0     0   220k      0  0:46:30  0:09:03  0:37:27  108k\n",
      " 19  599M   19  116M    0     0   219k      0  0:46:32  0:09:04  0:37:28  105k\n",
      " 19  599M   19  116M    0     0   219k      0  0:46:35  0:09:05  0:37:30   99k\n",
      " 19  599M   19  117M    0     0   219k      0  0:46:40  0:09:06  0:37:34 88784\n",
      " 19  599M   19  117M    0     0   219k      0  0:46:43  0:09:07  0:37:36 84722\n",
      " 19  599M   19  117M    0     0   218k      0  0:46:47  0:09:08  0:37:39 71659\n",
      " 19  599M   19  117M    0     0   218k      0  0:46:51  0:09:09  0:37:42 59302\n",
      " 19  599M   19  117M    0     0   218k      0  0:46:55  0:09:10  0:37:45 52376\n",
      " 19  599M   19  117M    0     0   217k      0  0:46:58  0:09:11  0:37:47 54106\n",
      " 19  599M   19  117M    0     0   217k      0  0:47:02  0:09:12  0:37:50 59171\n",
      " 19  599M   19  117M    0     0   217k      0  0:47:05  0:09:13  0:37:52 63040\n",
      " 19  599M   19  117M    0     0   217k      0  0:47:09  0:09:14  0:37:55 65287\n",
      " 19  599M   19  117M    0     0   216k      0  0:47:13  0:09:15  0:37:58 65588\n",
      " 19  599M   19  117M    0     0   216k      0  0:47:16  0:09:16  0:38:00 68552\n",
      " 19  599M   19  117M    0     0   216k      0  0:47:20  0:09:17  0:38:03 65588\n",
      " 19  599M   19  117M    0     0   215k      0  0:47:23  0:09:18  0:38:05 68730\n",
      " 19  599M   19  117M    0     0   215k      0  0:47:26  0:09:19  0:38:07 71902\n",
      " 19  599M   19  117M    0     0   215k      0  0:47:29  0:09:20  0:38:09 78533\n",
      " 19  599M   19  117M    0     0   215k      0  0:47:33  0:09:21  0:38:12 75699\n",
      " 19  599M   19  118M    0     0   214k      0  0:47:36  0:09:22  0:38:14 78361\n",
      " 19  599M   19  118M    0     0   214k      0  0:47:40  0:09:23  0:38:17 71659\n",
      " 19  599M   19  118M    0     0   214k      0  0:47:44  0:09:24  0:38:20 69144\n",
      " 19  599M   19  118M    0     0   214k      0  0:47:48  0:09:25  0:38:23 61826\n",
      " 19  599M   19  118M    0     0   213k      0  0:47:52  0:09:26  0:38:26 55208\n",
      " 19  599M   19  118M    0     0   213k      0  0:47:56  0:09:27  0:38:29 45701\n",
      " 19  599M   19  118M    0     0   213k      0  0:48:01  0:09:28  0:38:33 39590\n",
      " 19  599M   19  118M    0     0   212k      0  0:48:05  0:09:29  0:38:36 35186\n",
      " 19  599M   19  118M    0     0   212k      0  0:48:10  0:09:30  0:38:40 29286\n",
      " 19  599M   19  118M    0     0   212k      0  0:48:14  0:09:31  0:38:43 26214\n",
      " 19  599M   19  118M    0     0   211k      0  0:48:20  0:09:32  0:38:48 25028\n",
      " 19  599M   19  118M    0     0   211k      0  0:48:23  0:09:33  0:38:50 29455\n",
      " 19  599M   19  118M    0     0   211k      0  0:48:27  0:09:34  0:38:53 30253\n",
      " 19  599M   19  118M    0     0   210k      0  0:48:31  0:09:35  0:38:56 36298\n",
      " 19  599M   19  118M    0     0   210k      0  0:48:35  0:09:36  0:38:59 41722\n",
      " 19  599M   19  118M    0     0   210k      0  0:48:39  0:09:37  0:39:02 44849\n",
      " 19  599M   19  118M    0     0   210k      0  0:48:43  0:09:38  0:39:05 42193\n",
      " 19  599M   19  118M    0     0   209k      0  0:48:48  0:09:39  0:39:09 35758\n",
      " 19  599M   19  118M    0     0   209k      0  0:48:52  0:09:40  0:39:12 36269\n",
      " 19  599M   19  118M    0     0   209k      0  0:48:56  0:09:41  0:39:15 36638\n",
      " 19  599M   19  118M    0     0   208k      0  0:48:59  0:09:42  0:39:17 39487\n",
      " 19  599M   19  118M    0     0   208k      0  0:49:03  0:09:43  0:39:20 42950\n",
      " 19  599M   19  118M    0     0   208k      0  0:49:07  0:09:44  0:39:23 49478\n",
      " 19  599M   19  119M    0     0   208k      0  0:49:08  0:09:45  0:39:23 72219\n",
      " 19  599M   19  119M    0     0   208k      0  0:49:07  0:09:46  0:39:21  116k\n",
      " 19  599M   19  119M    0     0   208k      0  0:49:08  0:09:47  0:39:21  133k\n",
      " 19  599M   19  119M    0     0   208k      0  0:49:10  0:09:48  0:39:22  150k\n",
      " 19  599M   19  119M    0     0   207k      0  0:49:12  0:09:49  0:39:23  163k\n",
      " 19  599M   19  119M    0     0   207k      0  0:49:13  0:09:50  0:39:23  169k\n",
      " 20  599M   20  120M    0     0   207k      0  0:49:14  0:09:51  0:39:23  147k\n",
      " 20  599M   20  120M    0     0   207k      0  0:49:15  0:09:52  0:39:23  151k\n",
      " 20  599M   20  120M    0     0   207k      0  0:49:17  0:09:53  0:39:24  150k\n",
      " 20  599M   20  120M    0     0   207k      0  0:49:20  0:09:54  0:39:26  145k\n",
      " 20  599M   20  120M    0     0   207k      0  0:49:23  0:09:55  0:39:28  123k\n",
      " 20  599M   20  120M    0     0   207k      0  0:49:26  0:09:56  0:39:30  111k\n",
      " 20  599M   20  120M    0     0   206k      0  0:49:28  0:09:57  0:39:31  103k\n",
      " 20  599M   20  120M    0     0   206k      0  0:49:28  0:09:58  0:39:30  117k\n",
      " 20  599M   20  121M    0     0   206k      0  0:49:30  0:09:59  0:39:31  125k\n",
      " 20  599M   20  121M    0     0   206k      0  0:49:31  0:10:00  0:39:31  137k\n",
      " 20  599M   20  121M    0     0   206k      0  0:49:33  0:10:01  0:39:32  147k\n",
      " 20  599M   20  121M    0     0   206k      0  0:49:35  0:10:02  0:39:33  142k\n",
      " 20  599M   20  121M    0     0   206k      0  0:49:37  0:10:03  0:39:34  131k\n",
      " 20  599M   20  121M    0     0   206k      0  0:49:39  0:10:04  0:39:35  133k\n",
      " 20  599M   20  121M    0     0   206k      0  0:49:40  0:10:05  0:39:35  135k\n",
      " 20  599M   20  121M    0     0   205k      0  0:49:43  0:10:06  0:39:37  121k\n",
      " 20  599M   20  121M    0     0   205k      0  0:49:47  0:10:07  0:39:40  113k\n",
      " 20  599M   20  122M    0     0   205k      0  0:49:50  0:10:08  0:39:42   97k\n",
      " 20  599M   20  122M    0     0   205k      0  0:49:52  0:10:09  0:39:43 92733\n",
      " 20  599M   20  122M    0     0   205k      0  0:49:54  0:10:10  0:39:44 85111\n",
      " 20  599M   20  122M    0     0   204k      0  0:49:58  0:10:11  0:39:47 79984\n",
      " 20  599M   20  122M    0     0   204k      0  0:50:02  0:10:12  0:39:50 71665\n",
      " 20  599M   20  122M    0     0   204k      0  0:50:05  0:10:13  0:39:52 80231\n",
      " 20  599M   20  122M    0     0   204k      0  0:50:08  0:10:14  0:39:54 72118\n",
      " 20  599M   20  122M    0     0   203k      0  0:50:16  0:10:16  0:40:00 48676\n",
      " 20  599M   20  122M    0     0   203k      0  0:50:17  0:10:16  0:40:01 46479\n",
      " 20  599M   20  122M    0     0   203k      0  0:50:20  0:10:17  0:40:03 61569\n",
      " 20  599M   20  122M    0     0   203k      0  0:50:22  0:10:18  0:40:04 58747\n",
      " 20  599M   20  122M    0     0   202k      0  0:50:27  0:10:19  0:40:08 56496\n",
      " 20  599M   20  122M    0     0   202k      0  0:50:29  0:10:20  0:40:09 80558\n",
      " 20  599M   20  122M    0     0   202k      0  0:50:32  0:10:21  0:40:11 82831\n",
      " 20  599M   20  123M    0     0   202k      0  0:50:32  0:10:22  0:40:10  104k\n",
      " 20  599M   20  123M    0     0   202k      0  0:50:32  0:10:23  0:40:09  123k\n",
      " 20  599M   20  123M    0     0   202k      0  0:50:35  0:10:24  0:40:11  136k\n",
      " 20  599M   20  123M    0     0   202k      0  0:50:37  0:10:25  0:40:12  133k\n",
      " 20  599M   20  123M    0     0   201k      0  0:50:40  0:10:26  0:40:14  134k\n",
      " 20  599M   20  123M    0     0   201k      0  0:50:41  0:10:27  0:40:14  120k\n",
      " 20  599M   20  123M    0     0   201k      0  0:50:43  0:10:28  0:40:15  110k\n",
      " 20  599M   20  123M    0     0   201k      0  0:50:45  0:10:29  0:40:16  116k\n",
      " 20  599M   20  124M    0     0   201k      0  0:50:47  0:10:30  0:40:17  115k\n",
      " 20  599M   20  124M    0     0   201k      0  0:50:49  0:10:31  0:40:18  124k\n",
      " 20  599M   20  124M    0     0   201k      0  0:50:52  0:10:32  0:40:20  109k\n",
      " 20  599M   20  124M    0     0   200k      0  0:50:55  0:10:33  0:40:22  105k\n",
      " 20  599M   20  124M    0     0   200k      0  0:50:56  0:10:34  0:40:22  105k\n",
      " 20  599M   20  124M    0     0   200k      0  0:50:58  0:10:35  0:40:23  108k\n",
      " 20  599M   20  124M    0     0   200k      0  0:51:02  0:10:36  0:40:26 93715\n",
      " 20  599M   20  124M    0     0   200k      0  0:51:06  0:10:37  0:40:29 91494\n",
      " 20  599M   20  124M    0     0   200k      0  0:51:08  0:10:38  0:40:30 96319\n",
      " 20  599M   20  124M    0     0   200k      0  0:51:08  0:10:39  0:40:29   98k\n",
      " 20  599M   20  125M    0     0   199k      0  0:51:10  0:10:40  0:40:30  102k\n",
      " 20  599M   20  125M    0     0   199k      0  0:51:13  0:10:41  0:40:32  110k\n",
      " 20  599M   20  125M    0     0   199k      0  0:51:17  0:10:42  0:40:35  112k\n",
      " 20  599M   20  125M    0     0   199k      0  0:51:20  0:10:43  0:40:37 96946\n",
      " 20  599M   20  125M    0     0   199k      0  0:51:24  0:10:44  0:40:40 68812\n",
      " 20  599M   20  125M    0     0   198k      0  0:51:28  0:10:45  0:40:43 52261\n",
      " 20  599M   20  125M    0     0   198k      0  0:51:31  0:10:46  0:40:45 50526\n",
      " 20  599M   20  125M    0     0   198k      0  0:51:34  0:10:47  0:40:47 50619\n",
      " 20  599M   20  125M    0     0   198k      0  0:51:38  0:10:48  0:40:50 52502\n",
      " 20  599M   20  125M    0     0   197k      0  0:51:41  0:10:49  0:40:52 62309\n",
      " 20  599M   20  125M    0     0   197k      0  0:51:44  0:10:50  0:40:54 65536\n",
      " 20  599M   20  125M    0     0   197k      0  0:51:48  0:10:51  0:40:57 59017\n",
      " 20  599M   20  125M    0     0   197k      0  0:51:51  0:10:52  0:40:59 57871\n",
      " 20  599M   20  125M    0     0   197k      0  0:51:55  0:10:53  0:41:02 55661\n",
      " 20  599M   20  125M    0     0   196k      0  0:52:00  0:10:54  0:41:06 48000\n",
      " 20  599M   20  125M    0     0   196k      0  0:52:03  0:10:55  0:41:08 46050\n",
      " 20  599M   20  125M    0     0   196k      0  0:52:07  0:10:56  0:41:11 38656\n",
      " 20  599M   20  125M    0     0   196k      0  0:52:10  0:10:57  0:41:13 36795\n",
      " 21  599M   21  125M    0     0   195k      0  0:52:15  0:10:58  0:41:17 35702\n",
      " 21  599M   21  126M    0     0   195k      0  0:52:19  0:10:59  0:41:20 44444\n",
      " 21  599M   21  126M    0     0   195k      0  0:52:22  0:11:00  0:41:22 41853\n",
      " 21  599M   21  126M    0     0   195k      0  0:52:25  0:11:01  0:41:24 49789\n",
      " 21  599M   21  126M    0     0   194k      0  0:52:30  0:11:02  0:41:28 44221\n",
      " 21  599M   21  126M    0     0   194k      0  0:52:32  0:11:03  0:41:29 52755\n",
      " 21  599M   21  126M    0     0   194k      0  0:52:35  0:11:04  0:41:31 52056\n",
      " 21  599M   21  126M    0     0   194k      0  0:52:38  0:11:05  0:41:33 56530\n",
      " 21  599M   21  126M    0     0   194k      0  0:52:41  0:11:06  0:41:35 62559\n",
      " 21  599M   21  126M    0     0   194k      0  0:52:44  0:11:07  0:41:37 71220\n",
      " 21  599M   21  126M    0     0   193k      0  0:52:48  0:11:08  0:41:40 64618\n",
      " 21  599M   21  126M    0     0   193k      0  0:52:51  0:11:09  0:41:42 65444\n",
      " 21  599M   21  126M    0     0   193k      0  0:52:54  0:11:10  0:41:44 69019\n",
      " 21  599M   21  126M    0     0   193k      0  0:52:57  0:11:11  0:41:46 65041\n",
      " 21  599M   21  126M    0     0   193k      0  0:53:01  0:11:12  0:41:49 62521\n",
      " 21  599M   21  126M    0     0   192k      0  0:53:04  0:11:13  0:41:51 66818\n",
      " 21  599M   21  126M    0     0   192k      0  0:53:07  0:11:14  0:41:53 62685\n",
      " 21  599M   21  126M    0     0   192k      0  0:53:10  0:11:15  0:41:55 59088\n",
      " 21  599M   21  127M    0     0   192k      0  0:53:12  0:11:16  0:41:56 72451\n",
      " 21  599M   21  127M    0     0   192k      0  0:53:14  0:11:17  0:41:57 81920\n",
      " 21  599M   21  127M    0     0   192k      0  0:53:17  0:11:18  0:41:59 85043\n",
      " 21  599M   21  127M    0     0   191k      0  0:53:20  0:11:19  0:42:01 89933\n",
      " 21  599M   21  127M    0     0   191k      0  0:53:24  0:11:20  0:42:04 88191\n",
      " 21  599M   21  127M    0     0   191k      0  0:53:25  0:11:21  0:42:04 85384\n",
      " 21  599M   21  127M    0     0   191k      0  0:53:27  0:11:22  0:42:05 88473\n",
      " 21  599M   21  127M    0     0   191k      0  0:53:30  0:11:23  0:42:07 91989\n",
      " 21  599M   21  127M    0     0   191k      0  0:53:32  0:11:24  0:42:08 95851\n",
      " 21  599M   21  127M    0     0   190k      0  0:53:35  0:11:25  0:42:10  101k\n",
      " 21  599M   21  127M    0     0   190k      0  0:53:37  0:11:26  0:42:11 98029\n",
      " 21  599M   21  127M    0     0   190k      0  0:53:40  0:11:27  0:42:13 88314\n",
      " 21  599M   21  128M    0     0   190k      0  0:53:44  0:11:28  0:42:16 76042\n",
      " 21  599M   21  128M    0     0   190k      0  0:53:47  0:11:29  0:42:18 72685\n",
      " 21  599M   21  128M    0     0   190k      0  0:53:48  0:11:30  0:42:18 79905\n",
      " 21  599M   21  128M    0     0   190k      0  0:53:50  0:11:31  0:42:19 85538\n",
      " 21  599M   21  128M    0     0   190k      0  0:53:50  0:11:32  0:42:18  112k\n",
      " 21  599M   21  128M    0     0   190k      0  0:53:50  0:11:33  0:42:17  142k\n",
      " 21  599M   21  128M    0     0   190k      0  0:53:49  0:11:34  0:42:15  172k\n",
      " 21  599M   21  129M    0     0   190k      0  0:53:48  0:11:35  0:42:13  188k\n",
      " 21  599M   21  129M    0     0   190k      0  0:53:46  0:11:36  0:42:10  225k\n",
      " 21  599M   21  129M    0     0   190k      0  0:53:47  0:11:37  0:42:10  211k\n",
      " 21  599M   21  129M    0     0   190k      0  0:53:49  0:11:38  0:42:11  200k\n",
      " 21  599M   21  129M    0     0   190k      0  0:53:51  0:11:39  0:42:12  173k\n",
      " 21  599M   21  130M    0     0   190k      0  0:53:49  0:11:40  0:42:09  182k\n",
      " 21  599M   21  130M    0     0   190k      0  0:53:46  0:11:41  0:42:05  186k\n",
      " 21  599M   21  130M    0     0   190k      0  0:53:45  0:11:42  0:42:03  207k\n",
      " 21  599M   21  130M    0     0   190k      0  0:53:48  0:11:43  0:42:05  198k\n",
      " 21  599M   21  130M    0     0   190k      0  0:53:46  0:11:44  0:42:02  233k\n",
      " 21  599M   21  131M    0     0   190k      0  0:53:43  0:11:45  0:41:58  239k\n",
      " 21  599M   21  131M    0     0   190k      0  0:53:43  0:11:46  0:41:57  214k\n",
      " 21  599M   21  131M    0     0   190k      0  0:53:42  0:11:47  0:41:55  217k\n",
      " 22  599M   22  131M    0     0   190k      0  0:53:40  0:11:48  0:41:52  260k\n",
      " 22  599M   22  132M    0     0   190k      0  0:53:36  0:11:49  0:41:47  268k\n",
      " 22  599M   22  132M    0     0   190k      0  0:53:35  0:11:50  0:41:45  259k\n",
      " 22  599M   22  132M    0     0   191k      0  0:53:32  0:11:51  0:41:41  286k\n",
      " 22  599M   22  133M    0     0   191k      0  0:53:30  0:11:52  0:41:38  289k\n",
      " 22  599M   22  133M    0     0   191k      0  0:53:28  0:11:53  0:41:35  290k\n",
      " 22  599M   22  133M    0     0   191k      0  0:53:28  0:11:54  0:41:34  262k\n",
      " 22  599M   22  133M    0     0   191k      0  0:53:28  0:11:55  0:41:33  254k\n",
      " 22  599M   22  133M    0     0   191k      0  0:53:28  0:11:56  0:41:32  225k\n",
      " 22  599M   22  134M    0     0   191k      0  0:53:30  0:11:57  0:41:33  193k\n",
      " 22  599M   22  134M    0     0   191k      0  0:53:30  0:11:58  0:41:32  173k\n",
      " 22  599M   22  134M    0     0   191k      0  0:53:31  0:11:59  0:41:32  166k\n",
      " 22  599M   22  134M    0     0   191k      0  0:53:33  0:12:00  0:41:33  144k\n",
      " 22  599M   22  134M    0     0   190k      0  0:53:35  0:12:01  0:41:34  130k\n",
      " 22  599M   22  134M    0     0   190k      0  0:53:37  0:12:02  0:41:35  133k\n",
      " 22  599M   22  134M    0     0   190k      0  0:53:38  0:12:03  0:41:35  121k\n",
      " 22  599M   22  134M    0     0   190k      0  0:53:38  0:12:04  0:41:34  128k\n",
      " 22  599M   22  135M    0     0   190k      0  0:53:40  0:12:05  0:41:35  136k\n",
      " 22  599M   22  135M    0     0   190k      0  0:53:41  0:12:06  0:41:35  137k\n",
      " 22  599M   22  135M    0     0   190k      0  0:53:41  0:12:07  0:41:34  153k\n",
      " 22  599M   22  135M    0     0   190k      0  0:53:38  0:12:08  0:41:30  193k\n",
      " 22  599M   22  135M    0     0   190k      0  0:53:38  0:12:09  0:41:29  193k\n",
      " 22  599M   22  136M    0     0   190k      0  0:53:37  0:12:10  0:41:27  212k\n",
      " 22  599M   22  136M    0     0   190k      0  0:53:35  0:12:11  0:41:24  241k\n",
      " 22  599M   22  136M    0     0   190k      0  0:53:35  0:12:12  0:41:23  239k\n",
      " 22  599M   22  136M    0     0   191k      0  0:53:34  0:12:13  0:41:21  222k\n",
      " 22  599M   22  136M    0     0   190k      0  0:53:35  0:12:14  0:41:21  218k\n",
      " 22  599M   22  137M    0     0   190k      0  0:53:37  0:12:15  0:41:22  191k\n",
      " 22  599M   22  137M    0     0   190k      0  0:53:42  0:12:16  0:41:26  139k\n",
      " 22  599M   22  137M    0     0   190k      0  0:53:43  0:12:17  0:41:26  121k\n",
      " 22  599M   22  137M    0     0   190k      0  0:53:44  0:12:18  0:41:26   99k\n",
      " 22  599M   22  137M    0     0   190k      0  0:53:44  0:12:19  0:41:25  105k\n",
      " 22  599M   22  137M    0     0   190k      0  0:53:44  0:12:20  0:41:24  131k\n",
      " 23  599M   23  137M    0     0   190k      0  0:53:42  0:12:21  0:41:21  187k\n",
      " 23  599M   23  138M    0     0   190k      0  0:53:39  0:12:22  0:41:17  224k\n",
      " 23  599M   23  138M    0     0   190k      0  0:53:36  0:12:23  0:41:13  262k\n",
      " 23  599M   23  138M    0     0   190k      0  0:53:35  0:12:24  0:41:11  272k\n",
      " 23  599M   23  139M    0     0   190k      0  0:53:35  0:12:25  0:41:10  268k\n",
      " 23  599M   23  139M    0     0   190k      0  0:53:36  0:12:26  0:41:10  248k\n",
      " 23  599M   23  139M    0     0   190k      0  0:53:36  0:12:27  0:41:09  220k\n",
      " 23  599M   23  139M    0     0   190k      0  0:53:35  0:12:28  0:41:07  204k\n",
      " 23  599M   23  139M    0     0   191k      0  0:53:34  0:12:29  0:41:05  204k\n",
      " 23  599M   23  140M    0     0   191k      0  0:53:33  0:12:30  0:41:03  205k\n",
      " 23  599M   23  140M    0     0   191k      0  0:53:33  0:12:31  0:41:02  214k\n",
      " 23  599M   23  140M    0     0   190k      0  0:53:35  0:12:32  0:41:03  197k\n",
      " 23  599M   23  140M    0     0   190k      0  0:53:35  0:12:33  0:41:02  188k\n",
      " 23  599M   23  140M    0     0   190k      0  0:53:34  0:12:34  0:41:00  184k\n",
      " 23  599M   23  140M    0     0   191k      0  0:53:33  0:12:35  0:40:58  192k\n",
      " 23  599M   23  141M    0     0   191k      0  0:53:33  0:12:36  0:40:57  195k\n",
      " 23  599M   23  141M    0     0   191k      0  0:53:32  0:12:37  0:40:55  218k\n",
      " 23  599M   23  141M    0     0   191k      0  0:53:31  0:12:38  0:40:53  231k\n",
      " 23  599M   23  141M    0     0   191k      0  0:53:30  0:12:39  0:40:51  231k\n",
      " 23  599M   23  142M    0     0   191k      0  0:53:30  0:12:40  0:40:50  223k\n",
      " 23  599M   23  142M    0     0   191k      0  0:53:31  0:12:41  0:40:50  210k\n",
      " 23  599M   23  142M    0     0   191k      0  0:53:32  0:12:42  0:40:50  188k\n",
      " 23  599M   23  142M    0     0   191k      0  0:53:33  0:12:43  0:40:50  169k\n",
      " 23  599M   23  142M    0     0   191k      0  0:53:33  0:12:44  0:40:49  164k\n",
      " 23  599M   23  142M    0     0   191k      0  0:53:33  0:12:45  0:40:48  156k\n",
      " 23  599M   23  142M    0     0   190k      0  0:53:36  0:12:46  0:40:50  145k\n",
      " 23  599M   23  142M    0     0   190k      0  0:53:37  0:12:47  0:40:50  143k\n",
      " 23  599M   23  143M    0     0   190k      0  0:53:38  0:12:48  0:40:50  143k\n",
      " 23  599M   23  143M    0     0   190k      0  0:53:38  0:12:49  0:40:49  140k\n",
      " 23  599M   23  143M    0     0   190k      0  0:53:39  0:12:50  0:40:49  136k\n",
      " 23  599M   23  143M    0     0   190k      0  0:53:39  0:12:51  0:40:48  161k\n",
      " 24  599M   24  143M    0     0   190k      0  0:53:38  0:12:52  0:40:46  189k\n",
      " 24  599M   24  144M    0     0   190k      0  0:53:37  0:12:53  0:40:44  205k\n",
      " 24  599M   24  144M    0     0   190k      0  0:53:37  0:12:54  0:40:43  203k\n",
      " 24  599M   24  144M    0     0   190k      0  0:53:36  0:12:55  0:40:41  226k\n",
      " 24  599M   24  144M    0     0   191k      0  0:53:32  0:12:56  0:40:36  253k\n",
      " 24  599M   24  145M    0     0   191k      0  0:53:27  0:12:57  0:40:30  287k\n",
      " 24  599M   24  145M    0     0   191k      0  0:53:24  0:12:58  0:40:26  307k\n",
      " 24  599M   24  145M    0     0   191k      0  0:53:23  0:12:59  0:40:24  315k\n",
      " 24  599M   24  146M    0     0   192k      0  0:53:17  0:13:00  0:40:17  368k\n",
      " 24  599M   24  147M    0     0   192k      0  0:53:06  0:13:01  0:40:05  436k\n",
      " 24  599M   24  147M    0     0   192k      0  0:53:02  0:13:02  0:40:00  425k\n",
      " 24  599M   24  147M    0     0   192k      0  0:53:01  0:13:03  0:39:58  406k\n",
      " 24  599M   24  147M    0     0   193k      0  0:52:59  0:13:04  0:39:55  425k\n",
      " 24  599M   24  148M    0     0   193k      0  0:52:56  0:13:05  0:39:51  384k\n",
      " 24  599M   24  148M    0     0   193k      0  0:52:55  0:13:06  0:39:49  296k\n",
      " 24  599M   24  148M    0     0   193k      0  0:52:52  0:13:07  0:39:45  292k\n",
      " 24  599M   24  148M    0     0   193k      0  0:52:52  0:13:08  0:39:44  277k\n",
      " 24  599M   24  149M    0     0   193k      0  0:52:50  0:13:09  0:39:41  278k\n",
      " 24  599M   24  149M    0     0   193k      0  0:52:49  0:13:10  0:39:39  263k\n",
      " 24  599M   24  149M    0     0   193k      0  0:52:48  0:13:11  0:39:37  262k\n",
      " 25  599M   25  150M    0     0   193k      0  0:52:45  0:13:12  0:39:33  262k\n",
      " 25  599M   25  150M    0     0   194k      0  0:52:40  0:13:13  0:39:27  310k\n",
      " 25  599M   25  150M    0     0   194k      0  0:52:37  0:13:14  0:39:23  319k\n",
      " 25  599M   25  151M    0     0   194k      0  0:52:37  0:13:15  0:39:22  309k\n",
      " 25  599M   25  151M    0     0   194k      0  0:52:37  0:13:16  0:39:21  303k\n",
      " 25  599M   25  151M    0     0   194k      0  0:52:33  0:13:17  0:39:16  307k\n",
      " 25  599M   25  151M    0     0   194k      0  0:52:33  0:13:18  0:39:15  262k\n",
      " 25  599M   25  152M    0     0   194k      0  0:52:32  0:13:19  0:39:13  246k\n",
      " 25  599M   25  152M    0     0   194k      0  0:52:30  0:13:20  0:39:10  265k\n",
      " 25  599M   25  152M    0     0   195k      0  0:52:25  0:13:21  0:39:04  306k\n",
      " 25  599M   25  152M    0     0   195k      0  0:52:25  0:13:22  0:39:03  281k\n",
      " 25  599M   25  153M    0     0   195k      0  0:52:25  0:13:23  0:39:02  281k\n",
      " 25  599M   25  153M    0     0   195k      0  0:52:23  0:13:24  0:38:59  280k\n",
      " 25  599M   25  153M    0     0   195k      0  0:52:21  0:13:25  0:38:56  288k\n",
      " 25  599M   25  154M    0     0   195k      0  0:52:17  0:13:26  0:38:51  278k\n",
      " 25  599M   25  154M    0     0   195k      0  0:52:17  0:13:27  0:38:50  267k\n",
      " 25  599M   25  154M    0     0   195k      0  0:52:15  0:13:28  0:38:47  294k\n",
      " 25  599M   25  154M    0     0   195k      0  0:52:16  0:13:29  0:38:47  259k\n",
      " 25  599M   25  155M    0     0   195k      0  0:52:14  0:13:30  0:38:44  265k\n",
      " 25  599M   25  155M    0     0   195k      0  0:52:14  0:13:31  0:38:43  229k\n",
      " 25  599M   25  155M    0     0   195k      0  0:52:14  0:13:32  0:38:42  227k\n",
      " 25  599M   25  155M    0     0   196k      0  0:52:12  0:13:33  0:38:39  224k\n",
      " 26  599M   26  155M    0     0   196k      0  0:52:12  0:13:34  0:38:38  240k\n",
      " 26  599M   26  156M    0     0   195k      0  0:52:13  0:13:35  0:38:38  199k\n",
      " 26  599M   26  156M    0     0   195k      0  0:52:12  0:13:36  0:38:36  208k\n",
      " 26  599M   26  156M    0     0   195k      0  0:52:13  0:13:37  0:38:36  212k\n",
      " 26  599M   26  156M    0     0   196k      0  0:52:11  0:13:38  0:38:33  204k\n",
      " 26  599M   26  156M    0     0   196k      0  0:52:10  0:13:39  0:38:31  216k\n",
      " 26  599M   26  157M    0     0   196k      0  0:52:11  0:13:40  0:38:31  220k\n",
      " 26  599M   26  157M    0     0   196k      0  0:52:11  0:13:41  0:38:30  212k\n",
      " 26  599M   26  157M    0     0   196k      0  0:52:10  0:13:42  0:38:28  223k\n",
      " 26  599M   26  157M    0     0   196k      0  0:52:12  0:13:43  0:38:29  191k\n",
      " 26  599M   26  157M    0     0   196k      0  0:52:10  0:13:44  0:38:26  194k\n",
      " 26  599M   26  158M    0     0   196k      0  0:52:08  0:13:45  0:38:23  227k\n",
      " 26  599M   26  158M    0     0   196k      0  0:52:07  0:13:46  0:38:21  238k\n",
      " 26  599M   26  158M    0     0   196k      0  0:52:06  0:13:47  0:38:19  240k\n",
      " 26  599M   26  159M    0     0   196k      0  0:52:03  0:13:48  0:38:15  282k\n",
      " 26  599M   26  159M    0     0   196k      0  0:51:59  0:13:49  0:38:10  309k\n",
      " 26  599M   26  159M    0     0   197k      0  0:51:53  0:13:50  0:38:03  348k\n",
      " 26  599M   26  160M    0     0   197k      0  0:51:46  0:13:51  0:37:55  410k\n",
      " 26  599M   26  161M    0     0   198k      0  0:51:38  0:13:52  0:37:46  482k\n",
      " 26  599M   26  161M    0     0   198k      0  0:51:30  0:13:53  0:37:37  552k\n",
      " 27  599M   27  162M    0     0   199k      0  0:51:19  0:13:54  0:37:25  626k\n",
      " 27  599M   27  163M    0     0   200k      0  0:51:09  0:13:55  0:37:14  675k\n",
      " 27  599M   27  164M    0     0   201k      0  0:50:47  0:13:56  0:36:51  838k\n",
      " 27  599M   27  165M    0     0   202k      0  0:50:33  0:13:57  0:36:36  916k\n",
      " 27  599M   27  166M    0     0   203k      0  0:50:20  0:13:58  0:36:22  966k\n",
      " 27  599M   27  167M    0     0   204k      0  0:50:09  0:13:59  0:36:10  982k\n",
      " 28  599M   28  167M    0     0   204k      0  0:50:01  0:14:00  0:36:01  962k\n",
      " 28  599M   28  168M    0     0   204k      0  0:49:55  0:14:01  0:35:54  790k\n",
      " 28  599M   28  169M    0     0   205k      0  0:49:47  0:14:02  0:35:45  726k\n",
      " 28  599M   28  169M    0     0   206k      0  0:49:35  0:14:03  0:35:32  722k\n",
      " 28  599M   28  171M    0     0   207k      0  0:49:15  0:14:04  0:35:11  825k\n",
      " 28  599M   28  172M    0     0   208k      0  0:49:00  0:14:05  0:34:55  920k\n",
      " 28  599M   28  173M    0     0   210k      0  0:48:42  0:14:06  0:34:36 1075k\n",
      " 29  599M   29  174M    0     0   211k      0  0:48:29  0:14:07  0:34:22 1145k\n",
      " 29  599M   29  175M    0     0   211k      0  0:48:22  0:14:08  0:34:14 1081k\n",
      " 29  599M   29  176M    0     0   212k      0  0:48:11  0:14:09  0:34:02  993k\n",
      " 29  599M   29  176M    0     0   212k      0  0:48:04  0:14:10  0:33:54  897k\n",
      " 29  599M   29  177M    0     0   213k      0  0:48:01  0:14:11  0:33:50  723k\n",
      " 29  599M   29  177M    0     0   213k      0  0:47:55  0:14:12  0:33:43  634k\n",
      " 29  599M   29  178M    0     0   213k      0  0:47:51  0:14:13  0:33:38  603k\n",
      " 29  599M   29  178M    0     0   214k      0  0:47:44  0:14:14  0:33:30  556k\n",
      " 29  599M   29  179M    0     0   215k      0  0:47:35  0:14:15  0:33:20  579k\n",
      " 30  599M   30  180M    0     0   215k      0  0:47:27  0:14:16  0:33:11  637k\n",
      " 30  599M   30  181M    0     0   216k      0  0:47:18  0:14:17  0:33:01  697k\n",
      " 30  599M   30  181M    0     0   216k      0  0:47:09  0:14:18  0:32:51  756k\n",
      " 30  599M   30  182M    0     0   217k      0  0:46:58  0:14:19  0:32:39  806k\n",
      " 30  599M   30  183M    0     0   218k      0  0:46:51  0:14:20  0:32:31  803k\n",
      " 30  599M   30  184M    0     0   219k      0  0:46:43  0:14:21  0:32:22  806k\n",
      " 30  599M   30  184M    0     0   219k      0  0:46:35  0:14:22  0:32:13  783k\n",
      " 31  599M   31  185M    0     0   220k      0  0:46:24  0:14:23  0:32:01  824k\n",
      " 31  599M   31  186M    0     0   221k      0  0:46:17  0:14:24  0:31:53  773k\n",
      " 31  599M   31  187M    0     0   221k      0  0:46:12  0:14:25  0:31:47  750k\n",
      " 31  599M   31  187M    0     0   221k      0  0:46:09  0:14:26  0:31:43  674k\n",
      " 31  599M   31  187M    0     0   221k      0  0:46:08  0:14:27  0:31:41  594k\n",
      " 31  599M   31  188M    0     0   222k      0  0:46:05  0:14:28  0:31:37  485k\n",
      " 31  599M   31  188M    0     0   222k      0  0:46:04  0:14:29  0:31:35  413k\n",
      " 31  599M   31  191M    0     0   224k      0  0:45:30  0:14:30  0:31:00  804k\n",
      " 32  599M   32  193M    0     0   227k      0  0:44:56  0:14:31  0:30:25 1286k\n",
      " 32  599M   32  197M    0     0   231k      0  0:44:14  0:14:32  0:29:42 1882k\n",
      " 33  599M   33  200M    0     0   235k      0  0:43:26  0:14:33  0:28:53 2597k\n",
      " 34  599M   34  205M    0     0   240k      0  0:42:37  0:14:34  0:28:03 3370k\n",
      " 34  599M   34  208M    0     0   243k      0  0:41:58  0:14:35  0:27:23 3536k\n",
      " 35  599M   35  210M    0     0   246k      0  0:41:33  0:14:36  0:26:57 3478k\n",
      " 35  599M   35  212M    0     0   248k      0  0:41:11  0:14:37  0:26:34 3238k\n",
      " 35  599M   35  215M    0     0   251k      0  0:40:45  0:14:38  0:26:07 2948k\n",
      " 36  599M   36  217M    0     0   253k      0  0:40:20  0:14:39  0:25:41 2613k\n",
      " 36  599M   36  219M    0     0   255k      0  0:40:00  0:14:40  0:25:20 2352k\n",
      " 37  599M   37  222M    0     0   258k      0  0:39:38  0:14:41  0:24:57 2334k\n",
      " 37  599M   37  224M    0     0   260k      0  0:39:19  0:14:42  0:24:37 2323k\n",
      " 37  599M   37  227M    0     0   263k      0  0:38:53  0:14:43  0:24:10 2392k\n",
      " 38  599M   38  229M    0     0   265k      0  0:38:28  0:14:44  0:23:44 2435k\n",
      " 38  599M   38  232M    0     0   268k      0  0:38:06  0:14:45  0:23:21 2512k\n",
      " 39  599M   39  235M    0     0   271k      0  0:37:41  0:14:46  0:22:55 2631k\n",
      " 39  599M   39  238M    0     0   274k      0  0:37:15  0:14:47  0:22:28 2829k\n",
      " 40  599M   40  241M    0     0   278k      0  0:36:46  0:14:48  0:21:58 2944k\n",
      " 40  599M   40  244M    0     0   281k      0  0:36:17  0:14:49  0:21:28 3112k\n",
      " 41  599M   41  247M    0     0   285k      0  0:35:53  0:14:50  0:21:03 3220k\n",
      " 41  599M   41  251M    0     0   288k      0  0:35:28  0:14:51  0:20:37 3286k\n",
      " 42  599M   42  253M    0     0   290k      0  0:35:10  0:14:52  0:20:18 3189k\n",
      " 42  599M   42  256M    0     0   294k      0  0:34:46  0:14:53  0:19:53 3149k\n",
      " 43  599M   43  259M    0     0   296k      0  0:34:27  0:14:54  0:19:33 2962k\n",
      " 43  599M   43  262M    0     0   299k      0  0:34:06  0:14:55  0:19:11 2961k\n",
      " 44  599M   44  264M    0     0   302k      0  0:33:50  0:14:56  0:18:54 2787k\n",
      " 44  599M   44  267M    0     0   305k      0  0:33:32  0:14:57  0:18:35 2819k\n",
      " 45  599M   45  270M    0     0   308k      0  0:33:09  0:14:58  0:18:11 2861k\n",
      " 45  599M   45  273M    0     0   311k      0  0:32:48  0:14:59  0:17:49 2984k\n",
      " 46  599M   46  277M    0     0   315k      0  0:32:29  0:15:00  0:17:29 3008k\n",
      " 46  599M   46  280M    0     0   318k      0  0:32:06  0:15:01  0:17:05 3233k\n",
      " 47  599M   47  283M    0     0   321k      0  0:31:50  0:15:02  0:16:48 3264k\n",
      " 47  599M   47  286M    0     0   324k      0  0:31:32  0:15:03  0:16:29 3167k\n",
      " 48  599M   48  288M    0     0   326k      0  0:31:22  0:15:04  0:16:18 2889k\n",
      " 48  599M   48  290M    0     0   328k      0  0:31:10  0:15:05  0:16:05 2723k\n",
      " 48  599M   48  293M    0     0   331k      0  0:30:54  0:15:06  0:15:48 2567k\n",
      " 49  599M   49  295M    0     0   333k      0  0:30:41  0:15:07  0:15:34 2474k\n",
      " 49  599M   49  297M    0     0   334k      0  0:30:33  0:15:08  0:15:25 2235k\n",
      " 49  599M   49  299M    0     0   337k      0  0:30:20  0:15:09  0:15:11 2352k\n",
      " 50  599M   50  301M    0     0   339k      0  0:30:08  0:15:10  0:14:58 2354k\n",
      " 50  599M   50  304M    0     0   341k      0  0:29:55  0:15:11  0:14:44 2310k\n",
      " 51  599M   51  307M    0     0   345k      0  0:29:37  0:15:12  0:14:25 2532k\n",
      " 51  599M   51  310M    0     0   348k      0  0:29:23  0:15:13  0:14:10 2745k\n",
      " 52  599M   52  313M    0     0   350k      0  0:29:11  0:15:14  0:13:57 2773k\n",
      " 52  599M   52  315M    0     0   352k      0  0:29:00  0:15:15  0:13:45 2776k\n",
      " 53  599M   53  318M    0     0   355k      0  0:28:47  0:15:16  0:13:31 2805k\n",
      " 53  599M   53  320M    0     0   357k      0  0:28:36  0:15:17  0:13:19 2592k\n",
      " 53  599M   53  322M    0     0   359k      0  0:28:27  0:15:18  0:13:09 2442k\n",
      " 54  599M   54  324M    0     0   360k      0  0:28:21  0:15:19  0:13:02 2251k\n",
      " 54  599M   54  326M    0     0   362k      0  0:28:11  0:15:20  0:12:51 2232k\n",
      " 54  599M   54  328M    0     0   365k      0  0:27:59  0:15:21  0:12:38 2224k\n",
      " 55  599M   55  331M    0     0   368k      0  0:27:46  0:15:22  0:12:24 2371k\n",
      " 55  599M   55  334M    0     0   370k      0  0:27:35  0:15:23  0:12:12 2473k\n",
      " 56  599M   56  337M    0     0   373k      0  0:27:23  0:15:24  0:11:59 2713k\n",
      " 56  599M   56  339M    0     0   375k      0  0:27:13  0:15:25  0:11:48 2739k\n",
      " 56  599M   56  341M    0     0   377k      0  0:27:05  0:15:26  0:11:39 2625k\n",
      " 57  599M   57  344M    0     0   380k      0  0:26:55  0:15:27  0:11:28 2488k\n",
      " 57  599M   57  346M    0     0   382k      0  0:26:47  0:15:28  0:11:19 2417k\n",
      " 58  599M   58  348M    0     0   383k      0  0:26:39  0:15:29  0:11:10 2289k\n",
      " 58  599M   58  350M    0     0   386k      0  0:26:29  0:15:30  0:10:59 2318k\n",
      " 58  599M   58  353M    0     0   388k      0  0:26:21  0:15:31  0:10:50 2359k\n",
      " 59  599M   59  355M    0     0   390k      0  0:26:12  0:15:32  0:10:40 2322k\n",
      " 59  599M   59  357M    0     0   392k      0  0:26:04  0:15:33  0:10:31 2327k\n",
      " 60  599M   60  360M    0     0   394k      0  0:25:54  0:15:34  0:10:20 2426k\n",
      " 60  599M   60  362M    0     0   397k      0  0:25:46  0:15:35  0:10:11 2395k\n",
      " 60  599M   60  364M    0     0   398k      0  0:25:38  0:15:36  0:10:02 2386k\n",
      " 61  599M   61  367M    0     0   401k      0  0:25:30  0:15:37  0:09:53 2406k\n",
      " 61  599M   61  369M    0     0   403k      0  0:25:23  0:15:38  0:09:45 2403k\n",
      " 62  599M   62  371M    0     0   405k      0  0:25:14  0:15:39  0:09:35 2351k\n",
      " 62  599M   62  374M    0     0   407k      0  0:25:07  0:15:40  0:09:27 2338k\n",
      " 62  599M   62  375M    0     0   408k      0  0:25:02  0:15:41  0:09:21 2220k\n",
      " 63  599M   63  378M    0     0   410k      0  0:24:53  0:15:42  0:09:11 2251k\n",
      " 63  599M   63  380M    0     0   413k      0  0:24:45  0:15:43  0:09:02 2314k\n",
      " 63  599M   63  383M    0     0   415k      0  0:24:36  0:15:44  0:08:52 2384k\n",
      " 64  599M   64  385M    0     0   417k      0  0:24:31  0:15:45  0:08:46 2299k\n",
      " 64  599M   64  387M    0     0   418k      0  0:24:26  0:15:46  0:08:40 2321k\n",
      " 64  599M   64  389M    0     0   421k      0  0:24:18  0:15:47  0:08:31 2315k\n",
      " 65  599M   65  392M    0     0   423k      0  0:24:09  0:15:48  0:08:21 2348k\n",
      " 65  599M   65  394M    0     0   425k      0  0:24:03  0:15:49  0:08:14 2246k\n",
      " 66  599M   66  396M    0     0   426k      0  0:23:58  0:15:50  0:08:08 2239k\n",
      " 66  599M   66  398M    0     0   428k      0  0:23:51  0:15:51  0:08:00 2325k\n",
      " 66  599M   66  401M    0     0   431k      0  0:23:43  0:15:52  0:07:51 2393k\n",
      " 67  599M   67  404M    0     0   434k      0  0:23:33  0:15:53  0:07:40 2516k\n",
      " 68  599M   68  407M    0     0   437k      0  0:23:22  0:15:54  0:07:28 2764k\n",
      " 68  599M   68  411M    0     0   441k      0  0:23:11  0:15:55  0:07:16 3176k\n",
      " 69  599M   69  414M    0     0   443k      0  0:23:03  0:15:56  0:07:07 3321k\n",
      " 69  599M   69  417M    0     0   446k      0  0:22:56  0:15:57  0:06:59 3269k\n",
      " 70  599M   70  419M    0     0   448k      0  0:22:48  0:15:58  0:06:50 3168k\n",
      " 70  599M   70  422M    0     0   451k      0  0:22:41  0:15:59  0:06:42 3020k\n",
      " 70  599M   70  424M    0     0   453k      0  0:22:35  0:16:00  0:06:35 2697k\n",
      " 71  599M   71  427M    0     0   455k      0  0:22:28  0:16:01  0:06:27 2654k\n",
      " 71  599M   71  430M    0     0   457k      0  0:22:20  0:16:02  0:06:18 2714k\n",
      " 72  599M   72  433M    0     0   461k      0  0:22:11  0:16:03  0:06:08 2841k\n",
      " 72  599M   72  436M    0     0   463k      0  0:22:03  0:16:04  0:05:59 2928k\n",
      " 73  599M   73  439M    0     0   466k      0  0:21:55  0:16:05  0:05:50 3080k\n",
      " 73  599M   73  442M    0     0   468k      0  0:21:50  0:16:06  0:05:44 2957k\n",
      " 74  599M   74  444M    0     0   470k      0  0:21:44  0:16:07  0:05:37 2910k\n",
      " 74  599M   74  446M    0     0   472k      0  0:21:39  0:16:08  0:05:31 2643k\n",
      " 74  599M   74  449M    0     0   474k      0  0:21:34  0:16:09  0:05:25 2483k\n",
      " 75  599M   75  451M    0     0   475k      0  0:21:30  0:16:10  0:05:20 2260k\n",
      " 75  599M   75  453M    0     0   477k      0  0:21:24  0:16:11  0:05:13 2303k\n",
      " 76  599M   76  456M    0     0   480k      0  0:21:17  0:16:12  0:05:05 2378k\n",
      " 76  599M   76  459M    0     0   483k      0  0:21:10  0:16:13  0:04:57 2554k\n",
      " 76  599M   76  461M    0     0   485k      0  0:21:05  0:16:14  0:04:51 2568k\n",
      " 77  599M   77  463M    0     0   487k      0  0:21:00  0:16:15  0:04:45 2652k\n",
      " 77  599M   77  466M    0     0   489k      0  0:20:54  0:16:16  0:04:38 2715k\n",
      " 78  599M   78  468M    0     0   491k      0  0:20:50  0:16:17  0:04:33 2573k\n",
      " 78  599M   78  470M    0     0   492k      0  0:20:45  0:16:18  0:04:27 2396k\n",
      " 79  599M   79  473M    0     0   495k      0  0:20:39  0:16:19  0:04:20 2471k\n",
      " 79  599M   79  476M    0     0   497k      0  0:20:34  0:16:20  0:04:14 2534k\n",
      " 79  599M   79  478M    0     0   499k      0  0:20:30  0:16:21  0:04:09 2419k\n",
      " 80  599M   80  480M    0     0   500k      0  0:20:25  0:16:22  0:04:03 2393k\n",
      " 80  599M   80  482M    0     0   502k      0  0:20:20  0:16:23  0:03:57 2473k\n",
      " 80  599M   80  485M    0     0   504k      0  0:20:16  0:16:24  0:03:52 2387k\n",
      " 81  599M   81  487M    0     0   507k      0  0:20:10  0:16:25  0:03:45 2384k\n",
      " 81  599M   81  488M    0     0   507k      0  0:20:10  0:16:26  0:03:44 2078k\n",
      " 81  599M   81  490M    0     0   508k      0  0:20:08  0:16:28  0:03:40 1779k\n",
      " 81  599M   81  490M    0     0   508k      0  0:20:07  0:16:28  0:03:39 1627k\n",
      " 82  599M   82  493M    0     0   511k      0  0:20:01  0:16:29  0:03:32 1735k\n",
      " 82  599M   82  497M    0     0   514k      0  0:19:54  0:16:30  0:03:24 1919k\n",
      " 83  599M   83  499M    0     0   516k      0  0:19:48  0:16:31  0:03:17 2357k\n",
      " 83  599M   83  502M    0     0   518k      0  0:19:43  0:16:32  0:03:11 2908k\n",
      " 84  599M   84  504M    0     0   520k      0  0:19:40  0:16:33  0:03:07 2822k\n",
      " 84  599M   84  507M    0     0   522k      0  0:19:34  0:16:34  0:03:00 2836k\n",
      " 85  599M   85  510M    0     0   525k      0  0:19:28  0:16:35  0:02:53 2777k\n",
      " 85  599M   85  514M    0     0   528k      0  0:19:21  0:16:36  0:02:45 2907k\n",
      " 86  599M   86  516M    0     0   530k      0  0:19:16  0:16:37  0:02:39 2927k\n",
      " 86  599M   86  519M    0     0   532k      0  0:19:12  0:16:38  0:02:34 2989k\n",
      " 87  599M   87  521M    0     0   534k      0  0:19:08  0:16:39  0:02:29 2876k\n",
      " 87  599M   87  524M    0     0   536k      0  0:19:03  0:16:40  0:02:23 2759k\n",
      " 87  599M   87  526M    0     0   538k      0  0:19:00  0:16:41  0:02:19 2547k\n",
      " 88  599M   88  529M    0     0   540k      0  0:18:55  0:16:42  0:02:13 2483k\n",
      " 88  599M   88  532M    0     0   543k      0  0:18:50  0:16:43  0:02:07 2623k\n",
      " 89  599M   89  535M    0     0   545k      0  0:18:44  0:16:44  0:02:00 2817k\n",
      " 89  599M   89  539M    0     0   549k      0  0:18:37  0:16:45  0:01:52 3049k\n",
      " 90  599M   90  542M    0     0   552k      0  0:18:32  0:16:46  0:01:46 3256k\n",
      " 90  599M   90  545M    0     0   554k      0  0:18:27  0:16:47  0:01:40 3379k\n",
      " 91  599M   91  548M    0     0   557k      0  0:18:21  0:16:48  0:01:33 3425k\n",
      " 91  599M   91  551M    0     0   559k      0  0:18:18  0:16:49  0:01:29 3201k\n",
      " 92  599M   92  553M    0     0   561k      0  0:18:13  0:16:50  0:01:23 2995k\n",
      " 92  599M   92  556M    0     0   563k      0  0:18:10  0:16:51  0:01:19 2819k\n",
      " 93  599M   93  558M    0     0   564k      0  0:18:07  0:16:52  0:01:15 2620k\n",
      " 93  599M   93  560M    0     0   566k      0  0:18:04  0:16:53  0:01:11 2370k\n",
      " 93  599M   93  562M    0     0   568k      0  0:18:00  0:16:54  0:01:06 2393k\n",
      " 94  599M   94  565M    0     0   570k      0  0:17:56  0:16:55  0:01:01 2403k\n",
      " 94  599M   94  568M    0     0   572k      0  0:17:52  0:16:56  0:00:56 2492k\n",
      " 95  599M   95  571M    0     0   575k      0  0:17:46  0:16:57  0:00:49 2736k\n",
      " 96  599M   96  575M    0     0   578k      0  0:17:40  0:16:58  0:00:42 3116k\n",
      " 96  599M   96  579M    0     0   581k      0  0:17:35  0:16:59  0:00:36 3314k\n",
      " 97  599M   97  582M    0     0   584k      0  0:17:30  0:17:00  0:00:30 3417k\n",
      " 97  599M   97  585M    0     0   587k      0  0:17:25  0:17:01  0:00:24 3501k\n",
      " 98  599M   98  588M    0     0   589k      0  0:17:20  0:17:02  0:00:18 3528k\n",
      " 98  599M   98  591M    0     0   592k      0  0:17:16  0:17:03  0:00:13 3346k\n",
      " 99  599M   99  594M    0     0   594k      0  0:17:12  0:17:04  0:00:08 3218k\n",
      " 99  599M   99  597M    0     0   596k      0  0:17:09  0:17:05  0:00:04 3052k\n",
      "100  599M  100  599M    0     0   598k      0  0:17:06  0:17:06 --:--:-- 2966k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "  0  599M    0 35081    0     0  17780      0  9:49:15  0:00:01  9:49:14 17789\n",
      "  0  599M    0  324k    0     0   112k      0  1:30:54  0:00:02  1:30:52  112k\n",
      "  0  599M    0  649k    0     0   164k      0  1:02:08  0:00:03  1:02:05  164k\n",
      "  0  599M    0 1150k    0     0   236k      0  0:43:16  0:00:04  0:43:12  236k\n",
      "  0  599M    0 1663k    0     0   281k      0  0:36:19  0:00:05  0:36:14  402k\n",
      "  0  599M    0 2462k    0     0   351k      0  0:29:04  0:00:07  0:28:57  483k\n",
      "  0  599M    0 3244k    0     0   412k      0  0:24:49  0:00:07  0:24:42  584k\n",
      "  0  599M    0 4468k    0     0   498k      0  0:20:32  0:00:08  0:20:24  760k\n",
      "  0  599M    0 5760k    0     0   581k      0  0:17:35  0:00:09  0:17:26  915k\n",
      "  1  599M    1 7391k    0     0   680k      0  0:15:02  0:00:10  0:14:52 1153k\n",
      "  1  599M    1 9407k    0     0   792k      0  0:12:54  0:00:11  0:12:43 1426k\n",
      "  1  599M    1 10.8M    0     0   859k      0  0:11:54  0:00:12  0:11:42 1564k\n",
      "  2  599M    2 12.8M    0     0   947k      0  0:10:47  0:00:13  0:10:34 1766k\n",
      "  2  599M    2 14.6M    0     0  1009k      0  0:10:07  0:00:14  0:09:53 1861k\n",
      "  2  599M    2 16.6M    0     0  1075k      0  0:09:30  0:00:15  0:09:15 1934k\n",
      "  3  599M    3 19.0M    0     0  1153k      0  0:08:51  0:00:16  0:08:35 2011k\n",
      "  3  599M    3 20.9M    0     0  1202k      0  0:08:30  0:00:17  0:08:13 2085k\n",
      "  3  599M    3 23.3M    0     0  1265k      0  0:08:05  0:00:18  0:07:47 2153k\n",
      "  4  599M    4 25.1M    0     0  1298k      0  0:07:52  0:00:19  0:07:33 2160k\n",
      "  4  599M    4 27.5M    0     0  1350k      0  0:07:34  0:00:20  0:07:14 2223k\n",
      "  5  599M    5 30.0M    0     0  1407k      0  0:07:16  0:00:21  0:06:55 2261k\n",
      "  5  599M    5 32.4M    0     0  1454k      0  0:07:02  0:00:22  0:06:40 2355k\n",
      "  5  599M    5 35.1M    0     0  1510k      0  0:06:46  0:00:23  0:06:23 2432k\n",
      "  6  599M    6 37.8M    0     0  1554k      0  0:06:34  0:00:24  0:06:10 2563k\n",
      "  6  599M    6 39.8M    0     0  1576k      0  0:06:29  0:00:25  0:06:04 2516k\n",
      "  7  599M    7 42.4M    0     0  1616k      0  0:06:19  0:00:26  0:05:53 2533k\n",
      "  7  599M    7 44.3M    0     0  1628k      0  0:06:16  0:00:27  0:05:49 2423k\n",
      "  7  599M    7 45.8M    0     0  1626k      0  0:06:17  0:00:28  0:05:49 2179k\n",
      "  7  599M    7 47.1M    0     0  1615k      0  0:06:19  0:00:29  0:05:50 1924k\n",
      "  8  599M    8 48.3M    0     0  1605k      0  0:06:22  0:00:30  0:05:52 1756k\n",
      "  8  599M    8 50.1M    0     0  1611k      0  0:06:20  0:00:31  0:05:49 1584k\n",
      "  8  599M    8 51.7M    0     0  1611k      0  0:06:20  0:00:32  0:05:48 1515k\n",
      "  8  599M    8 53.4M    0     0  1616k      0  0:06:19  0:00:33  0:05:46 1561k\n",
      "  9  599M    9 55.4M    0     0  1627k      0  0:06:17  0:00:34  0:05:43 1693k\n",
      "  9  599M    9 57.1M    0     0  1631k      0  0:06:16  0:00:35  0:05:41 1794k\n",
      "  9  599M    9 59.4M    0     0  1649k      0  0:06:12  0:00:36  0:05:36 1891k\n",
      " 10  599M   10 61.9M    0     0  1674k      0  0:06:06  0:00:37  0:05:29 2089k\n",
      " 10  599M   10 65.0M    0     0  1713k      0  0:05:58  0:00:38  0:05:20 2367k\n",
      " 11  599M   11 67.6M    0     0  1736k      0  0:05:53  0:00:39  0:05:14 2496k\n",
      " 11  599M   11 69.2M    0     0  1734k      0  0:05:53  0:00:40  0:05:13 2471k\n",
      " 11  599M   11 70.7M    0     0  1730k      0  0:05:54  0:00:41  0:05:13 2327k\n",
      " 12  599M   12 72.9M    0     0  1742k      0  0:05:52  0:00:42  0:05:10 2256k\n",
      " 12  599M   12 75.0M    0     0  1751k      0  0:05:50  0:00:43  0:05:07 2045k\n",
      " 12  599M   12 77.4M    0     0  1767k      0  0:05:47  0:00:44  0:05:03 2017k\n",
      " 13  599M   13 79.6M    0     0  1777k      0  0:05:45  0:00:45  0:05:00 2123k\n",
      " 13  599M   13 81.0M    0     0  1770k      0  0:05:46  0:00:46  0:05:00 2106k\n",
      " 13  599M   13 82.4M    0     0  1762k      0  0:05:48  0:00:47  0:05:01 1938k\n",
      " 13  599M   13 83.6M    0     0  1752k      0  0:05:50  0:00:48  0:05:02 1766k\n",
      " 14  599M   14 84.9M    0     0  1743k      0  0:05:52  0:00:49  0:05:03 1527k\n",
      " 14  599M   14 86.6M    0     0  1743k      0  0:05:52  0:00:50  0:05:02 1436k\n",
      " 14  599M   14 87.9M    0     0  1736k      0  0:05:53  0:00:51  0:05:02 1415k\n",
      " 14  599M   14 89.6M    0     0  1736k      0  0:05:53  0:00:52  0:05:01 1484k\n",
      " 15  599M   15 91.7M    0     0  1743k      0  0:05:52  0:00:53  0:04:59 1655k\n",
      " 15  599M   15 93.9M    0     0  1752k      0  0:05:50  0:00:54  0:04:56 1845k\n",
      " 15  599M   15 95.6M    0     0  1751k      0  0:05:50  0:00:55  0:04:55 1841k\n",
      " 16  599M   16 96.9M    0     0  1745k      0  0:05:51  0:00:56  0:04:55 1838k\n",
      " 16  599M   16 97.7M    0     0  1728k      0  0:05:55  0:00:57  0:04:58 1647k\n",
      " 16  599M   16 98.8M    0     0  1720k      0  0:05:56  0:00:58  0:04:58 1465k\n",
      " 16  599M   16  100M    0     0  1723k      0  0:05:56  0:00:59  0:04:57 1398k\n",
      " 17  599M   17  102M    0     0  1731k      0  0:05:54  0:01:00  0:04:54 1507k\n",
      " 17  599M   17  105M    0     0  1738k      0  0:05:53  0:01:01  0:04:52 1656k\n",
      " 17  599M   17  107M    0     0  1746k      0  0:05:51  0:01:02  0:04:49 1952k\n",
      " 18  599M   18  109M    0     0  1747k      0  0:05:51  0:01:03  0:04:48 2073k\n",
      " 18  599M   18  110M    0     0  1748k      0  0:05:51  0:01:04  0:04:47 2050k\n",
      " 18  599M   18  113M    0     0  1764k      0  0:05:47  0:01:05  0:04:42 2157k\n",
      " 19  599M   19  116M    0     0  1777k      0  0:05:45  0:01:06  0:04:39 2256k\n",
      " 19  599M   19  117M    0     0  1778k      0  0:05:45  0:01:07  0:04:38 2182k\n",
      " 19  599M   19  119M    0     0  1779k      0  0:05:44  0:01:08  0:04:36 2185k\n",
      " 20  599M   20  121M    0     0  1774k      0  0:05:45  0:01:09  0:04:36 2118k\n",
      " 20  599M   20  122M    0     0  1776k      0  0:05:45  0:01:10  0:04:35 1931k\n",
      " 20  599M   20  124M    0     0  1777k      0  0:05:45  0:01:11  0:04:34 1780k\n",
      " 21  599M   21  126M    0     0  1776k      0  0:05:45  0:01:12  0:04:33 1741k\n",
      " 21  599M   21  128M    0     0  1774k      0  0:05:45  0:01:13  0:04:32 1712k\n",
      " 21  599M   21  129M    0     0  1775k      0  0:05:45  0:01:14  0:04:31 1783k\n",
      " 21  599M   21  131M    0     0  1773k      0  0:05:46  0:01:15  0:04:31 1732k\n",
      " 22  599M   22  134M    0     0  1786k      0  0:05:43  0:01:16  0:04:27 1917k\n",
      " 22  599M   22  135M    0     0  1786k      0  0:05:43  0:01:17  0:04:26 1941k\n",
      " 23  599M   23  138M    0     0  1792k      0  0:05:42  0:01:18  0:04:24 2047k\n",
      " 23  599M   23  140M    0     0  1796k      0  0:05:41  0:01:19  0:04:22 2116k\n",
      " 23  599M   23  142M    0     0  1802k      0  0:05:40  0:01:20  0:04:20 2238k\n",
      " 24  599M   24  144M    0     0  1809k      0  0:05:39  0:01:21  0:04:18 2158k\n",
      " 24  599M   24  147M    0     0  1815k      0  0:05:38  0:01:22  0:04:16 2260k\n",
      " 24  599M   24  147M    0     0  1804k      0  0:05:40  0:01:23  0:04:17 2004k\n",
      " 24  599M   24  149M    0     0  1803k      0  0:05:40  0:01:24  0:04:16 1909k\n",
      " 25  599M   25  152M    0     0  1814k      0  0:05:38  0:01:25  0:04:13 2015k\n",
      " 25  599M   25  154M    0     0  1817k      0  0:05:37  0:01:26  0:04:11 1945k\n",
      " 26  599M   26  156M    0     0  1827k      0  0:05:35  0:01:27  0:04:08 2021k\n",
      " 26  599M   26  159M    0     0  1838k      0  0:05:33  0:01:28  0:04:05 2405k\n",
      " 27  599M   27  162M    0     0  1849k      0  0:05:31  0:01:29  0:04:02 2629k\n",
      " 27  599M   27  165M    0     0  1861k      0  0:05:29  0:01:30  0:03:59 2673k\n",
      " 28  599M   28  168M    0     0  1881k      0  0:05:26  0:01:31  0:03:55 2992k\n",
      " 28  599M   28  172M    0     0  1900k      0  0:05:23  0:01:32  0:03:51 3184k\n",
      " 29  599M   29  175M    0     0  1918k      0  0:05:19  0:01:33  0:03:46 3344k\n",
      " 29  599M   29  179M    0     0  1935k      0  0:05:17  0:01:34  0:03:43 3482k\n",
      " 30  599M   30  182M    0     0  1944k      0  0:05:15  0:01:35  0:03:40 3445k\n",
      " 30  599M   30  184M    0     0  1955k      0  0:05:13  0:01:36  0:03:37 3315k\n",
      " 31  599M   31  187M    0     0  1966k      0  0:05:12  0:01:37  0:03:35 3200k\n",
      " 31  599M   31  190M    0     0  1975k      0  0:05:10  0:01:38  0:03:32 3043k\n",
      " 32  599M   32  194M    0     0  1990k      0  0:05:08  0:01:39  0:03:29 3038k\n",
      " 32  599M   32  196M    0     0  1995k      0  0:05:07  0:01:40  0:03:27 2978k\n",
      " 33  599M   33  198M    0     0  1996k      0  0:05:07  0:01:41  0:03:26 2803k\n",
      " 33  599M   33  200M    0     0  1994k      0  0:05:07  0:01:42  0:03:25 2538k\n",
      " 33  599M   33  202M    0     0  1996k      0  0:05:07  0:01:43  0:03:24 2415k\n",
      " 34  599M   34  204M    0     0  2001k      0  0:05:06  0:01:44  0:03:22 2210k\n",
      " 34  599M   34  207M    0     0  2005k      0  0:05:06  0:01:45  0:03:21 2205k\n",
      " 34  599M   34  209M    0     0  2006k      0  0:05:05  0:01:46  0:03:19 2204k\n",
      " 35  599M   35  212M    0     0  2018k      0  0:05:04  0:01:47  0:03:17 2514k\n",
      " 35  599M   35  215M    0     0  2024k      0  0:05:03  0:01:48  0:03:15 2601k\n",
      " 36  599M   36  218M    0     0  2032k      0  0:05:02  0:01:49  0:03:13 2691k\n",
      " 36  599M   36  220M    0     0  2040k      0  0:05:00  0:01:50  0:03:10 2788k\n",
      " 37  599M   37  223M    0     0  2045k      0  0:05:00  0:01:51  0:03:09 2883k\n",
      " 37  599M   37  225M    0     0  2048k      0  0:04:59  0:01:52  0:03:07 2691k\n",
      " 38  599M   38  228M    0     0  2053k      0  0:04:58  0:01:53  0:03:05 2684k\n",
      " 38  599M   38  230M    0     0  2057k      0  0:04:58  0:01:54  0:03:04 2606k\n",
      " 38  599M   38  232M    0     0  2056k      0  0:04:58  0:01:55  0:03:03 2408k\n",
      " 39  599M   39  235M    0     0  2063k      0  0:04:57  0:01:56  0:03:01 2475k\n",
      " 39  599M   39  238M    0     0  2074k      0  0:04:55  0:01:57  0:02:58 2658k\n",
      " 40  599M   40  241M    0     0  2081k      0  0:04:54  0:01:58  0:02:56 2712k\n",
      " 40  599M   40  243M    0     0  2080k      0  0:04:55  0:01:59  0:02:56 2609k\n",
      " 40  599M   40  245M    0     0  2080k      0  0:04:55  0:02:00  0:02:55 2640k\n",
      " 41  599M   41  248M    0     0  2084k      0  0:04:54  0:02:01  0:02:53 2566k\n",
      " 41  599M   41  250M    0     0  2085k      0  0:04:54  0:02:02  0:02:52 2365k\n",
      " 42  599M   42  252M    0     0  2088k      0  0:04:53  0:02:03  0:02:50 2259k\n",
      " 42  599M   42  255M    0     0  2091k      0  0:04:53  0:02:04  0:02:49 2345k\n",
      " 42  599M   42  257M    0     0  2092k      0  0:04:53  0:02:05  0:02:48 2387k\n",
      " 43  599M   43  258M    0     0  2090k      0  0:04:53  0:02:06  0:02:47 2225k\n",
      " 43  599M   43  261M    0     0  2092k      0  0:04:53  0:02:07  0:02:46 2246k\n",
      " 43  599M   43  263M    0     0  2094k      0  0:04:53  0:02:08  0:02:45 2247k\n",
      " 44  599M   44  266M    0     0  2098k      0  0:04:52  0:02:09  0:02:43 2279k\n",
      " 44  599M   44  269M    0     0  2105k      0  0:04:51  0:02:10  0:02:41 2431k\n",
      " 45  599M   45  271M    0     0  2109k      0  0:04:50  0:02:11  0:02:39 2611k\n",
      " 45  599M   45  273M    0     0  2110k      0  0:04:50  0:02:12  0:02:38 2564k\n",
      " 46  599M   46  276M    0     0  2111k      0  0:04:50  0:02:13  0:02:37 2542k\n",
      " 46  599M   46  278M    0     0  2113k      0  0:04:50  0:02:14  0:02:36 2491k\n",
      " 46  599M   46  280M    0     0  2114k      0  0:04:50  0:02:15  0:02:35 2333k\n",
      " 47  599M   47  282M    0     0  2115k      0  0:04:50  0:02:16  0:02:34 2269k\n",
      " 47  599M   47  284M    0     0  2116k      0  0:04:50  0:02:17  0:02:33 2288k\n",
      " 47  599M   47  287M    0     0  2120k      0  0:04:49  0:02:18  0:02:31 2376k\n",
      " 48  599M   48  290M    0     0  2123k      0  0:04:49  0:02:19  0:02:30 2400k\n",
      " 48  599M   48  292M    0     0  2125k      0  0:04:48  0:02:20  0:02:28 2431k\n",
      " 49  599M   49  294M    0     0  2127k      0  0:04:48  0:02:21  0:02:27 2449k\n",
      " 49  599M   49  297M    0     0  2132k      0  0:04:47  0:02:22  0:02:25 2578k\n",
      " 50  599M   50  300M    0     0  2139k      0  0:04:46  0:02:23  0:02:23 2657k\n",
      " 50  599M   50  302M    0     0  2139k      0  0:04:46  0:02:24  0:02:22 2592k\n",
      " 50  599M   50  305M    0     0  2142k      0  0:04:46  0:02:25  0:02:21 2617k\n",
      " 51  599M   51  306M    0     0  2140k      0  0:04:46  0:02:26  0:02:20 2497k\n",
      " 51  599M   51  308M    0     0  2134k      0  0:04:47  0:02:27  0:02:20 2177k\n",
      " 51  599M   51  309M    0     0  2129k      0  0:04:48  0:02:28  0:02:20 1846k\n",
      " 51  599M   51  311M    0     0  2127k      0  0:04:48  0:02:29  0:02:19 1769k\n",
      " 52  599M   52  312M    0     0  2124k      0  0:04:48  0:02:30  0:02:18 1602k\n",
      " 52  599M   52  314M    0     0  2121k      0  0:04:49  0:02:31  0:02:18 1574k\n",
      " 52  599M   52  316M    0     0  2119k      0  0:04:49  0:02:32  0:02:17 1672k\n",
      " 53  599M   53  318M    0     0  2117k      0  0:04:49  0:02:33  0:02:16 1764k\n",
      " 53  599M   53  319M    0     0  2111k      0  0:04:50  0:02:34  0:02:16 1646k\n",
      " 53  599M   53  320M    0     0  2108k      0  0:04:51  0:02:35  0:02:16 1628k\n",
      " 53  599M   53  322M    0     0  2105k      0  0:04:51  0:02:36  0:02:15 1624k\n",
      " 54  599M   54  324M    0     0  2103k      0  0:04:51  0:02:37  0:02:14 1632k\n",
      " 54  599M   54  325M    0     0  2099k      0  0:04:52  0:02:38  0:02:14 1544k\n",
      " 54  599M   54  327M    0     0  2096k      0  0:04:52  0:02:39  0:02:13 1634k\n",
      " 54  599M   54  329M    0     0  2095k      0  0:04:52  0:02:40  0:02:12 1684k\n",
      " 55  599M   55  330M    0     0  2093k      0  0:04:53  0:02:41  0:02:12 1702k\n",
      " 55  599M   55  332M    0     0  2090k      0  0:04:53  0:02:42  0:02:11 1676k\n",
      " 55  599M   55  334M    0     0  2090k      0  0:04:53  0:02:43  0:02:10 1801k\n",
      " 56  599M   56  336M    0     0  2092k      0  0:04:53  0:02:44  0:02:09 1952k\n",
      " 56  599M   56  338M    0     0  2091k      0  0:04:53  0:02:45  0:02:08 1955k\n",
      " 56  599M   56  340M    0     0  2092k      0  0:04:53  0:02:46  0:02:07 2070k\n",
      " 57  599M   57  343M    0     0  2094k      0  0:04:53  0:02:47  0:02:06 2221k\n",
      " 57  599M   57  345M    0     0  2095k      0  0:04:52  0:02:48  0:02:04 2249k\n",
      " 58  599M   58  347M    0     0  2096k      0  0:04:52  0:02:49  0:02:03 2245k\n",
      " 58  599M   58  349M    0     0  2097k      0  0:04:52  0:02:50  0:02:02 2301k\n",
      " 58  599M   58  350M    0     0  2082k      0  0:04:54  0:02:52  0:02:02 1778k\n",
      " 58  599M   58  350M    0     0  2070k      0  0:04:56  0:02:53  0:02:03 1335k\n",
      " 58  599M   58  350M    0     0  2058k      0  0:04:58  0:02:54  0:02:04  936k\n",
      " 58  599M   58  350M    0     0  2049k      0  0:04:59  0:02:55  0:02:04  539k\n",
      " 58  599M   58  351M    0     0  2044k      0  0:05:00  0:02:55  0:02:05  258k\n",
      " 58  599M   58  352M    0     0  2041k      0  0:05:00  0:02:56  0:02:04  442k\n",
      " 59  599M   59  353M    0     0  2037k      0  0:05:01  0:02:57  0:02:04  772k\n",
      " 59  599M   59  355M    0     0  2032k      0  0:05:02  0:02:58  0:02:04 1023k\n",
      " 59  599M   59  356M    0     0  2030k      0  0:05:02  0:02:59  0:02:03 1296k\n",
      " 59  599M   59  358M    0     0  2028k      0  0:05:02  0:03:00  0:02:02 1462k\n",
      " 59  599M   59  359M    0     0  2023k      0  0:05:03  0:03:01  0:02:02 1396k\n",
      " 60  599M   60  360M    0     0  2021k      0  0:05:03  0:03:02  0:02:01 1429k\n",
      " 60  599M   60  362M    0     0  2016k      0  0:05:04  0:03:03  0:02:01 1437k\n",
      " 60  599M   60  363M    0     0  2012k      0  0:05:05  0:03:04  0:02:01 1373k\n",
      " 60  599M   60  364M    0     0  2009k      0  0:05:05  0:03:05  0:02:00 1319k\n",
      " 61  599M   61  366M    0     0  2010k      0  0:05:05  0:03:06  0:01:59 1562k\n",
      " 61  599M   61  369M    0     0  2011k      0  0:05:05  0:03:07  0:01:58 1654k\n",
      " 61  599M   61  371M    0     0  2012k      0  0:05:05  0:03:08  0:01:57 1862k\n",
      " 62  599M   62  373M    0     0  2014k      0  0:05:04  0:03:09  0:01:55 2096k\n",
      " 62  599M   62  375M    0     0  2016k      0  0:05:04  0:03:10  0:01:54 2264k\n",
      " 63  599M   63  377M    0     0  2016k      0  0:05:04  0:03:11  0:01:53 2226k\n",
      " 63  599M   63  379M    0     0  2016k      0  0:05:04  0:03:12  0:01:52 2225k\n",
      " 63  599M   63  381M    0     0  2016k      0  0:05:04  0:03:13  0:01:51 2176k\n",
      " 64  599M   64  383M    0     0  2016k      0  0:05:04  0:03:14  0:01:50 2083k\n",
      " 64  599M   64  385M    0     0  2015k      0  0:05:04  0:03:15  0:01:49 1984k\n",
      " 64  599M   64  387M    0     0  2017k      0  0:05:04  0:03:16  0:01:48 2054k\n",
      " 65  599M   65  390M    0     0  2018k      0  0:05:04  0:03:17  0:01:47 2086k\n",
      " 65  599M   65  392M    0     0  2020k      0  0:05:03  0:03:18  0:01:45 2166k\n",
      " 65  599M   65  394M    0     0  2022k      0  0:05:03  0:03:19  0:01:44 2259k\n",
      " 66  599M   66  396M    0     0  2023k      0  0:05:03  0:03:20  0:01:43 2323k\n",
      " 66  599M   66  399M    0     0  2027k      0  0:05:02  0:03:21  0:01:41 2400k\n",
      " 67  599M   67  402M    0     0  2031k      0  0:05:02  0:03:22  0:01:40 2540k\n",
      " 67  599M   67  405M    0     0  2035k      0  0:05:01  0:03:23  0:01:38 2649k\n",
      " 68  599M   68  407M    0     0  2039k      0  0:05:01  0:03:24  0:01:37 2713k\n",
      " 68  599M   68  410M    0     0  2040k      0  0:05:00  0:03:25  0:01:35 2727k\n",
      " 68  599M   68  412M    0     0  2040k      0  0:05:00  0:03:26  0:01:34 2588k\n",
      " 69  599M   69  414M    0     0  2042k      0  0:05:00  0:03:27  0:01:33 2495k\n",
      " 69  599M   69  416M    0     0  2043k      0  0:05:00  0:03:28  0:01:32 2356k\n",
      " 69  599M   69  419M    0     0  2045k      0  0:05:00  0:03:29  0:01:31 2314k\n",
      " 70  599M   70  420M    0     0  2044k      0  0:05:00  0:03:30  0:01:30 2209k\n",
      " 70  599M   70  423M    0     0  2046k      0  0:04:59  0:03:31  0:01:28 2298k\n",
      " 71  599M   71  426M    0     0  2049k      0  0:04:59  0:03:32  0:01:27 2335k\n",
      " 71  599M   71  428M    0     0  2053k      0  0:04:58  0:03:33  0:01:25 2464k\n",
      " 71  599M   71  431M    0     0  2054k      0  0:04:58  0:03:34  0:01:24 2416k\n",
      " 72  599M   72  433M    0     0  2054k      0  0:04:58  0:03:35  0:01:23 2488k\n",
      " 72  599M   72  435M    0     0  2055k      0  0:04:58  0:03:36  0:01:22 2416k\n",
      " 72  599M   72  437M    0     0  2055k      0  0:04:58  0:03:37  0:01:21 2327k\n",
      " 73  599M   73  439M    0     0  2057k      0  0:04:58  0:03:38  0:01:20 2220k\n",
      " 73  599M   73  441M    0     0  2056k      0  0:04:58  0:03:39  0:01:19 2159k\n",
      " 74  599M   74  443M    0     0  2057k      0  0:04:58  0:03:40  0:01:18 2180k\n",
      " 74  599M   74  446M    0     0  2061k      0  0:04:57  0:03:41  0:01:16 2315k\n",
      " 74  599M   74  449M    0     0  2063k      0  0:04:57  0:03:42  0:01:15 2393k\n",
      " 75  599M   75  451M    0     0  2065k      0  0:04:57  0:03:43  0:01:14 2420k\n",
      " 75  599M   75  454M    0     0  2067k      0  0:04:56  0:03:44  0:01:12 2554k\n",
      " 76  599M   76  456M    0     0  2069k      0  0:04:56  0:03:45  0:01:11 2598k\n",
      " 76  599M   76  459M    0     0  2072k      0  0:04:56  0:03:46  0:01:10 2579k\n",
      " 77  599M   77  461M    0     0  2075k      0  0:04:55  0:03:47  0:01:08 2613k\n",
      " 77  599M   77  464M    0     0  2077k      0  0:04:55  0:03:48  0:01:07 2627k\n",
      " 77  599M   77  466M    0     0  2077k      0  0:04:55  0:03:49  0:01:06 2531k\n",
      " 78  599M   78  468M    0     0  2079k      0  0:04:55  0:03:50  0:01:05 2543k\n",
      " 78  599M   78  471M    0     0  2080k      0  0:04:55  0:03:51  0:01:04 2456k\n",
      " 78  599M   78  473M    0     0  2081k      0  0:04:54  0:03:52  0:01:02 2356k\n",
      " 79  599M   79  475M    0     0  2082k      0  0:04:54  0:03:53  0:01:01 2289k\n",
      " 79  599M   79  477M    0     0  2082k      0  0:04:54  0:03:54  0:01:00 2293k\n",
      " 80  599M   80  479M    0     0  2083k      0  0:04:54  0:03:55  0:00:59 2262k\n",
      " 80  599M   80  482M    0     0  2084k      0  0:04:54  0:03:56  0:00:58 2264k\n",
      " 80  599M   80  484M    0     0  2083k      0  0:04:54  0:03:57  0:00:57 2160k\n",
      " 80  599M   80  485M    0     0  2080k      0  0:04:55  0:03:58  0:00:57 2016k\n",
      " 81  599M   81  486M    0     0  2076k      0  0:04:55  0:03:59  0:00:56 1806k\n",
      " 81  599M   81  487M    0     0  2073k      0  0:04:56  0:04:00  0:00:56 1579k\n",
      " 81  599M   81  489M    0     0  2070k      0  0:04:56  0:04:01  0:00:55 1382k\n",
      " 81  599M   81  490M    0     0  2067k      0  0:04:56  0:04:02  0:00:54 1291k\n",
      " 82  599M   82  492M    0     0  2066k      0  0:04:57  0:04:03  0:00:54 1377k\n",
      " 82  599M   82  494M    0     0  2066k      0  0:04:57  0:04:04  0:00:53 1587k\n",
      " 82  599M   82  496M    0     0  2066k      0  0:04:57  0:04:05  0:00:52 1729k\n",
      " 83  599M   83  497M    0     0  2064k      0  0:04:57  0:04:06  0:00:51 1800k\n",
      " 83  599M   83  499M    0     0  2063k      0  0:04:57  0:04:07  0:00:50 1863k\n",
      " 83  599M   83  501M    0     0  2065k      0  0:04:57  0:04:08  0:00:49 2006k\n",
      " 84  599M   84  504M    0     0  2067k      0  0:04:56  0:04:09  0:00:47 2089k\n",
      " 84  599M   84  506M    0     0  2067k      0  0:04:56  0:04:10  0:00:46 2161k\n",
      " 84  599M   84  508M    0     0  2067k      0  0:04:56  0:04:11  0:00:45 2208k\n",
      " 85  599M   85  510M    0     0  2067k      0  0:04:56  0:04:12  0:00:44 2259k\n",
      " 85  599M   85  512M    0     0  2068k      0  0:04:56  0:04:13  0:00:43 2236k\n",
      " 86  599M   86  515M    0     0  2072k      0  0:04:56  0:04:14  0:00:42 2331k\n",
      " 86  599M   86  518M    0     0  2076k      0  0:04:55  0:04:15  0:00:40 2495k\n",
      " 86  599M   86  521M    0     0  2078k      0  0:04:55  0:04:16  0:00:39 2642k\n",
      " 87  599M   87  524M    0     0  2082k      0  0:04:54  0:04:17  0:00:37 2861k\n",
      " 88  599M   88  527M    0     0  2087k      0  0:04:54  0:04:18  0:00:36 3074k\n",
      " 88  599M   88  530M    0     0  2091k      0  0:04:53  0:04:19  0:00:34 3038k\n",
      " 88  599M   88  532M    0     0  2091k      0  0:04:53  0:04:20  0:00:33 2883k\n",
      " 89  599M   89  535M    0     0  2093k      0  0:04:53  0:04:21  0:00:32 2866k\n",
      " 89  599M   89  537M    0     0  2094k      0  0:04:53  0:04:22  0:00:31 2713k\n",
      " 90  599M   90  539M    0     0  2095k      0  0:04:52  0:04:23  0:00:29 2482k\n",
      " 90  599M   90  542M    0     0  2095k      0  0:04:52  0:04:24  0:00:28 2337k\n",
      " 90  599M   90  544M    0     0  2096k      0  0:04:52  0:04:25  0:00:27 2318k\n",
      " 91  599M   91  546M    0     0  2096k      0  0:04:52  0:04:26  0:00:26 2246k\n",
      " 91  599M   91  548M    0     0  2095k      0  0:04:52  0:04:27  0:00:25 2145k\n",
      " 91  599M   91  550M    0     0  2096k      0  0:04:52  0:04:28  0:00:24 2144k\n",
      " 92  599M   92  552M    0     0  2097k      0  0:04:52  0:04:29  0:00:23 2167k\n",
      " 92  599M   92  555M    0     0  2098k      0  0:04:52  0:04:30  0:00:22 2234k\n",
      " 93  599M   93  557M    0     0  2100k      0  0:04:52  0:04:31  0:00:21 2284k\n",
      " 93  599M   93  559M    0     0  2100k      0  0:04:52  0:04:32  0:00:20 2398k\n",
      " 93  599M   93  562M    0     0  2101k      0  0:04:52  0:04:33  0:00:19 2379k\n",
      " 94  599M   94  564M    0     0  2102k      0  0:04:51  0:04:34  0:00:17 2390k\n",
      " 94  599M   94  566M    0     0  2104k      0  0:04:51  0:04:35  0:00:16 2427k\n",
      " 95  599M   95  569M    0     0  2107k      0  0:04:51  0:04:36  0:00:15 2502k\n",
      " 95  599M   95  572M    0     0  2110k      0  0:04:50  0:04:37  0:00:13 2652k\n",
      " 95  599M   95  575M    0     0  2111k      0  0:04:50  0:04:38  0:00:12 2674k\n",
      " 96  599M   96  577M    0     0  2112k      0  0:04:50  0:04:39  0:00:11 2696k\n",
      " 96  599M   96  579M    0     0  2114k      0  0:04:50  0:04:40  0:00:10 2636k\n",
      " 96  599M   96  581M    0     0  2112k      0  0:04:50  0:04:41  0:00:09 2370k\n",
      " 97  599M   97  582M    0     0  2108k      0  0:04:51  0:04:42  0:00:09 1945k\n",
      " 97  599M   97  583M    0     0  2105k      0  0:04:51  0:04:43  0:00:08 1746k\n",
      " 97  599M   97  584M    0     0  2102k      0  0:04:52  0:04:44  0:00:08 1494k\n",
      " 97  599M   97  585M    0     0  2098k      0  0:04:52  0:04:45  0:00:07 1223k\n",
      " 98  599M   98  587M    0     0  2098k      0  0:04:52  0:04:46  0:00:06 1304k\n",
      " 98  599M   98  589M    0     0  2098k      0  0:04:52  0:04:47  0:00:05 1541k\n",
      " 98  599M   98  592M    0     0  2099k      0  0:04:52  0:04:48  0:00:04 1761k\n",
      " 99  599M   99  594M    0     0  2100k      0  0:04:52  0:04:49  0:00:03 1984k\n",
      " 99  599M   99  597M    0     0  2103k      0  0:04:51  0:04:50  0:00:01 2372k\n",
      "100  599M  100  599M    0     0  2105k      0  0:04:51  0:04:51 --:--:-- 2554k\n"
     ]
    }
   ],
   "source": [
    "# !curl https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.fr.vec -o wiki_fr.vec\n",
    "# !curl https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.en.vec -o wiki_en.vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The word embeddings data for English and French words\n",
    "\n",
    "Write a program that translates English to French.\n",
    "\n",
    "## The data\n",
    "\n",
    "The full dataset for English embeddings is about 3.64 gigabytes, and the French\n",
    "embeddings are about 629 megabytes. To prevent the Coursera workspace from\n",
    "crashing, we've extracted a subset of the embeddings for the words that you'll\n",
    "use in this assignment.\n",
    "\n",
    "If you want to run this on your local computer and use the full dataset,\n",
    "you can download the\n",
    "* English embeddings from Google code archive word2vec\n",
    "[look for GoogleNews-vectors-negative300.bin.gz](https://code.google.com/archive/p/word2vec/)\n",
    "    * You'll need to unzip the file first.\n",
    "* and the French embeddings from\n",
    "[cross_lingual_text_classification](https://github.com/vjstark/crosslingual_text_classification).\n",
    "    * in the terminal, type (in one line)\n",
    "    `curl -o ./wiki.multi.fr.vec https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.fr.vec`\n",
    "\n",
    "Then copy-paste the code below and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_embeddings = KeyedVectors.load_word2vec_format('D:/Pulkit/2017 Class-XII/Jupyter/NLP - Deeplearning.ai/Week 4/wiki_en.vec')\n",
    "# fr_embeddings = KeyedVectors.load_word2vec_format('D:/Pulkit/2017 Class-XII/Jupyter/NLP - Deeplearning.ai/Week 4/wiki_fr.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.70610e-02,  2.50389e-02, -6.78157e-02,  1.03693e-01,\n",
       "       -6.84974e-02, -6.95416e-03,  5.59558e-02, -5.30692e-03,\n",
       "        8.21806e-02,  1.49233e-01,  7.40973e-02,  4.80450e-03,\n",
       "        7.64617e-02, -6.49264e-02, -3.43239e-02, -8.21211e-02,\n",
       "        5.30719e-02, -6.49805e-02, -3.73792e-02,  7.93509e-03,\n",
       "       -1.24664e-02,  1.64643e-02, -6.85190e-02, -3.42390e-02,\n",
       "       -4.44995e-02,  1.98664e-02,  1.22808e-01, -5.19547e-02,\n",
       "       -6.32979e-03,  3.57950e-02, -1.00322e-01,  1.04007e-01,\n",
       "       -3.33749e-02,  1.46350e-01,  4.06418e-02, -2.97190e-02,\n",
       "       -4.65452e-02, -1.04894e-01,  7.94104e-02, -3.25336e-02,\n",
       "        3.69372e-02,  3.87465e-02, -5.10830e-02,  1.95634e-02,\n",
       "        1.50521e-03, -4.42100e-02, -7.23335e-03, -2.86850e-02,\n",
       "        2.82576e-02, -4.31122e-02, -1.71882e-04,  1.64464e-02,\n",
       "       -9.11513e-02,  1.18101e-02, -1.05922e-01, -2.71117e-02,\n",
       "       -5.24167e-03,  4.62796e-02, -1.52225e-01,  9.19845e-02,\n",
       "       -2.66166e-02, -9.04696e-02,  1.02898e-01, -2.56459e-02,\n",
       "       -1.97008e-04,  1.42384e-02, -1.19762e-01, -3.33197e-02,\n",
       "       -1.18242e-01, -1.17241e-02, -1.60314e-01, -3.89283e-02,\n",
       "        5.75573e-03, -1.03098e-01, -6.10958e-02, -5.36033e-02,\n",
       "        1.04732e-01,  7.63697e-02,  3.69788e-02, -2.48598e-04,\n",
       "        3.92919e-02, -1.14660e-02, -6.71989e-02, -2.26880e-02,\n",
       "       -1.53583e-02,  2.65565e-02, -3.98075e-02,  3.97810e-02,\n",
       "        4.76858e-02, -1.74133e-02,  1.61791e-02, -3.78873e-02,\n",
       "        8.29056e-02, -9.32560e-02,  3.97685e-02,  7.15922e-02,\n",
       "        4.87982e-02,  4.27557e-03, -1.50884e-02, -2.54138e-02,\n",
       "        2.12082e-02, -6.79942e-02,  1.07145e-01, -4.11174e-02,\n",
       "       -1.15531e-01,  1.72942e-02, -9.38512e-02,  3.02362e-02,\n",
       "       -2.99765e-02, -4.54074e-03, -1.30416e-02,  1.29279e-03,\n",
       "       -5.71894e-02, -5.73733e-02, -3.31790e-02, -2.24391e-02,\n",
       "        3.27321e-03,  3.02427e-02, -3.85977e-02,  7.43949e-02,\n",
       "        5.12816e-02,  2.60360e-02, -3.85425e-02,  1.42097e-01,\n",
       "        3.92643e-02, -1.10072e-04,  1.00852e-01,  3.60899e-02,\n",
       "        2.98818e-02,  6.09118e-02,  2.57796e-02,  4.62503e-02,\n",
       "       -7.83933e-02,  5.30655e-03,  4.46829e-02,  2.12385e-02,\n",
       "       -5.43434e-02,  8.94470e-02, -1.66866e-02,  5.58097e-02,\n",
       "       -2.52044e-02,  6.06575e-02,  8.34088e-02, -2.72199e-02,\n",
       "        8.03627e-02,  1.23739e-01, -3.03185e-02, -3.94785e-02,\n",
       "        9.82932e-04, -8.49130e-03, -3.25822e-02, -1.03038e-01,\n",
       "       -4.06185e-02, -1.77547e-03, -4.28817e-02, -4.23775e-02,\n",
       "       -5.99109e-02, -5.06994e-02,  1.42211e-01,  5.59449e-03,\n",
       "       -5.14001e-02,  9.35752e-02, -2.91893e-02,  8.14610e-02,\n",
       "        1.23441e-01, -8.97554e-02, -4.33243e-02, -4.12543e-02,\n",
       "        7.26256e-02, -5.06567e-02, -3.53762e-02, -7.67268e-03,\n",
       "       -3.67576e-02, -2.07132e-02, -4.57266e-02,  5.99596e-02,\n",
       "        3.72267e-02,  1.04975e-01, -3.75345e-02, -2.34806e-02,\n",
       "        8.33331e-02, -5.50360e-02,  2.69364e-02, -5.41324e-03,\n",
       "       -1.82389e-02,  1.57003e-01,  1.37455e-02, -5.13563e-02,\n",
       "        5.07919e-02, -2.99868e-02, -3.21489e-02, -4.46596e-02,\n",
       "        5.08850e-02,  3.21505e-02, -1.76189e-02, -3.35545e-03,\n",
       "       -5.15483e-03,  5.00145e-02, -9.19521e-02,  2.10491e-04,\n",
       "        1.03812e-01, -1.35523e-02, -6.40824e-02,  1.50840e-02,\n",
       "       -1.84088e-02, -2.53570e-02, -4.87435e-02, -1.86214e-02,\n",
       "        1.38153e-01,  5.23621e-02,  1.12761e-01,  1.60655e-02,\n",
       "       -8.62602e-03, -1.93584e-02,  1.16646e-03,  4.34174e-02,\n",
       "       -1.69647e-02, -1.22689e-01, -6.26486e-02, -3.22354e-02,\n",
       "       -4.02652e-02, -6.96390e-02, -5.51821e-02,  3.51517e-02,\n",
       "       -3.80837e-02, -2.17130e-02, -7.97513e-02, -5.34772e-02,\n",
       "        6.28380e-02,  8.58706e-02,  3.74950e-02,  1.72580e-02,\n",
       "       -1.55488e-02, -4.57915e-02, -8.04222e-02,  6.16693e-02,\n",
       "        3.93281e-02, -3.55754e-02, -7.19385e-03,  4.60783e-02,\n",
       "        1.35550e-02,  9.12595e-03, -2.44865e-02, -2.32247e-02,\n",
       "        6.67065e-02,  7.04019e-02, -8.28894e-03, -7.54391e-02,\n",
       "        4.85671e-02,  4.44595e-02, -4.43220e-02, -6.32383e-03,\n",
       "       -6.35305e-02,  1.58215e-02, -3.56089e-02,  1.62094e-02,\n",
       "       -5.91967e-03, -9.90128e-03,  3.09374e-02,  3.70275e-02,\n",
       "        3.91025e-03,  3.11560e-03,  3.86669e-02, -4.49962e-02,\n",
       "       -8.12121e-03, -4.22346e-02,  1.80133e-03,  5.36357e-02,\n",
       "        3.31060e-02, -5.29232e-02, -7.57908e-02, -1.42319e-03,\n",
       "        1.20487e-03,  4.51758e-02, -7.75546e-02, -2.02608e-02,\n",
       "        3.33094e-02,  1.16521e-01, -1.99302e-02,  2.09004e-02,\n",
       "        7.05047e-02,  2.48582e-02,  1.49877e-02,  3.33716e-02,\n",
       "        3.40436e-02,  3.70367e-02, -1.42254e-02,  9.38295e-02,\n",
       "       -7.80253e-02, -7.10079e-03,  8.38308e-02, -5.83580e-02,\n",
       "        9.90885e-02,  7.51036e-02,  1.49168e-02, -1.89764e-02,\n",
       "       -9.64644e-03,  6.03978e-02, -3.15061e-02,  6.48020e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# en_embeddings['and']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "en_embeddings_subset = {}\n",
    "fr_embeddings_subset = {}\n",
    "french_words = set(en_fr_train.values())\n",
    "\n",
    "for en_word in en_fr_train.keys():\n",
    "    fr_word = en_fr_train[en_word]\n",
    "    if fr_embeddings.has_index_for(fr_word) and en_embeddings.has_index_for(en_word):\n",
    "        en_embeddings_subset[en_word] = en_embeddings[en_word]\n",
    "        fr_embeddings_subset[fr_word] = fr_embeddings[fr_word]\n",
    "\n",
    "\n",
    "for en_word in en_fr_test.keys():\n",
    "    fr_word = en_fr_test[en_word]\n",
    "    if fr_embeddings.has_index_for(fr_word) and en_embeddings.has_index_for(en_word):\n",
    "        en_embeddings_subset[en_word] = en_embeddings[en_word]\n",
    "        fr_embeddings_subset[fr_word] = fr_embeddings[fr_word]\n",
    "\n",
    "\n",
    "pickle.dump( en_embeddings_subset, open( \"en_embeddings.p\", \"wb\" ) )\n",
    "pickle.dump( fr_embeddings_subset, open( \"fr_embeddings.p\", \"wb\" ) )\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The subset of data\n",
    "\n",
    "To do the assignment on the Coursera workspace, we'll use the subset of word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_embeddings_subset = pickle.load(open(\"en_embeddings.p\", \"rb\"))\n",
    "fr_embeddings_subset = pickle.load(open(\"fr_embeddings.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6500, 5873)"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_embeddings_subset), len(fr_embeddings_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.0324474 , -0.0462027 , -0.00872643,  0.0993624 ,  0.0146613 ,\n",
       "        -0.0198258 , -0.0810911 , -0.0362278 ,  0.0445008 ,  0.0401815 ],\n",
       "       dtype=float32),\n",
       " array([-0.0061825 , -0.00094387, -0.00882648,  0.0324623 , -0.0218281 ,\n",
       "         0.0298912 ,  0.022999  ,  0.0280628 ,  0.00587757, -0.0256806 ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_embeddings_subset['the'][:10], fr_embeddings_subset['la'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the data\n",
    "\n",
    "* en_embeddings_subset: the key is an English word, and the vaule is a\n",
    "300 dimensional array, which is the embedding for that word.\n",
    "```\n",
    "'the': array([ 0.08007812,  0.10498047,  0.04980469,  0.0534668 , -0.06738281, ....\n",
    "```\n",
    "\n",
    "* fr_embeddings_subset: the key is an French word, and the vaule is a 300\n",
    "dimensional array, which is the embedding for that word.\n",
    "```\n",
    "'la': array([-6.18250e-03, -9.43867e-04, -8.82648e-03,  3.24623e-02,...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load two dictionaries mapping the English to French words\n",
    "* A training dictionary\n",
    "* and a testing dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(file_path, key):\n",
    "    \"\"\"\n",
    "    This function returns the english to french dictionary given a file where the each column corresponds to a word.\n",
    "    Check out the files this function takes in your workspace.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path, delimiter=' ', header=None)\n",
    "    data.columns = ['en', 'fr']\n",
    "    data.set_index(key, inplace=True)\n",
    "    \n",
    "    return data.to_dict()['en' if key=='fr' else 'fr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the English to French training dictionary is 5000\n",
      "The length of the English to French test dictionary is 1500\n"
     ]
    }
   ],
   "source": [
    "# loading the english to french dictionaries\n",
    "en_fr_train = get_dict('en-fr.train.txt', 'en')\n",
    "print('The length of the English to French training dictionary is', len(en_fr_train))\n",
    "en_fr_test = get_dict('en-fr.test.txt', 'en')\n",
    "print('The length of the English to French test dictionary is', len(en_fr_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the English French dictionary\n",
    "\n",
    "* `en_fr_train` is a dictionary where the key is the English word and the value\n",
    "is the French translation of that English word.\n",
    "```\n",
    "{'the': 'la',\n",
    " 'and': 'et',\n",
    " 'was': 'était',\n",
    " 'for': 'pour',\n",
    "```\n",
    "\n",
    "* `en_fr_test` is similar to `en_fr_train`, but is a test set.  We won't look at it\n",
    "until we get to testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Generate embedding and transform matrices\n",
    "\n",
    "#### Exercise: Translating English dictionary to French by using embeddings\n",
    "\n",
    "You will now implement a function `get_matrices`, which takes the loaded data\n",
    "and returns matrices `X` and `Y`.\n",
    "\n",
    "Inputs:\n",
    "- `en_fr` : English to French dictionary\n",
    "- `en_embeddings` : English to embeddings dictionary\n",
    "- `fr_embeddings` : French to embeddings dictionary\n",
    "\n",
    "Returns:\n",
    "- Matrix `X` and matrix `Y`, where each row in X is the word embedding for an\n",
    "english word, and the same row in Y is the word embedding for the French\n",
    "version of that English word.\n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\">\n",
    "<img src='X_to_Y.jpg' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:800px;height:200px;\" /> Figure 2 </div>\n",
    "\n",
    "Use the `en_fr` dictionary to ensure that the ith row in the `X` matrix\n",
    "corresponds to the ith row in the `Y` matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions**: Complete the function `get_matrices()`:\n",
    "* Iterate over English words in `en_fr` dictionary.\n",
    "* Check if the word have both English and French embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "    <p>\n",
    "        <ul>\n",
    "            <li><a href=\"https://realpython.com/python-sets/#set-size-and-membership\" >Sets</a> are useful data structures that can be used to check if an item is a member of a group.</li>\n",
    "            <li>You can get words which are embedded into the language by using <a href=\"https://www.w3schools.com/python/ref_dictionary_keys.asp\"> keys</a> method.</li>\n",
    "            <li>Keep vectors in `X` and `Y` sorted in list. You can use <a href=\"https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ma.vstack.html\"> np.vstack()</a> to merge them into the numpy matrix. </li>\n",
    "            <li><a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.vstack.html\">numpy.vstack</a> stacks the items in a list as rows in a matrix.</li>\n",
    "        </ul>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0324474 , -0.0462027 , -0.00872643, ...,  0.0826505 ,\n",
       "        -0.0649553 ,  0.0175795 ],\n",
       "       [-0.017061  ,  0.0250389 , -0.0678157 , ...,  0.0603978 ,\n",
       "        -0.0315061 ,  0.0064802 ],\n",
       "       [-0.0422937 , -0.00247886, -0.0445384 , ...,  0.0346122 ,\n",
       "        -0.0238589 ,  0.020346  ],\n",
       "       ...,\n",
       "       [ 0.0634232 , -0.0694376 ,  0.0112874 , ..., -0.0747475 ,\n",
       "        -0.0748488 ,  0.0294758 ],\n",
       "       [ 0.0363894 ,  0.0682363 , -0.0526155 , ...,  0.0621424 ,\n",
       "         0.0199822 ,  0.00315008],\n",
       "       [-0.00292518, -0.0410032 , -0.0422389 , ...,  0.0672043 ,\n",
       "         0.0790065 ,  0.0312828 ]], dtype=float32)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([list(en_embeddings_subset[word]) for word in en_fr_train if word in en_embeddings_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.0324474,\n",
       "  -0.0462027,\n",
       "  -0.00872643,\n",
       "  0.0993624,\n",
       "  0.0146613,\n",
       "  -0.0198258,\n",
       "  -0.0810911,\n",
       "  -0.0362278,\n",
       "  0.0445008,\n",
       "  0.0401815,\n",
       "  -0.0198814,\n",
       "  -0.117326,\n",
       "  0.0906365,\n",
       "  -0.0304146,\n",
       "  -0.0319765,\n",
       "  -0.037376,\n",
       "  -0.0248697,\n",
       "  -0.00993326,\n",
       "  0.00173625,\n",
       "  0.071948,\n",
       "  -0.0833905,\n",
       "  0.0381676,\n",
       "  -0.114113,\n",
       "  -0.0287737,\n",
       "  -0.0665892,\n",
       "  -0.0365456,\n",
       "  -0.000624522,\n",
       "  0.00978774,\n",
       "  0.0282418,\n",
       "  0.0310399,\n",
       "  -0.0772521,\n",
       "  0.0755238,\n",
       "  -0.0527877,\n",
       "  0.122521,\n",
       "  -0.0138329,\n",
       "  -0.0879198,\n",
       "  0.00357867,\n",
       "  -0.0593036,\n",
       "  0.0416396,\n",
       "  -0.0588169,\n",
       "  0.0266258,\n",
       "  -0.00114942,\n",
       "  -0.0418562,\n",
       "  0.0141145,\n",
       "  0.0388292,\n",
       "  -0.059681,\n",
       "  -0.0202956,\n",
       "  0.0444183,\n",
       "  0.0252516,\n",
       "  -0.0316458,\n",
       "  0.0351938,\n",
       "  -0.031766,\n",
       "  -0.047344,\n",
       "  0.0346892,\n",
       "  -0.024958,\n",
       "  0.0289366,\n",
       "  0.0426498,\n",
       "  0.0218352,\n",
       "  -0.0254174,\n",
       "  0.0485806,\n",
       "  -0.025182,\n",
       "  -0.0903633,\n",
       "  0.160737,\n",
       "  -0.0379248,\n",
       "  0.0230897,\n",
       "  -0.0987615,\n",
       "  -0.121324,\n",
       "  -0.092628,\n",
       "  -0.11157,\n",
       "  0.0344627,\n",
       "  -0.185628,\n",
       "  -0.0408986,\n",
       "  0.0305586,\n",
       "  -0.0653029,\n",
       "  -0.0376571,\n",
       "  -0.0301196,\n",
       "  0.0361289,\n",
       "  0.121165,\n",
       "  0.0104522,\n",
       "  -0.035387,\n",
       "  0.0552013,\n",
       "  0.0363226,\n",
       "  -0.0427432,\n",
       "  0.0555291,\n",
       "  -0.00308546,\n",
       "  -0.0830081,\n",
       "  -0.0325407,\n",
       "  0.041505,\n",
       "  -0.0461163,\n",
       "  -0.0614689,\n",
       "  -0.0411753,\n",
       "  0.00597207,\n",
       "  0.168042,\n",
       "  -0.134708,\n",
       "  0.0270638,\n",
       "  -0.0438065,\n",
       "  0.0364006,\n",
       "  0.0121269,\n",
       "  0.00179654,\n",
       "  -0.0138085,\n",
       "  -0.062492,\n",
       "  -0.0160732,\n",
       "  -0.000860326,\n",
       "  -0.0372806,\n",
       "  -0.100937,\n",
       "  -0.0582805,\n",
       "  0.00380385,\n",
       "  0.0108739,\n",
       "  -0.0067801,\n",
       "  0.0319279,\n",
       "  -0.00429016,\n",
       "  -0.0411564,\n",
       "  -0.0506422,\n",
       "  -0.0673888,\n",
       "  0.0426046,\n",
       "  -0.00305348,\n",
       "  0.0787569,\n",
       "  0.0924194,\n",
       "  0.0559314,\n",
       "  0.0449169,\n",
       "  0.136362,\n",
       "  0.113209,\n",
       "  -0.0377922,\n",
       "  0.106017,\n",
       "  0.0130159,\n",
       "  0.0348615,\n",
       "  0.0637584,\n",
       "  0.102019,\n",
       "  0.045864,\n",
       "  0.0634405,\n",
       "  -0.0869911,\n",
       "  0.0446686,\n",
       "  -0.012407,\n",
       "  0.0166697,\n",
       "  -0.060272,\n",
       "  0.0296508,\n",
       "  -0.0298062,\n",
       "  0.0690724,\n",
       "  -0.0280054,\n",
       "  0.0748583,\n",
       "  0.0474294,\n",
       "  0.0275028,\n",
       "  0.0254666,\n",
       "  0.0184317,\n",
       "  0.00850046,\n",
       "  0.111624,\n",
       "  0.0232536,\n",
       "  0.0176376,\n",
       "  0.0326713,\n",
       "  0.0471344,\n",
       "  0.066177,\n",
       "  -0.0353393,\n",
       "  -0.0386831,\n",
       "  -0.0335559,\n",
       "  -0.0354103,\n",
       "  -0.0348263,\n",
       "  0.0157385,\n",
       "  -0.0293796,\n",
       "  0.0709845,\n",
       "  0.0299031,\n",
       "  -0.0602124,\n",
       "  0.0731896,\n",
       "  -0.0344279,\n",
       "  0.0419451,\n",
       "  0.0773117,\n",
       "  0.0119258,\n",
       "  -0.0549927,\n",
       "  0.0376705,\n",
       "  0.0808378,\n",
       "  -0.0424492,\n",
       "  -0.0976788,\n",
       "  -0.0385813,\n",
       "  -0.0333711,\n",
       "  -0.0383653,\n",
       "  -0.0519533,\n",
       "  0.0641259,\n",
       "  0.00494627,\n",
       "  0.12256,\n",
       "  -0.00106191,\n",
       "  -0.0130795,\n",
       "  0.0224391,\n",
       "  0.0137877,\n",
       "  -0.0242573,\n",
       "  0.0543968,\n",
       "  -0.0163632,\n",
       "  0.119417,\n",
       "  0.0915652,\n",
       "  -0.0755138,\n",
       "  0.0565075,\n",
       "  0.0235357,\n",
       "  -0.000859482,\n",
       "  -0.0818311,\n",
       "  0.0952651,\n",
       "  0.0873189,\n",
       "  -0.0215312,\n",
       "  0.0239941,\n",
       "  -0.0271477,\n",
       "  0.0133839,\n",
       "  -0.0870209,\n",
       "  0.0596959,\n",
       "  -0.00732442,\n",
       "  -0.0229839,\n",
       "  -0.0220115,\n",
       "  0.0562194,\n",
       "  -0.00690774,\n",
       "  -0.0795863,\n",
       "  -0.0118359,\n",
       "  0.00591446,\n",
       "  0.0220542,\n",
       "  0.0509153,\n",
       "  0.117505,\n",
       "  0.0507564,\n",
       "  -0.00442912,\n",
       "  -0.0265269,\n",
       "  0.0327935,\n",
       "  -0.0524549,\n",
       "  0.049343,\n",
       "  -0.130914,\n",
       "  -0.0674385,\n",
       "  0.0147963,\n",
       "  -0.00244783,\n",
       "  -0.0163409,\n",
       "  -0.0241316,\n",
       "  0.0725539,\n",
       "  -0.0165167,\n",
       "  0.036789,\n",
       "  -0.0913616,\n",
       "  0.0197319,\n",
       "  0.001773,\n",
       "  -0.0148669,\n",
       "  0.0653923,\n",
       "  0.0911728,\n",
       "  -0.0637634,\n",
       "  -0.013522,\n",
       "  -0.027694,\n",
       "  -0.00776345,\n",
       "  0.00917837,\n",
       "  -0.047716,\n",
       "  0.00540889,\n",
       "  -0.0153352,\n",
       "  -0.0411236,\n",
       "  -0.0176694,\n",
       "  0.0874033,\n",
       "  0.0221386,\n",
       "  0.104041,\n",
       "  0.100415,\n",
       "  0.059532,\n",
       "  -0.0609971,\n",
       "  0.0649702,\n",
       "  -0.0235387,\n",
       "  0.0257209,\n",
       "  0.120822,\n",
       "  0.0129111,\n",
       "  -0.00860525,\n",
       "  -0.0846023,\n",
       "  0.110179,\n",
       "  -0.0337957,\n",
       "  -0.0553205,\n",
       "  0.0165544,\n",
       "  -0.0602025,\n",
       "  0.0128028,\n",
       "  0.0791542,\n",
       "  -0.0180503,\n",
       "  0.00456763,\n",
       "  -0.0547941,\n",
       "  -0.0393576,\n",
       "  -0.0545954,\n",
       "  0.0424899,\n",
       "  0.00484421,\n",
       "  -0.117246,\n",
       "  -0.092469,\n",
       "  -0.035676,\n",
       "  -0.0123231,\n",
       "  0.037078,\n",
       "  -0.0142381,\n",
       "  0.0156669,\n",
       "  0.0441665,\n",
       "  0.118557,\n",
       "  0.0834352,\n",
       "  -0.0292853,\n",
       "  0.0313498,\n",
       "  -0.0287121,\n",
       "  0.0095424,\n",
       "  0.00800034,\n",
       "  0.0566465,\n",
       "  -0.0370065,\n",
       "  0.0257363,\n",
       "  0.103216,\n",
       "  -0.0431097,\n",
       "  0.0543968,\n",
       "  0.0322537,\n",
       "  -0.107636,\n",
       "  -0.0187148,\n",
       "  0.0406548,\n",
       "  -0.0198114,\n",
       "  -0.0254944,\n",
       "  -0.0504833,\n",
       "  0.0826505,\n",
       "  -0.0649553,\n",
       "  0.0175795],\n",
       " [-0.0422937,\n",
       "  -0.00247886,\n",
       "  -0.0445384,\n",
       "  0.0760957,\n",
       "  -0.0241759,\n",
       "  0.0271023,\n",
       "  -0.0351552,\n",
       "  -0.0581791,\n",
       "  -0.0135616,\n",
       "  0.130505,\n",
       "  0.0868509,\n",
       "  0.0224757,\n",
       "  -0.0346984,\n",
       "  0.0345653,\n",
       "  0.00550875,\n",
       "  -0.0815182,\n",
       "  -0.0287665,\n",
       "  -0.0579206,\n",
       "  -0.0701335,\n",
       "  0.0986928,\n",
       "  -0.000275123,\n",
       "  0.0756722,\n",
       "  -0.0580405,\n",
       "  -0.0671505,\n",
       "  -0.089208,\n",
       "  0.0269723,\n",
       "  -0.0485857,\n",
       "  0.0259732,\n",
       "  0.0768751,\n",
       "  0.0772424,\n",
       "  -0.0529889,\n",
       "  0.037244,\n",
       "  -0.0731352,\n",
       "  0.0395318,\n",
       "  0.0191026,\n",
       "  -0.0567963,\n",
       "  -0.0514075,\n",
       "  -0.00401427,\n",
       "  0.129403,\n",
       "  -0.013954,\n",
       "  -0.0140304,\n",
       "  -0.0435866,\n",
       "  -0.0826012,\n",
       "  0.0548439,\n",
       "  -0.0335449,\n",
       "  -0.0711303,\n",
       "  0.0278574,\n",
       "  0.0810348,\n",
       "  -0.0187522,\n",
       "  0.0298211,\n",
       "  0.0100544,\n",
       "  0.00298177,\n",
       "  -0.0586925,\n",
       "  0.0105813,\n",
       "  -0.000224495,\n",
       "  0.00159109,\n",
       "  0.0622564,\n",
       "  0.111955,\n",
       "  0.0637066,\n",
       "  0.0451717,\n",
       "  0.0860864,\n",
       "  -0.0185622,\n",
       "  -0.0110943,\n",
       "  0.0327043,\n",
       "  0.0455502,\n",
       "  0.00373549,\n",
       "  -0.0659101,\n",
       "  0.00525954,\n",
       "  -0.116253,\n",
       "  -0.031682,\n",
       "  -0.0196445,\n",
       "  0.00994273,\n",
       "  0.00435079,\n",
       "  -0.0466182,\n",
       "  -0.0259024,\n",
       "  0.0123658,\n",
       "  -0.0558445,\n",
       "  0.0597755,\n",
       "  0.0652468,\n",
       "  -0.0722208,\n",
       "  0.0187035,\n",
       "  -0.00400302,\n",
       "  0.0900587,\n",
       "  0.0286076,\n",
       "  0.017915,\n",
       "  -0.062841,\n",
       "  -0.122129,\n",
       "  0.0305728,\n",
       "  -0.0635492,\n",
       "  -0.0526367,\n",
       "  -0.0232357,\n",
       "  -0.0672929,\n",
       "  0.0386662,\n",
       "  -0.0786627,\n",
       "  0.0364117,\n",
       "  -0.0183366,\n",
       "  -0.0512876,\n",
       "  -0.0279387,\n",
       "  -0.0575908,\n",
       "  -0.0386287,\n",
       "  -0.0414505,\n",
       "  0.086656,\n",
       "  0.0377518,\n",
       "  0.023872,\n",
       "  -0.0312938,\n",
       "  -0.0264045,\n",
       "  -0.0431594,\n",
       "  0.0727979,\n",
       "  -0.0186548,\n",
       "  -0.0136564,\n",
       "  0.073064,\n",
       "  0.0298649,\n",
       "  -0.0173454,\n",
       "  -0.021878,\n",
       "  0.0541281,\n",
       "  0.00803378,\n",
       "  0.0281565,\n",
       "  0.122987,\n",
       "  0.0202733,\n",
       "  0.0660713,\n",
       "  0.0682335,\n",
       "  0.0972013,\n",
       "  -0.065318,\n",
       "  0.164284,\n",
       "  0.0310281,\n",
       "  -0.000117082,\n",
       "  0.0106499,\n",
       "  0.0787189,\n",
       "  0.0226736,\n",
       "  0.0331139,\n",
       "  -0.0825975,\n",
       "  0.0321257,\n",
       "  0.0626948,\n",
       "  0.0186199,\n",
       "  0.0234141,\n",
       "  -0.0415742,\n",
       "  -0.0187998,\n",
       "  0.00913553,\n",
       "  -0.0543792,\n",
       "  0.11348,\n",
       "  -0.00205454,\n",
       "  -0.0260556,\n",
       "  0.0221107,\n",
       "  -0.0548589,\n",
       "  0.0306819,\n",
       "  0.0948067,\n",
       "  -0.0372987,\n",
       "  -0.0406486,\n",
       "  0.0345803,\n",
       "  0.0585351,\n",
       "  -0.000368854,\n",
       "  0.0365241,\n",
       "  -0.0170831,\n",
       "  0.0483795,\n",
       "  -0.0517897,\n",
       "  0.005867,\n",
       "  -0.0289427,\n",
       "  -0.026062,\n",
       "  0.149943,\n",
       "  -0.076047,\n",
       "  -0.0709092,\n",
       "  0.0307294,\n",
       "  -0.0528278,\n",
       "  0.0261819,\n",
       "  0.122403,\n",
       "  0.0155444,\n",
       "  0.0626498,\n",
       "  0.0391496,\n",
       "  0.130351,\n",
       "  0.0532437,\n",
       "  -0.0595619,\n",
       "  0.0280028,\n",
       "  -0.032876,\n",
       "  0.066401,\n",
       "  -0.00831821,\n",
       "  -0.0699461,\n",
       "  -0.0361546,\n",
       "  0.0429158,\n",
       "  -0.0867909,\n",
       "  -0.0185993,\n",
       "  -0.0273099,\n",
       "  0.0732101,\n",
       "  -0.0923296,\n",
       "  0.0992512,\n",
       "  -0.0643174,\n",
       "  0.0687357,\n",
       "  -0.0151704,\n",
       "  -0.0221943,\n",
       "  0.0042927,\n",
       "  0.0369472,\n",
       "  -0.0403713,\n",
       "  -0.128331,\n",
       "  0.00304611,\n",
       "  0.117681,\n",
       "  -0.00950728,\n",
       "  -0.0283877,\n",
       "  -0.0140867,\n",
       "  -0.00405212,\n",
       "  -0.0511189,\n",
       "  -0.0790637,\n",
       "  -0.0263228,\n",
       "  -0.0407198,\n",
       "  -0.101593,\n",
       "  0.0376619,\n",
       "  -0.0631557,\n",
       "  0.0129763,\n",
       "  0.00969989,\n",
       "  0.0733525,\n",
       "  0.160402,\n",
       "  0.0518197,\n",
       "  0.141676,\n",
       "  -0.06615,\n",
       "  -0.015951,\n",
       "  0.05873,\n",
       "  -0.00922584,\n",
       "  -0.0251176,\n",
       "  -0.0858503,\n",
       "  -0.0639764,\n",
       "  -0.102748,\n",
       "  0.0408959,\n",
       "  0.0714301,\n",
       "  -0.0282981,\n",
       "  -0.113589,\n",
       "  0.0146023,\n",
       "  0.0686832,\n",
       "  -0.00401277,\n",
       "  0.00678775,\n",
       "  0.0477163,\n",
       "  0.000742894,\n",
       "  0.0213125,\n",
       "  0.0154058,\n",
       "  -0.0481397,\n",
       "  -0.0350165,\n",
       "  0.0248744,\n",
       "  -0.0535997,\n",
       "  -0.0408734,\n",
       "  0.0167683,\n",
       "  0.0479224,\n",
       "  -0.0512089,\n",
       "  0.0475514,\n",
       "  -0.0110906,\n",
       "  0.0361258,\n",
       "  0.0537309,\n",
       "  0.0515686,\n",
       "  0.030113,\n",
       "  -0.0435566,\n",
       "  0.074473,\n",
       "  -0.087027,\n",
       "  0.0460524,\n",
       "  -0.0655991,\n",
       "  0.029244,\n",
       "  0.0474127,\n",
       "  0.0633843,\n",
       "  -0.0040345,\n",
       "  -0.0269295,\n",
       "  -0.0245289,\n",
       "  -0.0801691,\n",
       "  0.0188448,\n",
       "  -0.0632232,\n",
       "  0.0814995,\n",
       "  0.0442574,\n",
       "  0.0146847,\n",
       "  -0.0184985,\n",
       "  -0.0646285,\n",
       "  -0.107739,\n",
       "  0.0713439,\n",
       "  0.00479149,\n",
       "  0.042245,\n",
       "  0.0476001,\n",
       "  -0.0475326,\n",
       "  -0.11447,\n",
       "  -0.027522,\n",
       "  -0.0439463,\n",
       "  -0.00419227,\n",
       "  -0.0377443,\n",
       "  -0.128065,\n",
       "  0.13966,\n",
       "  0.113098,\n",
       "  0.0966317,\n",
       "  -0.0699611,\n",
       "  0.0402513,\n",
       "  -0.0436653,\n",
       "  -0.0341644,\n",
       "  0.0192454,\n",
       "  -0.0244854,\n",
       "  -0.0143917,\n",
       "  -0.0191836,\n",
       "  0.0927831,\n",
       "  -0.0254853,\n",
       "  -0.0781081,\n",
       "  0.0462622,\n",
       "  -0.0202411,\n",
       "  -0.100874,\n",
       "  -0.000126596,\n",
       "  -0.00823989,\n",
       "  0.0239166,\n",
       "  -0.0317892,\n",
       "  0.0346122,\n",
       "  -0.0238589,\n",
       "  0.020346]]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(x) for x in list(map(en_embeddings_subset.get, ['the', 'was']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def get_matrices(en_fr, french_vecs, english_vecs):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        en_fr: English to French dictionary\n",
    "        french_vecs: French words to their corresponding word embeddings.\n",
    "        english_vecs: English words to their corresponding word embeddings.\n",
    "    Output: \n",
    "        X: a matrix where the columns are the English embeddings.\n",
    "        Y: a matrix where the columns correspong to the French embeddings.\n",
    "        R: the projection matrix that minimizes the F norm ||X R -Y||^2.\n",
    "    \"\"\"\n",
    "    X = np.array([list(english_vecs[word]) for word in en_fr if word in english_vecs])\n",
    "    Y = np.array([list(x) for x in list(map(french_vecs.get, list(en_fr.values()))) if x is not None])\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use function `get_matrices()` to obtain sets `X_train` and `Y_train`\n",
    "of English and French word embeddings into the corresponding vector space models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = get_matrices(en_fr_train, fr_embeddings_subset, en_embeddings_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0324474 , -0.0462027 , -0.00872643,  0.0993624 ,  0.0146613 ,\n",
       "        -0.0198258 , -0.0810911 , -0.0362278 ,  0.0445008 ,  0.0401815 ],\n",
       "       [-0.017061  ,  0.0250389 , -0.0678157 ,  0.103693  , -0.0684974 ,\n",
       "        -0.00695416,  0.0559558 , -0.00530692,  0.0821806 ,  0.149233  ],\n",
       "       [-0.0422937 , -0.00247886, -0.0445384 ,  0.0760957 , -0.0241759 ,\n",
       "         0.0271023 , -0.0351552 , -0.0581791 , -0.0135616 ,  0.130505  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train)[:3, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0061825 , -0.00094387, -0.00882648,  0.0324623 , -0.0218281 ,\n",
       "         0.0298912 ,  0.022999  ,  0.0280628 ,  0.00587757, -0.0256806 ],\n",
       "       [ 0.0452279 , -0.00746001, -0.0699478 ,  0.0678657 , -0.0446425 ,\n",
       "         0.0252148 ,  0.0740176 , -0.038979  ,  0.0768492 ,  0.082898  ],\n",
       "       [-0.0341354 ,  0.042414  , -0.0656882 ,  0.0563061 ,  0.0743264 ,\n",
       "        -0.0364962 , -0.0430151 , -0.0518952 , -0.0167207 ,  0.0971362 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Y_train)[:3, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, (5000, 300), (5000, 300))"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_fr_train), X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Translations\n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='e_to_f.jpg' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:700px;height:200px;\" /> Figure 1 </div>\n",
    "\n",
    "Write a program that translates English words to French words using word embeddings and vector space models. \n",
    "\n",
    "## 2.1 Translation as linear transformation of embeddings\n",
    "\n",
    "Given dictionaries of English and French word embeddings you will create a transformation matrix `R`\n",
    "* Given an English word embedding, $\\mathbf{e}$, you can multiply $\\mathbf{eR}$ to get a new word embedding $\\mathbf{f}$.\n",
    "    * Both $\\mathbf{e}$ and $\\mathbf{f}$ are [row vectors](https://en.wikipedia.org/wiki/Row_and_column_vectors).\n",
    "* You can then compute the nearest neighbors to `f` in the french embeddings and recommend the word that is most similar to the transformed word embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describing translation as the minimization problem\n",
    "\n",
    "Find a matrix `R` that minimizes the following equation. \n",
    "\n",
    "$$\\arg \\min _{\\mathbf{R}}\\| \\mathbf{X R} - \\mathbf{Y}\\|_{F}\\tag{1} $$\n",
    "\n",
    "### Frobenius norm\n",
    "\n",
    "The Frobenius norm of a matrix $A$ (assuming it is of dimension $m,n$) is defined as the square root of the sum of the absolute squares of its elements:\n",
    "\n",
    "$$\\|\\mathbf{A}\\|_{F} \\equiv \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left|a_{i j}\\right|^{2}}\\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual loss function\n",
    "In the real world applications, the Frobenius norm loss:\n",
    "\n",
    "$$\\| \\mathbf{XR} - \\mathbf{Y}\\|_{F}$$\n",
    "\n",
    "is often replaced by it's squared value divided by $m$:\n",
    "\n",
    "$$ \\frac{1}{m} \\|  \\mathbf{X R} - \\mathbf{Y} \\|_{F}^{2}$$\n",
    "\n",
    "where $m$ is the number of examples (rows in $\\mathbf{X}$).\n",
    "\n",
    "* The same R is found when using this loss function versus the original Frobenius norm.\n",
    "* The reason for taking the square is that it's easier to compute the gradient of the squared Frobenius.\n",
    "* The reason for dividing by $m$ is that we're more interested in the average loss per embedding than the  loss for the entire training set.\n",
    "    * The loss for all training set increases with more words (training examples),\n",
    "    so taking the average helps us to track the average loss regardless of the size of the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Optional] Detailed explanation why we use norm squared instead of the norm:\n",
    "<details>\n",
    "<summary>\n",
    "    Click for optional details\n",
    "</summary>\n",
    "    <p>\n",
    "        <ul>\n",
    "            <li>The norm is always nonnegative (we're summing up absolute values), and so is the square. \n",
    "            <li> When we take the square of all non-negative (positive or zero) numbers, the order of the data is preserved.  \n",
    "            <li> For example, if 3 > 2, 3^2 > 2^2\n",
    "            <li> Using the norm or squared norm in gradient descent results in the same <i>location</i> of the minimum.\n",
    "            <li> Squaring cancels the square root in the Frobenius norm formula. Because of the <a href=\"https://en.wikipedia.org/wiki/Chain_rule\"> chain rule</a>, we would have to do more calculations if we had a square root in our expression for summation.\n",
    "            <li> Dividing the function value by the positive number doesn't change the optimum of the function, for the same reason as described above.\n",
    "            <li> We're interested in transforming English embedding into the French. Thus, it is more important to measure average loss per embedding than the loss for the entire dictionary (which increases as the number of words in the dictionary increases).\n",
    "        </ul>\n",
    "    </p>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Implementing translation mechanism described in this section.\n",
    "\n",
    "#### Step 1: Computing the loss\n",
    "* The loss function will be squared Frobenoius norm of the difference between\n",
    "matrix and its approximation, divided by the number of training examples $m$.\n",
    "* Its formula is:\n",
    "$$ L(X, Y, R)=\\frac{1}{m}\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left( a_{i j} \\right)^{2}$$\n",
    "\n",
    "where $a_{i j}$ is value in $i$th row and $j$th column of the matrix $\\mathbf{XR}-\\mathbf{Y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions: complete the `compute_loss()` function\n",
    "\n",
    "* Compute the approximation of `Y` by matrix multiplying `X` and `R`\n",
    "* Compute difference `XR - Y`\n",
    "* Compute the squared Frobenius norm of the difference and divide it by $m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "   <li> Useful functions:\n",
    "       <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html\">Numpy dot </a>,\n",
    "       <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html\">Numpy sum</a>,\n",
    "       <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.square.html\">Numpy square</a>,\n",
    "       <a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html\">Numpy norm</a>\n",
    "    </li>\n",
    "   <li> Be careful about which operation is elementwise and which operation is a matrix multiplication.</li>\n",
    "   <li> Try to use matrix operations instead of the numpy norm function.  If you choose to use norm function, take care of extra arguments and that it's returning loss squared, and not the loss itself.</li>\n",
    "\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X, Y, R):\n",
    "    '''\n",
    "    Inputs: \n",
    "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
    "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
    "        R: a matrix of dimension (n,n) - transformation matrix from English to French vector space embeddings.\n",
    "    Outputs:\n",
    "        L: the value of the loss function for given X, Y and R.\n",
    "    '''\n",
    "    return round(np.power(np.matmul(X, R) - Y, 2).sum() / Y.shape[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(np.array([[1,0],[1,0]]), np.array([[0,1],[0,1]]), np.array([[1,0],[0,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Computing the gradient of loss in respect to transform matrix R\n",
    "\n",
    "* Calculate the gradient of the loss with respect to transform matrix `R`.\n",
    "* The gradient is a matrix that encodes how much a small change in `R`\n",
    "affect the change in the loss function.\n",
    "* The gradient gives us the direction in which we should decrease `R`\n",
    "to minimize the loss.\n",
    "* $m$ is the number of training examples (number of rows in $X$).\n",
    "* The formula for the gradient of the loss function $𝐿(𝑋,𝑌,𝑅)$ is:\n",
    "\n",
    "$$\\frac{d}{dR}𝐿(𝑋,𝑌,𝑅)=\\frac{d}{dR}\\Big(\\frac{1}{m}\\| X R -Y\\|_{F}^{2}\\Big) = \\frac{2}{m}X^{T} (X R - Y)$$\n",
    "\n",
    "**Instructions**: Complete the `compute_gradient` function below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "    <ul>\n",
    "    <li><a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.T.html\" > Transposing in numpy </a></li>\n",
    "    <li><a href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html\" > Finding out the dimensions</a> of matrices in numpy </li>\n",
    "    <li>Remember to use numpy.dot for matrix multiplication </li>\n",
    "    </ul>\n",
    "</p>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, Y, R):\n",
    "    '''\n",
    "    Inputs: \n",
    "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
    "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
    "        R: a matrix of dimension (n,n) - transformation matrix from English to French vector space embeddings.\n",
    "    Outputs:\n",
    "        g: a matrix of dimension (n,n) - gradient of the loss function L for given X, Y and R.\n",
    "    '''\n",
    "    return 2/Y.shape[0] * np.matmul(X.T, (np.matmul(X,R) - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.],\n",
       "       [ 0., -0.]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_gradient(np.array([[1,0],[1,0]]), np.array([[0,1],[0,1]]), np.array([[1,0],[0,0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Finding the optimal R with gradient descent algorithm\n",
    "\n",
    "#### Gradient descent\n",
    "\n",
    "[Gradient descent](https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html) is an iterative algorithm which is used in searching for the optimum of the function. \n",
    "* Earlier, we've mentioned that the gradient of the loss with respect to the matrix encodes how much a tiny change in some coordinate of that matrix affect the change of loss function.\n",
    "* Gradient descent uses that information to iteratively change matrix `R` until we reach a point where the loss is minimized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with a fixed number of iterations\n",
    "\n",
    "Most of the time we iterate for a fixed number of training steps rather than iterating until the loss falls below a threshold.\n",
    "\n",
    "##### OPTIONAL: explanation for fixed number of iterations\n",
    "<details>\n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>click here for detailed discussion</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> You cannot rely on training loss getting low -- what you really want is the validation loss to go down, or validation accuracy to go up. And indeed - in some cases people train until validation accuracy reaches a threshold, or -- commonly known as \"early stopping\" -- until the validation accuracy starts to go down, which is a sign of over-fitting.\n",
    "    </li>\n",
    "    <li>\n",
    "    Why not always do \"early stopping\"? Well, mostly because well-regularized models on larger data-sets never stop improving. Especially in NLP, you can often continue training for months and the model will continue getting slightly and slightly better. This is also the reason why it's hard to just stop at a threshold -- unless there's an external customer setting the threshold, why stop, where do you put the threshold?\n",
    "    </li>\n",
    "    <li>Stopping after a certain number of steps has the advantage that you know how long your training will take - so you can keep some sanity and not train for months. You can then try to get the best performance within this time budget. Another advantage is that you can fix your learning rate schedule -- e.g., lower the learning rate at 10% before finish, and then again more at 1% before finishing. Such learning rate schedules help a lot, but are harder to do if you don't know how long you're training.\n",
    "    </li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudocode:\n",
    "1. Calculate gradient $g$ of the loss with respect to the matrix $R$.\n",
    "2. Update $R$ with the formula:\n",
    "$$R_{\\text{new}}= R_{\\text{old}}-\\alpha g$$\n",
    "\n",
    "Where $\\alpha$ is the learning rate, which is a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate\n",
    "\n",
    "* The learning rate or \"step size\" $\\alpha$ is a coefficient which decides how much we want to change $R$ in each step.\n",
    "* If we change $R$ too much, we could skip the optimum by taking too large of a step.\n",
    "* If we make only small changes to $R$, we will need many steps to reach the optimum.\n",
    "* Learning rate $\\alpha$ is used to control those changes.\n",
    "* Values of $\\alpha$ are chosen depending on the problem, and we'll use `learning_rate`$=0.0003$ as the default value for our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions: Implement `align_embeddings()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>Use the 'compute_gradient()' function to get the gradient in each step</li>\n",
    "\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_embeddings(X, Y, train_steps=100, learning_rate=0.0003, random_state=56):\n",
    "    '''\n",
    "    Inputs:\n",
    "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
    "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
    "        train_steps: positive int - describes how many steps will gradient descent algorithm do.\n",
    "        learning_rate: positive float - describes how big steps will  gradient descent algorithm do.\n",
    "    Outputs:\n",
    "        R: a matrix of dimension (n,n) - the projection matrix that minimizes the F norm ||X R -Y||^2\n",
    "    '''\n",
    "    np.random.seed(random_state)\n",
    "    R = np.random.rand(X.shape[1], X.shape[1])\n",
    "    \n",
    "    for i in range(train_steps):\n",
    "        if i%25 == 0:\n",
    "            print(f'loss at iteration {i} is: {compute_loss(X, Y, R)}')\n",
    "        R = R - learning_rate * compute_gradient(X, Y, R)\n",
    "    print(f'loss at iteration {i} is: {compute_loss(X, Y, R)}')\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iteration 0 is: 5.1591\n",
      "loss at iteration 25 is: 5.0231\n",
      "loss at iteration 50 is: 4.8907\n",
      "loss at iteration 75 is: 4.7618\n",
      "loss at iteration 99 is: 4.6365\n"
     ]
    }
   ],
   "source": [
    "# Testing the implementation.\n",
    "np.random.seed(129)\n",
    "m = 10\n",
    "n = 5\n",
    "X = np.random.rand(m, n)\n",
    "Y = np.random.rand(m, n) * .1\n",
    "R = align_embeddings(X, Y, random_state=79)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "loss at iteration 0 is: 3.7242\n",
    "loss at iteration 25 is: 3.6283\n",
    "loss at iteration 50 is: 3.5350\n",
    "loss at iteration 75 is: 3.4442\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate transformation matrix R\n",
    "\n",
    "Using those the training set, find the transformation matrix $\\mathbf{R}$ by calling the function `align_embeddings()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iteration 0 is: 101.0315\n",
      "loss at iteration 25 is: 40.8758\n",
      "loss at iteration 50 is: 24.0417\n",
      "loss at iteration 75 is: 15.308\n",
      "loss at iteration 100 is: 10.2322\n",
      "loss at iteration 125 is: 7.0957\n",
      "loss at iteration 150 is: 5.0755\n",
      "loss at iteration 175 is: 3.7335\n",
      "loss at iteration 200 is: 2.8204\n",
      "loss at iteration 225 is: 2.1866\n",
      "loss at iteration 250 is: 1.7395\n",
      "loss at iteration 275 is: 1.4196\n",
      "loss at iteration 300 is: 1.1878\n",
      "loss at iteration 325 is: 1.0179\n",
      "loss at iteration 350 is: 0.8922\n",
      "loss at iteration 375 is: 0.7983\n",
      "loss at iteration 399 is: 0.7276\n"
     ]
    }
   ],
   "source": [
    "R_train = align_embeddings(X_train, Y_train, train_steps=400, learning_rate=2, random_state=np.random.randint(1,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "\n",
    "```\n",
    "loss at iteration 0 is: 963.0146\n",
    "loss at iteration 25 is: 97.8292\n",
    "loss at iteration 50 is: 26.8329\n",
    "loss at iteration 75 is: 9.7893\n",
    "loss at iteration 100 is: 4.3776\n",
    "loss at iteration 125 is: 2.3281\n",
    "loss at iteration 150 is: 1.4480\n",
    "loss at iteration 175 is: 1.0338\n",
    "loss at iteration 200 is: 0.8251\n",
    "loss at iteration 225 is: 0.7145\n",
    "loss at iteration 250 is: 0.6534\n",
    "loss at iteration 275 is: 0.6185\n",
    "loss at iteration 300 is: 0.5981\n",
    "loss at iteration 325 is: 0.5858\n",
    "loss at iteration 350 is: 0.5782\n",
    "loss at iteration 375 is: 0.5735\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Testing the translation\n",
    "\n",
    "### k-Nearest neighbors algorithm\n",
    "\n",
    "[k-Nearest neighbors algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) \n",
    "* k-NN is a method which takes a vector as input and finds the other vectors in the dataset that are closest to it. \n",
    "* The 'k' is the number of \"nearest neighbors\" to find (e.g. k=2 finds the closest two neighbors).\n",
    "\n",
    "### Searching for the translation embedding\n",
    "Since we're approximating the translation function from English to French embeddings by a linear transformation matrix $\\mathbf{R}$, most of the time we won't get the exact embedding of a French word when we transform embedding $\\mathbf{e}$ of some particular English word into the French embedding space. \n",
    "* This is where $k$-NN becomes really useful! By using $1$-NN with $\\mathbf{eR}$ as input, we can search for an embedding $\\mathbf{f}$ (as a row) in the matrix $\\mathbf{Y}$ which is the closest to the transformed vector $\\mathbf{eR}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity\n",
    "Cosine similarity between vectors $u$ and $v$ calculated as the cosine of the angle between them.\n",
    "The formula is \n",
    "\n",
    "$$\\cos(u,v)=\\frac{u\\cdot v}{\\left\\|u\\right\\|\\left\\|v\\right\\|}$$\n",
    "\n",
    "* $\\cos(u,v)$ = $1$ when $u$ and $v$ lie on the same line and have the same direction.\n",
    "* $\\cos(u,v)$ is $-1$ when they have exactly opposite directions.\n",
    "* $\\cos(u,v)$ is $0$ when the vectors are orthogonal (perpendicular) to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Distance and similarity are pretty much opposite things.\n",
    "* We can obtain distance metric from cosine similarity, but the cosine similarity can't be used directly as the distance metric. \n",
    "* When the cosine similarity increases (towards $1$), the \"distance\" between the two vectors decreases (towards $0$). \n",
    "* We can define the cosine distance between $u$ and $v$ as\n",
    "$$d_{\\text{cos}}(u,v)=1-\\cos(u,v)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Complete the function `nearest_neighbor()`\n",
    "\n",
    "Inputs:\n",
    "* Vector `v`,\n",
    "* A set of possible nearest neighbors `candidates`\n",
    "* `k` nearest neighbors to find.\n",
    "* The distance metric should be based on cosine similarity.\n",
    "* `cosine_similarity` function is already implemented and imported for you. It's arguments are two vectors and it returns the cosine of the angle between them.\n",
    "* Iterate over rows in `candidates`, and save the result of similarities between current row and vector `v` in a python list. Take care that similarities are in the same order as row vectors of `candidates`.\n",
    "* Now you can use [numpy argsort]( https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html#numpy.argsort) to sort the indices for the rows of `candidates`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> numpy.argsort sorts values from most negative to most positive (smallest to largest) </li>\n",
    "    <li> The candidates that are nearest to 'v' should have the highest cosine similarity </li>\n",
    "    <li> To get the last element of a list 'tmp', the notation is tmp[-1:] </li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x,y) / (np.linalg.norm(x) * np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C8 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def nearest_neighbor(v, candidates, k=1):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      - v, the vector you are going to find the nearest neighbor for\n",
    "      - candidates: a set of vectors where we will find the neighbors\n",
    "      - k: top k nearest neighbors to find\n",
    "    Output:\n",
    "      - k_idx: the indices of the top k closest vectors in descending sorted form\n",
    "    \"\"\"\n",
    "    scores = np.array([cosine_similarity(v, candidate) for candidate in candidates])\n",
    "    #k_idx = np.sort(scores)[::-1][:k]\n",
    "    k_idx = np.argsort(scores)[-k:][::-1]\n",
    "    \n",
    "    return k_idx\n",
    "    #[np.where(score == scores)[0][0] for score in k_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbor(v, candidates, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 1]\n",
      " [1 0 5]\n",
      " [9 9 9]]\n"
     ]
    }
   ],
   "source": [
    "v = np.array([1, 0, 1])\n",
    "candidates = np.array([[1, 0, 5], [-2, 5, 3], [2, 0, 1], [6, -9, 5], [9, 9, 9]])\n",
    "print(candidates[nearest_neighbor(v, candidates, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.quiver([0]*5,[0]*5,[0]*5, candidates[:, 0], candidates[:,1], candidates[:,2], color=['black','g','b','y','c'], linewidths=0.5)\n",
    "ax.quiver(0,0,0,v[0],v[1],v[2],color='r', linewidths=1)\n",
    "\n",
    "ax.set_xlim([-5, 10])\n",
    "ax.set_ylim([-10, 10])\n",
    "ax.set_zlim([0, 10])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your translation and compute its accuracy\n",
    "\n",
    "**Exercise**:\n",
    "Complete the function `test_vocabulary` which takes in English\n",
    "embedding matrix $X$, French embedding matrix $Y$ and the $R$\n",
    "matrix and returns the accuracy of translations from $X$ to $Y$ by $R$.\n",
    "\n",
    "* Iterate over transformed English word embeddings and check if the\n",
    "closest French word vector belongs to French word that is the actual\n",
    "translation.\n",
    "* Obtain an index of the closest French embedding by using\n",
    "`nearest_neighbor` (with argument `k=1`), and compare it to the index\n",
    "of the English embedding you have just transformed.\n",
    "* Keep track of the number of times you get the correct translation.\n",
    "* Calculate accuracy as $$\\text{accuracy}=\\frac{\\#(\\text{correct predictions})}{\\#(\\text{total predictions})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C10 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def test_vocabulary(X, Y, R):\n",
    "    '''\n",
    "    Input:\n",
    "        X: a matrix where the columns are the English embeddings.\n",
    "        Y: a matrix where the columns correspong to the French embeddings.\n",
    "        R: the transform matrix which translates word embeddings from\n",
    "        English to French word vector space.\n",
    "    Output:\n",
    "        accuracy: for the English to French capitals\n",
    "    '''\n",
    "    pred = np.matmul(X, R)\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        if nearest_neighbor(pred[i], Y) == i:\n",
    "            count += 1\n",
    "    \n",
    "    return round(count/Y.shape[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C10 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def test_vocabulary(X, Y, R):\n",
    "    '''\n",
    "    Input:\n",
    "        X: a matrix where the columns are the English embeddings.\n",
    "        Y: a matrix where the columns correspong to the French embeddings.\n",
    "        R: the transform matrix which translates word embeddings from\n",
    "        English to French word vector space.\n",
    "    Output:\n",
    "        accuracy: for the English to French capitals\n",
    "    '''\n",
    "    pred = np.dot(X, R)\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        if nearest_neighbor(pred[i], Y)[0] == i:\n",
    "            count += 1\n",
    "    \n",
    "    return round(count/Y.shape[0], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how is your translation mechanism working on the unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = get_matrices(en_fr_test, fr_embeddings_subset, en_embeddings_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, (1500, 300), (1500, 300))"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_fr_test), X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set is 0.726\n",
      "CPU times: total: 56.9 s\n",
      "Wall time: 56.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "acc = test_vocabulary(X_val, Y_val, R_train)  # this might take a minute or two\n",
    "print(f\"accuracy on test set is {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "```\n",
    "0.557\n",
    "```\n",
    "\n",
    "You managed to translate words from one language to another language\n",
    "without ever seing them with almost 56% accuracy by using some basic\n",
    "linear algebra and learning a mapping of words from one language to another!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LSH and document search\n",
    "\n",
    "In this part of the assignment, you will implement a more efficient version\n",
    "of k-nearest neighbors using locality sensitive hashing.\n",
    "You will then apply this to document search.\n",
    "\n",
    "* Process the tweets and represent each tweet as a vector (represent a\n",
    "document with a vector embedding).\n",
    "* Use locality sensitive hashing and k nearest neighbors to find tweets\n",
    "that are similar to a given tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "all_tweets = all_positive_tweets + all_negative_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Getting the document embeddings\n",
    "\n",
    "#### Bag-of-words (BOW) document models\n",
    "Text documents are sequences of words.\n",
    "* The ordering of words makes a difference. For example, sentences \"Apple pie is\n",
    "better than pepperoni pizza.\" and \"Pepperoni pizza is better than apple pie\"\n",
    "have opposite meanings due to the word ordering.\n",
    "* However, for some applications, ignoring the order of words can allow\n",
    "us to train an efficient and still effective model.\n",
    "* This approach is called Bag-of-words document model.\n",
    "\n",
    "#### Document embeddings\n",
    "* Document embedding is created by summing up the embeddings of all words\n",
    "in the document.\n",
    "* If we don't know the embedding of some word, we can ignore that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "Complete the `get_document_embedding()` function.\n",
    "* The function `get_document_embedding()` encodes entire document as a \"document\" embedding.\n",
    "* It takes in a docoument (as a string) and a dictionary, `en_embeddings`\n",
    "* It processes the document, and looks up the corresponding embedding of each word.\n",
    "* It then sums them up and returns the sum of all word vectors of that processed tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> You can handle missing words easier by using the `get()` method of the python dictionary instead of the bracket notation (i.e. \"[ ]\"). See more about it <a href=\"https://stackoverflow.com/a/11041421/12816433\" >here</a> </li>\n",
    "    <li> The default value for missing word should be the zero vector. Numpy will <a href=\"https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html\" > broadcast </a> simple 0 scalar into a vector of zeros during the summation.</li>\n",
    "    <li>Alternatively, skip the addition if a word is not in the dictonary. </li>\n",
    "    <li>  You can use your `process_tweet()` function which allows you to process the tweet. The function just takes in a tweet and returns a list of words.</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \"\"\"Process tweet function.\n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "    Output:\n",
    "        tweets_clean: a list of words containing the processed tweet\n",
    "\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_embedding(tweet, en_embeddings): \n",
    "    '''\n",
    "    Input:\n",
    "        - tweet: a string\n",
    "        - en_embeddings: a dictionary of word embeddings\n",
    "    Output:\n",
    "        - tweet_embedding: a\n",
    "    '''\n",
    "    return sum([en_embeddings[word] for word in process_tweet(tweet) if word in en_embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0398099 , -0.20691411,  0.0616893 ,  0.1492367 ,  0.12188119],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tweet = \"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np\"\n",
    "\n",
    "tweet_embedding = get_document_embedding(custom_tweet, en_embeddings_subset)\n",
    "tweet_embedding[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store all document vectors into a dictionary\n",
    "Now, let's store all the tweet embeddings into a dictionary.\n",
    "Implement `get_document_vecs()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C14 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def get_document_vecs(all_docs, en_embeddings):\n",
    "    '''\n",
    "    Input:\n",
    "        - all_docs: list of strings - all tweets in our dataset.\n",
    "        - en_embeddings: dictionary with words as the keys and their embeddings as the values.\n",
    "    Output:\n",
    "        - doc_vecs: matrix of tweet embeddings.\n",
    "        - ind2Doc_dict: dictionary with indices of tweets in vecs as keys and their embeddings as the values.\n",
    "    '''\n",
    "\n",
    "    # the dictionary's key is an index (integer) that identifies a specific tweet\n",
    "    # the value is the document embedding for that document\n",
    "    doc_vecs = [get_document_embedding(doc, en_embeddings) for doc in all_docs]\n",
    "    \n",
    "    if int in [type(doc) for doc in doc_vecs]:\n",
    "        for doc in doc_vecs:\n",
    "            if type(doc) is not int:\n",
    "                doc_len = len(doc)\n",
    "                break\n",
    "        \n",
    "        for i,doc in enumerate(doc_vecs):\n",
    "            if type(doc) == int:\n",
    "                doc_vecs[i] = np.ones(len(doc_vecs[0]))*doc\n",
    "    \n",
    "    doc_vecs = np.array(doc_vecs)\n",
    "    \n",
    "    return doc_vecs, {i: doc_vec for i,doc_vec in enumerate(doc_vecs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_vecs, ind2Tweet = get_document_vecs(all_tweets, en_embeddings_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `((pd.DataFrame(ind2Tweet) == 0).sum()).value_counts()`\n",
    "\n",
    "    - 0:      8653\n",
    "    - 300:    1347\n",
    "    - dtype: int64\n",
    "\n",
    "- `ind2Tweet[3]`\n",
    "    - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.0309365 , -0.18327793, -0.0265343 , -0.01930636,  0.08715737]),\n",
       " array([-0.06805824, -0.05019429, -0.07516   ,  0.10280149, -0.12424301])]"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ind2Tweet[tw][:5] for tw in [0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0309365 , -0.18327793, -0.0265343 , ..., -0.0510788 ,\n",
       "         0.1917097 ,  0.0342931 ],\n",
       "       [-0.06805824, -0.05019429, -0.07516   , ...,  0.19351122,\n",
       "         0.40420151,  0.06717461],\n",
       "       [-0.16645733, -0.04558986, -0.09931946, ...,  0.14182466,\n",
       "         0.15270641,  0.15162799],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.0874929 , -0.09656841, -0.18369341, ..., -0.13919711,\n",
       "        -0.0238108 , -0.05184384],\n",
       "       [-0.1526522 , -0.107896  , -0.09015776, ...,  0.0303527 ,\n",
       "         0.1685475 ,  0.0490873 ]])"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dictionary 10000\n",
      "shape of document_vecs (10000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of dictionary {len(ind2Tweet)}\")\n",
    "print(f\"shape of document_vecs {document_vecs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```\n",
    "length of dictionary 10000\n",
    "shape of document_vecs (10000, 300)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Looking up the tweets.\n",
    "\n",
    "Now you have a vector of dimension (m,d) where `m` is the number of tweets\n",
    "(10,000) and `d` is the dimension of the embeddings (300).  Now you\n",
    "will input a tweet, and use cosine similarity to see which tweet in our\n",
    "corpus is similar to your tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tweet = 'i am sad'\n",
    "process_tweet(my_tweet)\n",
    "tweet_embedding = get_document_embedding(my_tweet, en_embeddings_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@zoeeylim sad sad sad kid :( it's ok I help you watch the match HAHAHAHAHA\n"
     ]
    }
   ],
   "source": [
    "# this gives you a similar tweet as your input.\n",
    "# this implementation is vectorized...\n",
    "idx = np.argmax(cosine_similarity(document_vecs, tweet_embedding))\n",
    "print(all_tweets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "\n",
    "```\n",
    "@zoeeylim sad sad sad kid :( it's ok I help you watch the match HAHAHAHAHA\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Finding the most similar tweets with LSH\n",
    "\n",
    "You will now implement locality sensitive hashing (LSH) to identify the most similar tweet.\n",
    "* Instead of looking at all 10,000 vectors, you can just search a subset to find\n",
    "its nearest neighbors.\n",
    "\n",
    "Let's say your data points are plotted like this:\n",
    "\n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='one.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:400px;height:200px;\" /> Figure 3 </div>\n",
    "\n",
    "You can divide the vector space into regions and search within one region for nearest neighbors of a given vector.\n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='four.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:400px;height:200px;\" /> Figure 4 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors is 10000 and each has 300 dimensions.\n"
     ]
    }
   ],
   "source": [
    "N_VECS = len(all_tweets)       # This many vectors.\n",
    "N_DIMS = len(ind2Tweet[1])     # Vector dimensionality.\n",
    "print(f\"Number of vectors is {N_VECS} and each has {N_DIMS} dimensions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing the number of planes\n",
    "\n",
    "* Each plane divides the space to $2$ parts.\n",
    "* So $n$ planes divide the space into $2^{n}$ hash buckets.\n",
    "* We want to organize 10,000 document vectors into buckets so that every bucket has about $~16$ vectors.\n",
    "* For that we need $\\frac{10000}{16}=625$ buckets.\n",
    "* We're interested in $n$, number of planes, so that $2^{n}= 625$. Now, we can calculate $n=\\log_{2}625 = 9.29 \\approx 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of planes. We use log2(256) to have ~16 vectors/bucket.\n",
    "N_PLANES = 10\n",
    "# Number of times to repeat the hashing to improve the search.\n",
    "N_UNIVERSES = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Getting the hash number for a vector\n",
    "\n",
    "For each vector, we need to get a unique number associated to that vector in order to assign it to a \"hash bucket\".\n",
    "\n",
    "### Hyperlanes in vector spaces\n",
    "* In $3$-dimensional vector space, the hyperplane is a regular plane. In $2$ dimensional vector space, the hyperplane is a line.\n",
    "* Generally, the hyperplane is subspace which has dimension $1$ lower than the original vector space has.\n",
    "* A hyperplane is uniquely defined by its normal vector.\n",
    "* Normal vector $n$ of the plane $\\pi$ is the vector to which all vectors in the plane $\\pi$ are orthogonal (perpendicular in $3$ dimensional case).\n",
    "\n",
    "### Using Hyperplanes to split the vector space\n",
    "We can use a hyperplane to split the vector space into $2$ parts.\n",
    "* All vectors whose dot product with a plane's normal vector is positive are on one side of the plane.\n",
    "* All vectors whose dot product with the plane's normal vector is negative are on the other side of the plane.\n",
    "\n",
    "### Encoding hash buckets\n",
    "* For a vector, we can take its dot product with all the planes, then encode this information to assign the vector to a single hash bucket.\n",
    "* When the vector is pointing to the opposite side of the hyperplane than normal, encode it by 0.\n",
    "* Otherwise, if the vector is on the same side as the normal vector, encode it by 1.\n",
    "* If you calculate the dot product with each plane in the same order for every vector, you've encoded each vector's unique hash ID as a binary number, like [0, 1, 1, ... 0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing hash buckets\n",
    "\n",
    "We've initialized hash table `hashes` for you. It is list of `N_UNIVERSES` matrices, each describes its own hash table. Each matrix has `N_DIMS` rows and `N_PLANES` columns. Every column of that matrix is a `N_DIMS`-dimensional normal vector for each of `N_PLANES` hyperplanes which are used for creating buckets of the particular hash table.\n",
    "\n",
    "*Exercise*: Your task is to complete the function `hash_value_of_vector` which places vector `v` in the correct hash bucket.\n",
    "\n",
    "* First multiply your vector `v`, with a corresponding plane. This will give you a vector of dimension $(1,\\text{N_planes})$.\n",
    "* You will then convert every element in that vector to 0 or 1.\n",
    "* You create a hash vector by doing the following: if the element is negative, it becomes a 0, otherwise you change it to a 1.\n",
    "* You then compute the unique number for the vector by iterating over `N_PLANES`\n",
    "* Then you multiply $2^i$ times the corresponding bit (0 or 1).\n",
    "* You will then store that sum in the variable `hash_value`.\n",
    "\n",
    "**Intructions:** Create a hash for the vector in the function below.\n",
    "Use this formula:\n",
    "\n",
    "$$ hash = \\sum_{i=0}^{N-1} \\left( 2^{i} \\times h_{i} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the sets of planes\n",
    "* Create multiple (25) sets of planes (the planes that divide up the region).\n",
    "* You can think of these as 25 separate ways of dividing up the vector space with a different set of planes.\n",
    "* Each element of this list contains a matrix with 300 rows (the word vector have 300 dimensions), and 10 columns (there are 10 planes in each \"universe\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "planes_l = [np.random.normal(size=(N_DIMS, N_PLANES))\n",
    "            for _ in range(N_UNIVERSES)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> numpy.squeeze() removes unused dimensions from an array; for instance, it converts a (10,1) 2D array into a (10,) 1D array</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C17 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def hash_value_of_vector(v, planes):\n",
    "    \"\"\"Create a hash for a vector; hash_id says which random hash to use.\n",
    "    Input:\n",
    "        - v:  vector of tweet. It's dimension is (1, N_DIMS)\n",
    "        - planes: matrix of dimension (N_DIMS, N_PLANES) - the set of planes that divide up the region\n",
    "    Output:\n",
    "        - res: a number which is used as a hash for your vector\n",
    "\n",
    "    \"\"\"\n",
    "    res = sum([x * 2**i for i,x in enumerate([1 if x>0 else 0 for x in np.dot(v, planes).T])])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 300), (300, 10))"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.shape, planes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hash value for this vector, and the set of planes at index 0, is 768\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "idx = 0\n",
    "planes = planes_l[idx]  # get one 'universe' of planes to test the function\n",
    "vec = np.random.rand(1, 300)\n",
    "print(f\"The hash value for this vector, and the set of planes at index {idx},\", \n",
    "      f\"is {hash_value_of_vector(vec, planes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "\n",
    "```\n",
    "The hash value for this vector, and the set of planes at index 0, is 768\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Creating a hash table\n",
    "\n",
    "Given that you have a unique number for each vector (or tweet), You now want to create a hash table. You need a hash table, so that given a hash_id, you can quickly look up the corresponding vectors. This allows you to reduce your search by a significant amount of time.\n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='table.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:500px;height:200px;\" />  </div>\n",
    "\n",
    "Create a `make_hash_table` function, which maps the tweet vectors to a bucket and stores the vector there. It returns the `hash_table` and the `id_table`. The `id_table` allows you know which vector in a certain bucket corresponds to what tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> a dictionary comprehension, similar to a list comprehension, looks like this: `{i:0 for i in range(10)}`, where the key is 'i' and the value is zero for all key-value pairs. </li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hash_table(vecs, planes):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - vecs: list of vectors to be hashed.\n",
    "        - planes: the matrix of planes in a single \"universe\", with shape (embedding dimensions, number of planes).\n",
    "    Output:\n",
    "        - hash_table: dictionary - keys are hashes, values are lists of vectors (hash buckets)\n",
    "        - id_table: dictionary - keys are hashes, values are list of vectors id's\n",
    "                            (it's used to know which tweet corresponds to the hashed vector)\n",
    "    \"\"\"\n",
    "    # number of planes is the number of columns in the planes matrix\n",
    "    hash_table = {}\n",
    "    id_table = {}\n",
    "    \n",
    "    for i,v in enumerate(vecs):\n",
    "        hval = hash_value_of_vector(v, planes)\n",
    "        \n",
    "        if hval in id_table:\n",
    "            hash_table[hval].append(v)\n",
    "            id_table[hval].append(i)\n",
    "        else:\n",
    "            hash_table[hval] = [v]\n",
    "            id_table[hval] = [i]\n",
    "    \n",
    "    return hash_table, id_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 300), (300, 10))"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vecs.shape, planes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(44, [65, 2347, 5546, 5871, 6962]),\n",
       " (683, [126, 522, 2149, 9264]),\n",
       " (725, [258, 3337, 3502, 3503, 6368, 9660]),\n",
       " (500, [265, 3962, 4032, 6911]),\n",
       " (559, [293, 1347, 1688, 3401, 7392]),\n",
       " (941, [426, 2756, 5869, 6192, 7998]),\n",
       " (414, [460, 1321, 5001, 5083, 5616, 7773]),\n",
       " (245, [509, 856, 1146, 4017, 4440]),\n",
       " (938, [523, 1341, 6036, 8418, 9343]),\n",
       " (831, [568, 3432, 5687, 6837, 7014]),\n",
       " (88, [595, 1704, 2391, 2539, 4193, 9602]),\n",
       " (57, [599, 2209, 4255, 4688, 4713]),\n",
       " (387, [687, 1580, 4272, 4800]),\n",
       " (406, [760, 3878, 4487, 9024]),\n",
       " (952, [764, 1038, 3249, 3483, 5023]),\n",
       " (687, [774, 2479, 5879, 8439, 8902, 9784]),\n",
       " (182, [808, 4089, 5472, 6326, 6622, 9566]),\n",
       " (659, [815, 1924, 2542, 5729, 8723]),\n",
       " (272, [836, 2118, 3114, 8797, 9039]),\n",
       " (818, [867, 1491, 2288, 4126, 4857, 6789]),\n",
       " (291, [874, 4390, 5415, 5651, 9375]),\n",
       " (153, [916, 1418, 3492, 7035]),\n",
       " (165, [941, 6122, 7041, 7197]),\n",
       " (483, [945, 2921, 3322, 3594, 5859]),\n",
       " (1014, [1129, 1978, 4027, 4825, 8120]),\n",
       " (655, [1148, 5479, 8772, 9762]),\n",
       " (402, [1245, 2264, 3447, 5442, 5703, 5872]),\n",
       " (93, [1257, 1363, 2570, 7930]),\n",
       " (278, [1391, 2868, 4329, 6131, 8422]),\n",
       " (381, [1456, 2729, 3514, 8264, 9221]),\n",
       " (1019, [1511, 3723, 5494, 5624, 6360, 7901]),\n",
       " (508, [1592, 4154, 4700, 4947, 5907, 7857]),\n",
       " (471, [1679, 3574, 3846, 5802, 6447, 8832]),\n",
       " (225, [1789, 4727, 7686, 8818]),\n",
       " (60, [1819, 5352, 5711, 6577, 6912]),\n",
       " (552, [1828, 2313, 5073, 8322]),\n",
       " (702, [1879, 3109, 6970, 8845, 9863]),\n",
       " (1003, [1894, 2793, 2993, 7103, 7771]),\n",
       " (81, [1925, 3418, 4064, 6208, 8995]),\n",
       " (171, [1927, 6625, 7524, 7918, 8753]),\n",
       " (340, [2069, 3019, 9005, 9444, 9822]),\n",
       " (131, [2155, 6576, 9727, 9807]),\n",
       " (473, [2220, 3872, 6064, 9394]),\n",
       " (457, [2300, 3175, 5759, 8377]),\n",
       " (467, [2370, 4295, 6902, 8947, 9300, 9910]),\n",
       " (474, [2381, 5337, 6051, 7455]),\n",
       " (243, [2473, 4367, 5339, 5589, 7614]),\n",
       " (56, [2649, 6239, 6624, 6977, 7273, 7525]),\n",
       " (701, [2709, 3647, 3825, 7664, 8713]),\n",
       " (305, [2751, 3148, 3806, 4325, 4678]),\n",
       " (779, [2889, 5902, 7043, 8724]),\n",
       " (669, [2950, 3248, 4085, 4146, 5713]),\n",
       " (698, [3018, 4463, 7958, 8090, 9077, 9739]),\n",
       " (663, [3020, 5656, 6606, 8792, 9063]),\n",
       " (251, [3049, 3227, 4606, 5076]),\n",
       " (125, [3094, 4289, 4566, 4851]),\n",
       " (371, [3117, 4803, 5414, 5973, 6898]),\n",
       " (393, [3138, 3546, 5575, 6375]),\n",
       " (149, [3413, 6551, 7888, 8450, 9542]),\n",
       " (249, [4020, 4847, 6824, 6877, 8374, 9705]),\n",
       " (146, [4256, 4553, 5558, 7592]),\n",
       " (279, [4418, 5058, 7326, 8922]),\n",
       " (392, [4683, 6524, 9455, 9585]),\n",
       " (819, [4836, 5005, 6969, 8181, 8446]),\n",
       " (186, [4968, 6631, 6774, 7262, 8574]),\n",
       " (568, [5261, 5521, 7342, 8742]),\n",
       " (424, [5386, 6103, 7627, 9175]),\n",
       " (154, [5452, 6244, 6705, 7008, 7467]),\n",
       " (971, [5786, 6322, 6451, 8652]),\n",
       " (422, [6762, 7472, 8892, 9323]),\n",
       " (241, [6989, 7709, 8191, 9841, 9979]),\n",
       " (429, [7016, 7444, 7969, 8458, 9147]),\n",
       " (369, [7601, 7603, 8353, 8371]),\n",
       " (543, [7982, 8166, 8760, 9172])]"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in tuple(tmp_id_table.items()) if 3<len(x[1])<7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 10) \n"
     ]
    }
   ],
   "source": [
    "planes = planes_l[0]  # get one 'universe' of planes to test the function\n",
    "print(planes.shape,'')\n",
    "\n",
    "tmp_hash_table, tmp_id_table = make_hash_table(document_vecs, planes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hash table at key 56 has 6 document vectors\n",
      "The id table at key 56 has 6 indices\n",
      "The first 5 document indices stored at key 56 of id_table are [2649, 6239, 6624, 6977, 7273]\n",
      "The corresponding embeddings (first 4 values) are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.0290266,  0.0256658, -0.0138416, -0.0174541]),\n",
       " array([ 0.0290266,  0.0256658, -0.0138416, -0.0174541]),\n",
       " array([ 0.0290266,  0.0256658, -0.0138416, -0.0174541]),\n",
       " array([ 0.0290266,  0.0256658, -0.0138416, -0.0174541]),\n",
       " array([ 0.0290266,  0.0256658, -0.0138416, -0.0174541])]"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hval = 56\n",
    "print(f\"The hash table at key {hval} has {len(tmp_hash_table[hval])} document vectors\")\n",
    "print(f\"The id table at key {hval} has {len(tmp_id_table[hval])} indices\")\n",
    "print(f\"The first 5 document indices stored at key {hval} of id_table are {tmp_id_table[hval][0:5]}\")\n",
    "print(\"The corresponding embeddings (first 4 values) are:\")\n",
    "[vec[:4] for vec in tmp_hash_table[hval][:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Creating all hash tables\n",
    "\n",
    "You can now hash your vectors and store them in a hash table that\n",
    "would allow you to quickly look up and search for similar vectors.\n",
    "Run the cell below to create the hashes. By doing so, you end up having\n",
    "several tables which have all the vectors. Given a vector, you then\n",
    "identify the buckets in all the tables.  You can then iterate over the\n",
    "buckets and consider much fewer vectors. The more buckets you use, the\n",
    "more accurate your lookup will be, but also the longer it will take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the hashtables\n",
    "hash_table = []\n",
    "id_table = []\n",
    "for planes in planes_l:\n",
    "    hash_val, id_val = make_hash_table(document_vecs, planes)\n",
    "    hash_table.append(hash_val)\n",
    "    id_table.append(id_val)\n",
    "\n",
    "# there are 25 hashes\n",
    "len(hash_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(414, [460, 1321, 5001, 5083, 5616, 7773], [4003, 5452, 6244, 7008, 7467]),\n",
       " (153, [916, 1418, 3492, 7035], [3962, 6641, 6901, 7263, 7862, 8077]),\n",
       " (483, [945, 2921, 3322, 3594, 5859], [115, 2288, 2650, 8645]),\n",
       " (225, [1789, 4727, 7686, 8818], [2322, 3051, 4281, 7073, 8373, 9632]),\n",
       " (1003, [1894, 2793, 2993, 7103, 7771], [1879, 2145, 6875, 8845, 9863]),\n",
       " (81, [1925, 3418, 4064, 6208, 8995], [2177, 4461, 4734, 6327, 8855]),\n",
       " (457, [2300, 3175, 5759, 8377], [3496, 6045, 7910, 9247]),\n",
       " (779, [2889, 5902, 7043, 8724], [355, 4761, 7755, 8439, 8563]),\n",
       " (371, [3117, 4803, 5414, 5973, 6898], [3772, 5652, 5800, 9233, 9678])]"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x[0], x[1], y[1]) for x in tuple(id_table[0].items()) for y in tuple(id_table[1].items()) \n",
    " if ((x[0]==y[0]) & (3<len(x[1])<7) & (3<len(y[1])<7))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate K-NN\n",
    "\n",
    "Implement approximate K nearest neighbors using locality sensitive hashing,\n",
    "to search for documents that are similar to a given document at the\n",
    "index `doc_id`.\n",
    "\n",
    "##### Inputs\n",
    "* `doc_id` is the index into the document list `all_tweets`.\n",
    "* `v` is the document vector for the tweet in `all_tweets` at index `doc_id`.\n",
    "* `planes_l` is the list of planes (the global variable created earlier).\n",
    "* `k` is the number of nearest neighbors to search for.\n",
    "* `num_universes_to_use`: to save time, we can use fewer than the total\n",
    "number of available universes.  By default, it's set to `N_UNIVERSES`,\n",
    "which is $25$ for this assignment.\n",
    "\n",
    "The `approximate_knn` function finds a subset of candidate vectors that\n",
    "are in the same \"hash bucket\" as the input vector 'v'.  Then it performs\n",
    "the usual k-nearest neighbors search on this subset (instead of searching\n",
    "through all 10,000 tweets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> There are many dictionaries used in this function.  Try to print out planes_l, hash_tables, id_tables to understand how they are structured, what the keys represent, and what the values contain.</li>\n",
    "    <li> To remove an item from a list, use `.remove()` </li>\n",
    "    <li> To append to a list, use `.append()` </li>\n",
    "    <li> To add to a set, use `.add()` </li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to do the fast nearest neighbor search. \n",
    "def approximate_knn(doc_id, v, planes_l, k=1, num_universes_to_use=N_UNIVERSES):\n",
    "    \"\"\"Search for k-NN using hashes.\"\"\"\n",
    "    k += 1\n",
    "    \n",
    "    hvals = [hash_value_of_vector(v, planes_l[i]) for i in range(num_universes_to_use)]\n",
    "    \n",
    "    id_list = [id_table[i][hv] for i,hv in enumerate(hvals)]\n",
    "    \n",
    "    vec_list = [hash_table[i][hv] for i,hv in enumerate(hvals)]\n",
    "    \n",
    "    id_indices_list = [nearest_neighbor(v, candidates, k) for candidates in vec_list]\n",
    "    \n",
    "    universe_indices_list = [np.array(id_list[i])[[list(indices)]] for i,indices in enumerate(id_indices_list)]\n",
    "    \n",
    "    doc_indices = [x[0,i] for x in universe_indices_list for i in range(k)]\n",
    "    \n",
    "    top_k = []\n",
    "    for i in range(k):\n",
    "        index = mode(doc_indices)\n",
    "        top_k.append(index)\n",
    "        doc_indices.remove     \n",
    "        while index in doc_indices:\n",
    "            doc_indices.remove(index)\n",
    "    \n",
    "    top_k.remove(top_k[0])\n",
    "    \n",
    "    print(f'Removed doc_id {doc_id} of input vector from new_ids_to_search')\n",
    "    print(f'{k-1} Nearest Doc ids: {top_k}')\n",
    "    \n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = 0\n",
    "doc_to_search = all_tweets[doc_id]\n",
    "vec_to_search = document_vecs[doc_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed doc_id 0 of input vector from new_ids_to_search\n",
      "3 Nearest Doc ids: [51, 105, 2478]\n"
     ]
    }
   ],
   "source": [
    "nearest_neighbor_ids = approximate_knn(doc_id, vec_to_search, planes_l, k=3, num_universes_to_use=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors for document 0\n",
      "Document contents: #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
      "\n",
      "Nearest neighbor at document id 51\n",
      "document contents: #FollowFriday @France_Espana @reglisse_menthe @CCI_inter for being top engaged members in my community this week :)\n",
      "Nearest neighbor at document id 105\n",
      "document contents: #FollowFriday @straz_das @DCarsonCPA @GH813600 for being top engaged members in my community this week :)\n",
      "Nearest neighbor at document id 2478\n",
      "document contents: #ShareTheLove @oymgroup @musicartisthere for being top HighValue members this week :) @nataliavas http://t.co/IWSDMtcayt\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nearest neighbors for document {doc_id}\")\n",
    "print(f\"Document contents: {doc_to_search}\")\n",
    "print(\"\")\n",
    "\n",
    "for neighbor_id in nearest_neighbor_ids:\n",
    "    print(f\"Nearest neighbor at document id {neighbor_id}\")\n",
    "    print(f\"document contents: {all_tweets[neighbor_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Conclusion\n",
    "Congratulations - Now you can look up vectors that are similar to the\n",
    "encoding of your tweet using LSH!"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "NLPC1-4"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
